{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL_Project_02.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyPSZZtPk9sQficHwNR6S/My"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"RnN6UDH_tIfd","executionInfo":{"status":"ok","timestamp":1604937451661,"user_tz":300,"elapsed":140582,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"ddeffc01-4cc7-4db8-ff32-1017aa9ef446","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install git+https://github.com/kernelmachine/allennlp.git@4ae123d2c3bfb1ea3ce7362cb6c5bca3d094ffa7\n","!pip install transformers==2.4.1\n","!pip install pytorch-transformers==1.2.0\n","!git clone https://github.com/allenai/dont-stop-pretraining"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/kernelmachine/allennlp.git@4ae123d2c3bfb1ea3ce7362cb6c5bca3d094ffa7\n","  Cloning https://github.com/kernelmachine/allennlp.git (to revision 4ae123d2c3bfb1ea3ce7362cb6c5bca3d094ffa7) to /tmp/pip-req-build-i0rwsmyg\n","  Running command git clone -q https://github.com/kernelmachine/allennlp.git /tmp/pip-req-build-i0rwsmyg\n","  Running command git checkout -q 4ae123d2c3bfb1ea3ce7362cb6c5bca3d094ffa7\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting boto3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/54/099a2ea5d4b2d5931a26f280a7585f613b1fafaac9189e489a9e25004a01/boto3-1.16.13-py2.py3-none-any.whl (129kB)\n","\u001b[K     |████████████████████████████████| 133kB 9.8MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (2.23.0)\n","Collecting conllu==1.3.1\n","  Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl\n","Collecting numpydoc>=0.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/1d/9e398c53d6ae27d5ab312ddc16a9ffe1bee0dfdf1d6ec88c40b0ca97582e/numpydoc-1.1.0-py3-none-any.whl (47kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n","\u001b[?25hCollecting word2number>=1.1\n","  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n","Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (1.7.0+cu101)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (1.4.1)\n","Collecting jsonnet>=0.10.0; sys_platform != \"win32\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/70/ed1ba808a87d896b9f4d25400dda54e089ca7a97e87cee620b3744997c89/jsonnet-0.16.0.tar.gz (256kB)\n","\u001b[K     |████████████████████████████████| 266kB 16.6MB/s \n","\u001b[?25hCollecting flask-cors>=3.0.7\n","  Downloading https://files.pythonhosted.org/packages/69/7f/d0aeaaafb5c3c76c8d2141dbe2d4f6dca5d6c31872d4e5349768c1958abc/Flask_Cors-3.0.9-py2.py3-none-any.whl\n","Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (3.6.4)\n","Requirement already satisfied: sqlparse>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (0.4.1)\n","Collecting jsonpickle\n","  Downloading https://files.pythonhosted.org/packages/af/ca/4fee219cc4113a5635e348ad951cf8a2e47fed2e3342312493f5b73d0007/jsonpickle-1.4.1-py2.py3-none-any.whl\n","Collecting responses>=0.7\n","  Downloading https://files.pythonhosted.org/packages/c1/04/8a5258cfd851c9c89ae5c12c6952c05d42ca8c0788b999806e0c78d06c54/responses-0.12.0-py2.py3-none-any.whl\n","Collecting pytorch-transformers==1.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/89/ad0d6bb932d0a51793eaabcf1617a36ff530dc9ab9e38f765a35dc293306/pytorch_transformers-1.1.0-py3-none-any.whl (158kB)\n","\u001b[K     |████████████████████████████████| 163kB 24.0MB/s \n","\u001b[?25hCollecting unidecode\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n","\u001b[K     |████████████████████████████████| 245kB 22.7MB/s \n","\u001b[?25hCollecting spacy<2.2,>=2.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/5b/e07dd3bf104237bce4b398558b104c8e500333d6f30eabe3fa9685356b7d/spacy-2.1.9-cp36-cp36m-manylinux1_x86_64.whl (30.8MB)\n","\u001b[K     |████████████████████████████████| 30.9MB 105kB/s \n","\u001b[?25hCollecting flaky\n","  Downloading https://files.pythonhosted.org/packages/43/0e/2f50064e327f41a1eb811df089f813036e19a64b95e33f8e9e0b96c2447e/flaky-3.7.0-py2.py3-none-any.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (1.18.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (0.22.2.post1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (2.10.0)\n","Requirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (1.1.2)\n","Collecting pytorch-pretrained-bert>=0.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\u001b[K     |████████████████████████████████| 133kB 65.9MB/s \n","\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (3.2.5)\n","Collecting gevent>=1.3.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/92/b80b922f08f222faca53c8d278e2e612192bc74b0e1f0db2f80a6ee46982/gevent-20.9.0-cp36-cp36m-manylinux2010_x86_64.whl (5.3MB)\n","\u001b[K     |████████████████████████████████| 5.3MB 56.3MB/s \n","\u001b[?25hCollecting ftfy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/e2/3b51c53dffb1e52d9210ebc01f1fb9f2f6eba9b3201fa971fd3946643c71/ftfy-5.8.tar.gz (64kB)\n","\u001b[K     |████████████████████████████████| 71kB 10.6MB/s \n","\u001b[?25hCollecting overrides\n","  Downloading https://files.pythonhosted.org/packages/ff/b1/10f69c00947518e6676bbd43e739733048de64b8dd998e9c2d5a71f44c5d/overrides-3.1.0.tar.gz\n","Collecting tensorboardX>=1.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n","\u001b[K     |████████████████████████████████| 317kB 52.8MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (4.41.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (2018.9)\n","Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (0.5.3)\n","Collecting parsimonious>=0.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/fc/067a3f89869a41009e1a7cdfb14725f8ddd246f30f63c645e8ef8a1c56f4/parsimonious-0.8.1.tar.gz (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.9MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (3.2.2)\n","Collecting s3transfer<0.4.0,>=0.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n","\u001b[K     |████████████████████████████████| 71kB 9.8MB/s \n","\u001b[?25hCollecting botocore<1.20.0,>=1.19.13\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/40/b5e681d80dc46bafd0dc2e55266190cc432dfd5b72b9e7e1c5743aa6c362/botocore-1.19.13-py2.py3-none-any.whl (6.7MB)\n","\u001b[K     |████████████████████████████████| 6.7MB 47.4MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp===0.9.1-unreleased) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp===0.9.1-unreleased) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp===0.9.1-unreleased) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp===0.9.1-unreleased) (2.10)\n","Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (2.11.2)\n","Requirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (1.8.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->allennlp===0.9.1-unreleased) (0.16.0)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->allennlp===0.9.1-unreleased) (0.7)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->allennlp===0.9.1-unreleased) (3.7.4.3)\n","Requirement already satisfied: Six in /usr/local/lib/python3.6/dist-packages (from flask-cors>=3.0.7->allennlp===0.9.1-unreleased) (1.15.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp===0.9.1-unreleased) (0.7.1)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp===0.9.1-unreleased) (8.6.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp===0.9.1-unreleased) (1.4.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp===0.9.1-unreleased) (1.9.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp===0.9.1-unreleased) (20.2.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp===0.9.1-unreleased) (50.3.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonpickle->allennlp===0.9.1-unreleased) (2.0.0)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 64.3MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.1.0->allennlp===0.9.1-unreleased) (2019.12.20)\n","Collecting preshed<2.1.0,>=2.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/93/f222fb957764a283203525ef20e62008675fd0a14ffff8cc1b1490147c63/preshed-2.0.1-cp36-cp36m-manylinux1_x86_64.whl (83kB)\n","\u001b[K     |████████████████████████████████| 92kB 12.3MB/s \n","\u001b[?25hCollecting plac<1.0.0,>=0.9.6\n","  Downloading https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n","Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp===0.9.1-unreleased) (0.8.0)\n","Collecting blis<0.3.0,>=0.2.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/46/b1d0bb71d308e820ed30316c5f0a017cb5ef5f4324bcbc7da3cf9d3b075c/blis-0.2.4-cp36-cp36m-manylinux1_x86_64.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 60.8MB/s \n","\u001b[?25hRequirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp===0.9.1-unreleased) (1.0.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp===0.9.1-unreleased) (1.0.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp===0.9.1-unreleased) (2.0.4)\n","Collecting thinc<7.1.0,>=7.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/a5/9ace20422e7bb1bdcad31832ea85c52a09900cd4a7ce711246bfb92206ba/thinc-7.0.8-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 65.0MB/s \n","\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp===0.9.1-unreleased) (0.17.0)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp===0.9.1-unreleased) (7.1.2)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp===0.9.1-unreleased) (1.1.0)\n","Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp===0.9.1-unreleased) (1.0.1)\n","Collecting zope.interface\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/b0/da8afd9b3bd50c7665ecdac062f182982af1173c9081f9af7261091c5588/zope.interface-5.2.0-cp36-cp36m-manylinux2010_x86_64.whl (236kB)\n","\u001b[K     |████████████████████████████████| 245kB 66.2MB/s \n","\u001b[?25hCollecting greenlet>=0.4.17; platform_python_implementation == \"CPython\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d0/532e160c777b42f6f393f9de8c88abb8af6c892037c55e4d3a8a211324dd/greenlet-0.4.17-cp36-cp36m-manylinux1_x86_64.whl (44kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.3MB/s \n","\u001b[?25hCollecting zope.event\n","  Downloading https://files.pythonhosted.org/packages/9e/85/b45408c64f3b888976f1d5b37eed8d746b8d5729a66a49ec846fda27d371/zope.event-4.5.0-py2.py3-none-any.whl\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->allennlp===0.9.1-unreleased) (0.2.5)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp===0.9.1-unreleased) (3.12.4)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp===0.9.1-unreleased) (1.3.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp===0.9.1-unreleased) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp===0.9.1-unreleased) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp===0.9.1-unreleased) (2.4.7)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (1.1.1)\n","Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (1.2.4)\n","Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (2.6.1)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (0.7.12)\n","Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (2.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (20.4)\n","Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (2.8.0)\n","Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (0.16)\n","Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (1.2.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonpickle->allennlp===0.9.1-unreleased) (3.4.0)\n","Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.6/dist-packages (from sphinxcontrib-websupport->sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (1.1.4)\n","Building wheels for collected packages: allennlp\n","  Building wheel for allennlp (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for allennlp: filename=allennlp-0.9.1_unreleased-cp36-none-any.whl size=7535392 sha256=42e3d0b4030f5bcc86d5f2eafcd2bf8ad8a2d165a261bface70d1d046a88f8e7\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-vnsecljm/wheels/16/b3/9b/fceece1cbc3a6ac0c759db090cb239c3f4cba5bb369bb933c3\n","Successfully built allennlp\n","Building wheels for collected packages: word2number, jsonnet, ftfy, overrides, parsimonious\n","  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for word2number: filename=word2number-1.1-cp36-none-any.whl size=5588 sha256=fd7ca943a33d2f028e89bbfb3566c0b01b834bde70ecbd8046022ebe33640ce4\n","  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n","  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jsonnet: filename=jsonnet-0.16.0-cp36-cp36m-linux_x86_64.whl size=3321534 sha256=22ffe80e4c29194e34d7199dc301a78c1cb77ae5d5a7c46f34a399c7596caff8\n","  Stored in directory: /root/.cache/pip/wheels/64/a9/43/bc5e0463deeec89dfca928a2a64595f1bdb520c891f6fbd09c\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ftfy: filename=ftfy-5.8-cp36-none-any.whl size=45612 sha256=1d4d31057b29c3fea9111675604c220689a05e9e24e0f59b7bb33d92fb1d5fca\n","  Stored in directory: /root/.cache/pip/wheels/ba/c0/ef/f28c4da5ac84a4e06ac256ca9182fc34fa57fefffdbc68425b\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for overrides: filename=overrides-3.1.0-cp36-none-any.whl size=10174 sha256=067e4673b73cff141c1743d45fb96a2120fc40a8e8862372a95d92e9581e2b35\n","  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n","  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for parsimonious: filename=parsimonious-0.8.1-cp36-none-any.whl size=42709 sha256=1f5ecb8d7f01f244086a646349c4d7026dd7564501f93f272af6ab408686499f\n","  Stored in directory: /root/.cache/pip/wheels/b7/8d/e7/a0e74217da5caeb3c1c7689639b6d28ddbf9985b840bc96a9a\n","Successfully built word2number jsonnet ftfy overrides parsimonious\n","\u001b[31mERROR: en-core-web-sm 2.2.5 has requirement spacy>=2.2.2, but you'll have spacy 2.1.9 which is incompatible.\u001b[0m\n","\u001b[31mERROR: botocore 1.19.13 has requirement urllib3<1.26,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: responses 0.12.0 has requirement urllib3>=1.25.10, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n","Installing collected packages: jmespath, botocore, s3transfer, boto3, conllu, numpydoc, word2number, jsonnet, flask-cors, jsonpickle, responses, sentencepiece, pytorch-transformers, unidecode, preshed, plac, blis, thinc, spacy, flaky, pytorch-pretrained-bert, zope.interface, greenlet, zope.event, gevent, ftfy, overrides, tensorboardX, parsimonious, allennlp\n","  Found existing installation: preshed 3.0.2\n","    Uninstalling preshed-3.0.2:\n","      Successfully uninstalled preshed-3.0.2\n","  Found existing installation: plac 1.1.3\n","    Uninstalling plac-1.1.3:\n","      Successfully uninstalled plac-1.1.3\n","  Found existing installation: blis 0.4.1\n","    Uninstalling blis-0.4.1:\n","      Successfully uninstalled blis-0.4.1\n","  Found existing installation: thinc 7.4.0\n","    Uninstalling thinc-7.4.0:\n","      Successfully uninstalled thinc-7.4.0\n","  Found existing installation: spacy 2.2.4\n","    Uninstalling spacy-2.2.4:\n","      Successfully uninstalled spacy-2.2.4\n","Successfully installed allennlp-0.9.1-unreleased blis-0.2.4 boto3-1.16.13 botocore-1.19.13 conllu-1.3.1 flaky-3.7.0 flask-cors-3.0.9 ftfy-5.8 gevent-20.9.0 greenlet-0.4.17 jmespath-0.10.0 jsonnet-0.16.0 jsonpickle-1.4.1 numpydoc-1.1.0 overrides-3.1.0 parsimonious-0.8.1 plac-0.9.6 preshed-2.0.1 pytorch-pretrained-bert-0.6.2 pytorch-transformers-1.1.0 responses-0.12.0 s3transfer-0.3.3 sentencepiece-0.1.94 spacy-2.1.9 tensorboardX-2.1 thinc-7.0.8 unidecode-1.1.1 word2number-1.1 zope.event-4.5.0 zope.interface-5.2.0\n","Collecting transformers==2.4.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n","\u001b[K     |████████████████████████████████| 481kB 8.5MB/s \n","\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.4.1) (1.16.13)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.4.1) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.4.1) (3.0.12)\n","Collecting tokenizers==0.0.11\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.1MB 10.9MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.4.1) (2019.12.20)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.4.1) (0.1.94)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 64.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.4.1) (1.18.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.4.1) (2.23.0)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.4.1) (0.3.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.4.1) (0.10.0)\n","Requirement already satisfied: botocore<1.20.0,>=1.19.13 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.4.1) (1.19.13)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.4.1) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.4.1) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.4.1) (0.17.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.4.1) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.4.1) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.4.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.4.1) (2.10)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.13->boto3->transformers==2.4.1) (2.8.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=85e691b391869c4e5da36c8d1194d1e9a30429548d829ac61e6d5f14ece6fe10\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.0.11 transformers-2.4.1\n","Collecting pytorch-transformers==1.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n","\u001b[K     |████████████████████████████████| 184kB 9.1MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.2.0) (1.7.0+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.2.0) (1.18.5)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.2.0) (2019.12.20)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.2.0) (0.1.94)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.2.0) (0.0.43)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.2.0) (1.16.13)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.2.0) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.2.0) (2.23.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch-transformers==1.2.0) (0.16.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch-transformers==1.2.0) (3.7.4.3)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch-transformers==1.2.0) (0.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers==1.2.0) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers==1.2.0) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers==1.2.0) (0.17.0)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers==1.2.0) (0.3.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers==1.2.0) (0.10.0)\n","Requirement already satisfied: botocore<1.20.0,>=1.19.13 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers==1.2.0) (1.19.13)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers==1.2.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers==1.2.0) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers==1.2.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers==1.2.0) (1.24.3)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.13->boto3->pytorch-transformers==1.2.0) (2.8.1)\n","\u001b[31mERROR: allennlp 0.9.1-unreleased has requirement pytorch-transformers==1.1.0, but you'll have pytorch-transformers 1.2.0 which is incompatible.\u001b[0m\n","Installing collected packages: pytorch-transformers\n","  Found existing installation: pytorch-transformers 1.1.0\n","    Uninstalling pytorch-transformers-1.1.0:\n","      Successfully uninstalled pytorch-transformers-1.1.0\n","Successfully installed pytorch-transformers-1.2.0\n","Cloning into 'dont-stop-pretraining'...\n","remote: Enumerating objects: 439, done.\u001b[K\n","remote: Total 439 (delta 0), reused 0 (delta 0), pack-reused 439\u001b[K\n","Receiving objects: 100% (439/439), 566.01 KiB | 1.39 MiB/s, done.\n","Resolving deltas: 100% (232/232), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4KUeOGZgtOoK","executionInfo":{"status":"ok","timestamp":1604937540944,"user_tz":300,"elapsed":768,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"1e8e436f-1197-4c20-b3d2-6debcaf04a92","colab":{"base_uri":"https://localhost:8080/"}},"source":["%cd /content/dont-stop-pretraining\n","!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/dont-stop-pretraining\n","/content/dont-stop-pretraining\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HitYqsqPtzwO","executionInfo":{"status":"ok","timestamp":1604954069083,"user_tz":300,"elapsed":591,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"ac980038-69a6-4b92-8d41-652cafe81394","colab":{"base_uri":"https://localhost:8080/"}},"source":["import torch\n","if torch.cuda.is_available():\n","  device = torch.device(\"cuda\")\n","else:\n","  device = torch.device(\"cpu\")\n","print(device)\n","\n","!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda\n","Mon Nov  9 20:34:28 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    23W / 300W |     10MiB / 16130MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cV0P-3tK7mLk"},"source":["%pycat environments/hyperparameters.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ywN1xO08Mja"},"source":["!rm environments/hyperparameters.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VnyiDa1I708i","executionInfo":{"status":"ok","timestamp":1604941049564,"user_tz":300,"elapsed":458,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"d673af48-801f-4338-95e6-f99064f61026","colab":{"base_uri":"https://localhost:8080/"}},"source":["%%writefile environments/hyperparameters.py\n","ROBERTA_CLASSIFIER_SMALL = {\n","    \"LEARNING_RATE\": 2e-5,\n","    \"DROPOUT\": 0.1,\n","    \"ENCODER\": \"CLS\",\n","    \"NUM_FEEDFORWARD_LAYERS\": 1,\n","    \"FEEDFORWARD_WIDTH_MULTIPLIER\": 1,\n","    \"EMBEDDING\": \"ROBERTA\",\n","    \"NUM_EPOCHS\": 10,\n","    \"PATIENCE\": 3,\n","    \"LR_SCHEDULE\": 0,\n","    \"GRAD_ACC_BATCH_SIZE\": 16,\n","    \"BATCH_SIZE\": 16,\n","}\n","\n","ROBERTA_CLASSIFIER_MINI = {\n","    \"LEARNING_RATE\": 2e-5,\n","    \"DROPOUT\": 0.1,\n","    \"ENCODER\": \"CLS\",\n","    \"NUM_FEEDFORWARD_LAYERS\": 1,\n","    \"FEEDFORWARD_WIDTH_MULTIPLIER\": 1,\n","    \"EMBEDDING\": \"ROBERTA\",\n","    \"NUM_EPOCHS\": 10,\n","    \"PATIENCE\": 3,\n","    \"LR_SCHEDULE\": 0,\n","    \"GRAD_ACC_BATCH_SIZE\": 8,\n","    \"BATCH_SIZE\": 8,\n","}\n","\n","ROBERTA_CLASSIFIER_MINI_MOD = {\n","    \"LEARNING_RATE\": 2e-5,\n","    \"DROPOUT\": 0.1,\n","    \"ENCODER\": \"CLS\",\n","    \"NUM_FEEDFORWARD_LAYERS\": 1,\n","    \"FEEDFORWARD_WIDTH_MULTIPLIER\": 1,\n","    \"EMBEDDING\": \"ROBERTA\",\n","    \"NUM_EPOCHS\": 10,\n","    \"PATIENCE\": 10,\n","    \"LR_SCHEDULE\": 0,\n","    \"GRAD_ACC_BATCH_SIZE\": 8,\n","    \"BATCH_SIZE\": 8,\n","}\n","\n","ROBERTA_CLASSIFIER_BIG = {\n","    \"LEARNING_RATE\": 2e-5,\n","    \"DROPOUT\": 0.1,\n","    \"ENCODER\": \"CLS\",\n","    \"NUM_FEEDFORWARD_LAYERS\": 1,\n","    \"FEEDFORWARD_WIDTH_MULTIPLIER\": 1,\n","    \"EMBEDDING\": \"ROBERTA\",\n","    \"NUM_EPOCHS\": 3,\n","    \"PATIENCE\": 3,\n","    \"LR_SCHEDULE\": 1,\n","    \"GRAD_ACC_BATCH_SIZE\": 16,\n","    \"BATCH_SIZE\": 16,\n","}\n","\n","HYPERPARAMETERS = {\n","    \"ROBERTA_CLASSIFIER_SMALL\": ROBERTA_CLASSIFIER_SMALL,\n","    \"ROBERTA_CLASSIFIER_MINI\": ROBERTA_CLASSIFIER_MINI,\n","    \"ROBERTA_CLASSIFIER_MINI_MOD\": ROBERTA_CLASSIFIER_MINI_MOD,\n","    \"ROBERTA_CLASSIFIER_BIG\": ROBERTA_CLASSIFIER_BIG\n","}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing environments/hyperparameters.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HSluUzo3t0pe","executionInfo":{"status":"ok","timestamp":1604953716698,"user_tz":300,"elapsed":12636362,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"5cac378c-895c-47f0-cc13-814cea58e2bd","colab":{"base_uri":"https://localhost:8080/"}},"source":["!python -m scripts.train \\\n","        --config training_config/classifier.jsonnet \\\n","        --serialization_dir model_logs/amazon_nas_04 \\\n","        --hyperparameters ROBERTA_CLASSIFIER_MINI_MOD \\\n","        --dataset amazon \\\n","        --model roberta-base \\\n","        --device 0 \\\n","        --perf +f1 \\\n","        --evaluate_on_test"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-11-09 16:58:03,214 - INFO - pytorch_pretrained_bert.modeling - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-09 16:58:03,671 - INFO - pytorch_transformers.modeling_bert - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-09 16:58:03,674 - INFO - pytorch_transformers.modeling_xlnet - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-09 16:58:04,173 - INFO - allennlp.common.params - random_seed = 334422\n","2020-11-09 16:58:04,173 - INFO - allennlp.common.params - numpy_seed = 334422\n","2020-11-09 16:58:04,173 - INFO - allennlp.common.params - pytorch_seed = 334422\n","2020-11-09 16:58:04,181 - INFO - allennlp.common.checks - Pytorch version: 1.7.0+cu101\n","2020-11-09 16:58:04,182 - INFO - allennlp.common.params - evaluate_on_test = True\n","2020-11-09 16:58:04,182 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}, 'type': 'text_classification_json_with_sampling'} and extras set()\n","2020-11-09 16:58:04,183 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling\n","2020-11-09 16:58:04,183 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.data.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}} and extras set()\n","2020-11-09 16:58:04,183 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 16:58:04,183 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.type = pretrained_transformer\n","2020-11-09 16:58:04,183 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base'} and extras set()\n","2020-11-09 16:58:04,183 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.model_name = roberta-base\n","2020-11-09 16:58:04,184 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.do_lowercase = False\n","2020-11-09 16:58:04,184 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.namespace = tags\n","2020-11-09 16:58:04,184 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.token_min_padding_length = 0\n","2020-11-09 16:58:05,226 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 16:58:05,226 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 16:58:05,308 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 1\n","2020-11-09 16:58:05,308 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 16:58:05,308 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer\n","2020-11-09 16:58:05,309 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>']} and extras set()\n","2020-11-09 16:58:05,309 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base\n","2020-11-09 16:58:05,309 - INFO - allennlp.common.params - dataset_reader.tokenizer.do_lowercase = False\n","2020-11-09 16:58:05,309 - INFO - allennlp.common.params - dataset_reader.tokenizer.start_tokens = ['<s>']\n","2020-11-09 16:58:05,309 - INFO - allennlp.common.params - dataset_reader.tokenizer.end_tokens = ['</s>']\n","2020-11-09 16:58:06,039 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 16:58:06,039 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 16:58:06,116 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512\n","2020-11-09 16:58:06,117 - INFO - allennlp.common.params - dataset_reader.sample = None\n","2020-11-09 16:58:06,117 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False\n","2020-11-09 16:58:06,117 - INFO - allennlp.common.params - dataset_reader.lazy = False\n","2020-11-09 16:58:06,117 - INFO - allennlp.training.util - Using a separate dataset reader to load validation and test data.\n","2020-11-09 16:58:06,117 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}, 'type': 'text_classification_json_with_sampling'} and extras set()\n","2020-11-09 16:58:06,117 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling\n","2020-11-09 16:58:06,117 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.data.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}} and extras set()\n","2020-11-09 16:58:06,117 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 16:58:06,118 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.type = pretrained_transformer\n","2020-11-09 16:58:06,118 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base'} and extras set()\n","2020-11-09 16:58:06,118 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.model_name = roberta-base\n","2020-11-09 16:58:06,118 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.do_lowercase = False\n","2020-11-09 16:58:06,118 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.namespace = tags\n","2020-11-09 16:58:06,118 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.token_min_padding_length = 0\n","2020-11-09 16:58:06,899 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 16:58:06,900 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 16:58:06,977 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 1\n","2020-11-09 16:58:06,977 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 16:58:06,978 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer\n","2020-11-09 16:58:06,978 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>']} and extras set()\n","2020-11-09 16:58:06,978 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base\n","2020-11-09 16:58:06,978 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.do_lowercase = False\n","2020-11-09 16:58:06,978 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.start_tokens = ['<s>']\n","2020-11-09 16:58:06,978 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.end_tokens = ['</s>']\n","2020-11-09 16:58:07,705 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 16:58:07,705 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 16:58:07,783 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512\n","2020-11-09 16:58:07,783 - INFO - allennlp.common.params - validation_dataset_reader.sample = None\n","2020-11-09 16:58:07,783 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False\n","2020-11-09 16:58:07,783 - INFO - allennlp.common.params - validation_dataset_reader.lazy = False\n","2020-11-09 16:58:07,783 - INFO - allennlp.common.params - train_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/amazon/train.jsonl\n","2020-11-09 16:58:07,783 - INFO - allennlp.training.util - Reading training data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/amazon/train.jsonl\n","115251it [02:02, 939.82it/s] \n","2020-11-09 17:00:10,414 - INFO - allennlp.common.params - validation_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/amazon/dev.jsonl\n","2020-11-09 17:00:10,414 - INFO - allennlp.training.util - Reading validation data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/amazon/dev.jsonl\n","5000it [00:05, 835.06it/s]\n","2020-11-09 17:00:16,402 - INFO - allennlp.common.params - test_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/amazon/test.jsonl\n","2020-11-09 17:00:16,402 - INFO - allennlp.training.util - Reading test data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/amazon/test.jsonl\n","25000it [00:28, 886.32it/s] \n","2020-11-09 17:00:44,881 - INFO - allennlp.training.trainer_pieces - From dataset instances, test, validation, train will be considered for vocabulary creation.\n","2020-11-09 17:00:44,882 - INFO - allennlp.common.params - vocabulary.type = None\n","2020-11-09 17:00:44,882 - INFO - allennlp.common.params - vocabulary.extend = False\n","2020-11-09 17:00:44,882 - INFO - allennlp.common.params - vocabulary.directory_path = None\n","2020-11-09 17:00:44,882 - INFO - allennlp.common.params - vocabulary.min_count = None\n","2020-11-09 17:00:44,882 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None\n","2020-11-09 17:00:44,882 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')\n","2020-11-09 17:00:44,882 - INFO - allennlp.common.params - vocabulary.pretrained_files = {}\n","2020-11-09 17:00:44,882 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None\n","2020-11-09 17:00:44,882 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False\n","2020-11-09 17:00:44,882 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None\n","2020-11-09 17:00:44,882 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n","145251it [00:03, 42504.97it/s]\n","2020-11-09 17:00:48,300 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'dropout': '0.1', 'feedforward_layer': {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1}, 'seq2vec_encoder': {'embedding_dim': 768, 'type': 'cls_pooler'}, 'text_field_embedder': {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'type': 'basic_classifier_with_f1'} and extras {'vocab'}\n","2020-11-09 17:00:48,300 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1\n","2020-11-09 17:00:48,301 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.models.basic_classifier_with_f1.BasicClassifierWithF1'> from params {'dropout': '0.1', 'feedforward_layer': {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1}, 'seq2vec_encoder': {'embedding_dim': 768, 'type': 'cls_pooler'}, 'text_field_embedder': {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}} and extras {'vocab'}\n","2020-11-09 17:00:48,301 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}} and extras {'vocab'}\n","2020-11-09 17:00:48,301 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n","2020-11-09 17:00:48,301 - INFO - allennlp.common.params - model.text_field_embedder.embedder_to_indexer_map = None\n","2020-11-09 17:00:48,301 - INFO - allennlp.common.params - model.text_field_embedder.allow_unmatched_keys = False\n","2020-11-09 17:00:48,301 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders = None\n","2020-11-09 17:00:48,301 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras {'vocab'}\n","2020-11-09 17:00:48,301 - INFO - allennlp.common.params - model.text_field_embedder.roberta.type = pretrained_transformer\n","2020-11-09 17:00:48,302 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.pretrained_transformer_embedder.PretrainedTransformerEmbedder'> from params {'model_name': 'roberta-base'} and extras {'vocab'}\n","2020-11-09 17:00:48,302 - INFO - allennlp.common.params - model.text_field_embedder.roberta.model_name = roberta-base\n","2020-11-09 17:00:48,670 - INFO - pytorch_transformers.modeling_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/pytorch_transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n","2020-11-09 17:00:48,670 - INFO - pytorch_transformers.modeling_utils - Model config {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 1,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","2020-11-09 17:00:49,046 - INFO - pytorch_transformers.modeling_utils - loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n","2020-11-09 17:00:53,722 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'embedding_dim': 768, 'type': 'cls_pooler'} and extras {'vocab'}\n","2020-11-09 17:00:53,722 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler\n","2020-11-09 17:00:53,723 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.modules.seq2vec_encoders.cls_pooler.CLSPooler'> from params {'embedding_dim': 768} and extras {'vocab'}\n","2020-11-09 17:00:53,723 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768\n","2020-11-09 17:00:53,723 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1} and extras {'vocab'}\n","2020-11-09 17:00:53,723 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768\n","2020-11-09 17:00:53,723 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1\n","2020-11-09 17:00:53,723 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768\n","2020-11-09 17:00:53,724 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh\n","2020-11-09 17:00:53,724 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0\n","2020-11-09 17:00:53,729 - INFO - allennlp.common.params - model.dropout = 0.1\n","2020-11-09 17:00:53,729 - INFO - allennlp.common.params - model.num_labels = None\n","2020-11-09 17:00:53,729 - INFO - allennlp.common.params - model.label_namespace = labels\n","2020-11-09 17:00:53,730 - INFO - allennlp.nn.initializers - Initializing parameters\n","2020-11-09 17:00:53,731 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n","2020-11-09 17:00:53,732 - INFO - allennlp.nn.initializers -    _classification_layer.bias\n","2020-11-09 17:00:53,732 - INFO - allennlp.nn.initializers -    _classification_layer.weight\n","2020-11-09 17:00:53,732 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias\n","2020-11-09 17:00:53,732 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight\n","2020-11-09 17:00:53,732 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias\n","2020-11-09 17:00:53,732 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight\n","2020-11-09 17:00:53,732 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight\n","2020-11-09 17:00:53,732 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight\n","2020-11-09 17:00:53,732 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight\n","2020-11-09 17:00:53,732 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,732 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,732 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias\n","2020-11-09 17:00:53,733 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight\n","2020-11-09 17:00:53,733 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias\n","2020-11-09 17:00:53,733 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight\n","2020-11-09 17:00:53,733 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias\n","2020-11-09 17:00:53,733 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight\n","2020-11-09 17:00:53,733 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias\n","2020-11-09 17:00:53,733 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight\n","2020-11-09 17:00:53,733 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias\n","2020-11-09 17:00:53,733 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight\n","2020-11-09 17:00:53,733 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias\n","2020-11-09 17:00:53,733 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight\n","2020-11-09 17:00:53,733 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias\n","2020-11-09 17:00:53,733 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight\n","2020-11-09 17:00:53,733 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,733 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,734 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias\n","2020-11-09 17:00:53,734 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight\n","2020-11-09 17:00:53,734 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias\n","2020-11-09 17:00:53,734 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight\n","2020-11-09 17:00:53,734 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias\n","2020-11-09 17:00:53,734 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight\n","2020-11-09 17:00:53,734 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias\n","2020-11-09 17:00:53,734 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight\n","2020-11-09 17:00:53,734 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias\n","2020-11-09 17:00:53,734 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight\n","2020-11-09 17:00:53,734 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias\n","2020-11-09 17:00:53,734 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight\n","2020-11-09 17:00:53,734 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias\n","2020-11-09 17:00:53,734 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight\n","2020-11-09 17:00:53,735 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,735 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,735 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias\n","2020-11-09 17:00:53,735 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight\n","2020-11-09 17:00:53,735 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias\n","2020-11-09 17:00:53,735 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight\n","2020-11-09 17:00:53,735 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias\n","2020-11-09 17:00:53,735 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight\n","2020-11-09 17:00:53,735 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias\n","2020-11-09 17:00:53,735 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight\n","2020-11-09 17:00:53,735 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias\n","2020-11-09 17:00:53,735 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight\n","2020-11-09 17:00:53,735 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias\n","2020-11-09 17:00:53,735 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight\n","2020-11-09 17:00:53,735 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias\n","2020-11-09 17:00:53,736 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight\n","2020-11-09 17:00:53,736 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,736 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,736 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias\n","2020-11-09 17:00:53,736 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight\n","2020-11-09 17:00:53,736 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias\n","2020-11-09 17:00:53,736 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight\n","2020-11-09 17:00:53,736 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias\n","2020-11-09 17:00:53,736 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight\n","2020-11-09 17:00:53,736 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias\n","2020-11-09 17:00:53,736 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight\n","2020-11-09 17:00:53,736 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias\n","2020-11-09 17:00:53,736 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight\n","2020-11-09 17:00:53,736 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias\n","2020-11-09 17:00:53,737 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight\n","2020-11-09 17:00:53,737 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias\n","2020-11-09 17:00:53,737 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight\n","2020-11-09 17:00:53,737 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,737 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,737 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias\n","2020-11-09 17:00:53,737 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight\n","2020-11-09 17:00:53,737 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias\n","2020-11-09 17:00:53,737 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight\n","2020-11-09 17:00:53,737 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias\n","2020-11-09 17:00:53,737 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight\n","2020-11-09 17:00:53,737 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias\n","2020-11-09 17:00:53,737 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight\n","2020-11-09 17:00:53,737 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias\n","2020-11-09 17:00:53,737 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight\n","2020-11-09 17:00:53,738 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias\n","2020-11-09 17:00:53,738 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight\n","2020-11-09 17:00:53,738 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias\n","2020-11-09 17:00:53,738 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight\n","2020-11-09 17:00:53,738 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,738 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,738 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias\n","2020-11-09 17:00:53,738 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight\n","2020-11-09 17:00:53,738 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias\n","2020-11-09 17:00:53,738 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight\n","2020-11-09 17:00:53,738 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias\n","2020-11-09 17:00:53,738 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight\n","2020-11-09 17:00:53,738 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias\n","2020-11-09 17:00:53,738 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight\n","2020-11-09 17:00:53,739 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias\n","2020-11-09 17:00:53,739 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight\n","2020-11-09 17:00:53,739 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias\n","2020-11-09 17:00:53,739 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight\n","2020-11-09 17:00:53,739 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias\n","2020-11-09 17:00:53,739 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight\n","2020-11-09 17:00:53,739 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,803 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,803 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias\n","2020-11-09 17:00:53,803 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight\n","2020-11-09 17:00:53,803 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias\n","2020-11-09 17:00:53,803 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight\n","2020-11-09 17:00:53,803 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias\n","2020-11-09 17:00:53,804 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight\n","2020-11-09 17:00:53,804 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias\n","2020-11-09 17:00:53,804 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight\n","2020-11-09 17:00:53,804 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias\n","2020-11-09 17:00:53,804 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight\n","2020-11-09 17:00:53,804 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias\n","2020-11-09 17:00:53,804 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight\n","2020-11-09 17:00:53,804 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias\n","2020-11-09 17:00:53,804 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight\n","2020-11-09 17:00:53,804 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,804 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,804 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias\n","2020-11-09 17:00:53,804 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight\n","2020-11-09 17:00:53,805 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias\n","2020-11-09 17:00:53,805 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight\n","2020-11-09 17:00:53,805 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias\n","2020-11-09 17:00:53,805 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight\n","2020-11-09 17:00:53,805 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias\n","2020-11-09 17:00:53,805 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight\n","2020-11-09 17:00:53,805 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias\n","2020-11-09 17:00:53,805 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight\n","2020-11-09 17:00:53,805 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias\n","2020-11-09 17:00:53,805 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight\n","2020-11-09 17:00:53,805 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias\n","2020-11-09 17:00:53,805 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight\n","2020-11-09 17:00:53,806 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,806 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,806 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias\n","2020-11-09 17:00:53,806 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight\n","2020-11-09 17:00:53,806 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias\n","2020-11-09 17:00:53,806 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight\n","2020-11-09 17:00:53,806 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias\n","2020-11-09 17:00:53,806 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight\n","2020-11-09 17:00:53,806 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias\n","2020-11-09 17:00:53,806 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight\n","2020-11-09 17:00:53,806 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias\n","2020-11-09 17:00:53,806 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight\n","2020-11-09 17:00:53,807 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias\n","2020-11-09 17:00:53,807 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight\n","2020-11-09 17:00:53,807 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias\n","2020-11-09 17:00:53,807 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight\n","2020-11-09 17:00:53,807 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,807 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,807 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias\n","2020-11-09 17:00:53,807 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight\n","2020-11-09 17:00:53,807 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias\n","2020-11-09 17:00:53,807 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight\n","2020-11-09 17:00:53,807 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias\n","2020-11-09 17:00:53,807 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight\n","2020-11-09 17:00:53,807 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias\n","2020-11-09 17:00:53,808 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight\n","2020-11-09 17:00:53,808 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias\n","2020-11-09 17:00:53,808 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight\n","2020-11-09 17:00:53,808 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias\n","2020-11-09 17:00:53,808 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight\n","2020-11-09 17:00:53,808 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias\n","2020-11-09 17:00:53,808 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight\n","2020-11-09 17:00:53,808 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,808 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,808 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias\n","2020-11-09 17:00:53,808 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight\n","2020-11-09 17:00:53,808 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias\n","2020-11-09 17:00:53,809 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight\n","2020-11-09 17:00:53,809 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias\n","2020-11-09 17:00:53,809 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight\n","2020-11-09 17:00:53,809 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias\n","2020-11-09 17:00:53,809 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight\n","2020-11-09 17:00:53,809 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias\n","2020-11-09 17:00:53,809 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight\n","2020-11-09 17:00:53,809 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias\n","2020-11-09 17:00:53,809 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight\n","2020-11-09 17:00:53,809 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias\n","2020-11-09 17:00:53,809 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight\n","2020-11-09 17:00:53,809 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,809 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,810 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias\n","2020-11-09 17:00:53,810 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight\n","2020-11-09 17:00:53,810 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias\n","2020-11-09 17:00:53,810 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight\n","2020-11-09 17:00:53,810 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias\n","2020-11-09 17:00:53,810 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight\n","2020-11-09 17:00:53,810 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias\n","2020-11-09 17:00:53,810 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight\n","2020-11-09 17:00:53,810 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias\n","2020-11-09 17:00:53,810 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight\n","2020-11-09 17:00:53,810 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias\n","2020-11-09 17:00:53,810 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight\n","2020-11-09 17:00:53,810 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias\n","2020-11-09 17:00:53,811 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight\n","2020-11-09 17:00:53,811 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias\n","2020-11-09 17:00:53,811 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight\n","2020-11-09 17:00:53,813 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 8, 'sorting_keys': [['tokens', 'num_tokens']], 'type': 'bucket'} and extras set()\n","2020-11-09 17:00:53,813 - INFO - allennlp.common.params - iterator.type = bucket\n","2020-11-09 17:00:53,813 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 8, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()\n","2020-11-09 17:00:53,813 - INFO - allennlp.common.params - iterator.sorting_keys = [['tokens', 'num_tokens']]\n","2020-11-09 17:00:53,813 - INFO - allennlp.common.params - iterator.padding_noise = 0.1\n","2020-11-09 17:00:53,813 - INFO - allennlp.common.params - iterator.biggest_batch_first = False\n","2020-11-09 17:00:53,813 - INFO - allennlp.common.params - iterator.batch_size = 8\n","2020-11-09 17:00:53,813 - INFO - allennlp.common.params - iterator.instances_per_epoch = None\n","2020-11-09 17:00:53,813 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None\n","2020-11-09 17:00:53,813 - INFO - allennlp.common.params - iterator.cache_instances = False\n","2020-11-09 17:00:53,813 - INFO - allennlp.common.params - iterator.track_epoch = False\n","2020-11-09 17:00:53,814 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None\n","2020-11-09 17:00:53,814 - INFO - allennlp.common.params - iterator.skip_smaller_batches = False\n","2020-11-09 17:00:53,814 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'sorting_keys': [['tokens', 'num_tokens']], 'type': 'bucket'} and extras set()\n","2020-11-09 17:00:53,814 - INFO - allennlp.common.params - validation_iterator.type = bucket\n","2020-11-09 17:00:53,814 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 64, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()\n","2020-11-09 17:00:53,814 - INFO - allennlp.common.params - validation_iterator.sorting_keys = [['tokens', 'num_tokens']]\n","2020-11-09 17:00:53,814 - INFO - allennlp.common.params - validation_iterator.padding_noise = 0.1\n","2020-11-09 17:00:53,814 - INFO - allennlp.common.params - validation_iterator.biggest_batch_first = False\n","2020-11-09 17:00:53,814 - INFO - allennlp.common.params - validation_iterator.batch_size = 64\n","2020-11-09 17:00:53,814 - INFO - allennlp.common.params - validation_iterator.instances_per_epoch = None\n","2020-11-09 17:00:53,814 - INFO - allennlp.common.params - validation_iterator.max_instances_in_memory = None\n","2020-11-09 17:00:53,814 - INFO - allennlp.common.params - validation_iterator.cache_instances = False\n","2020-11-09 17:00:53,814 - INFO - allennlp.common.params - validation_iterator.track_epoch = False\n","2020-11-09 17:00:53,815 - INFO - allennlp.common.params - validation_iterator.maximum_samples_per_batch = None\n","2020-11-09 17:00:53,815 - INFO - allennlp.common.params - validation_iterator.skip_smaller_batches = False\n","2020-11-09 17:00:53,815 - INFO - allennlp.common.params - trainer.no_grad = ()\n","2020-11-09 17:00:53,818 - INFO - allennlp.training.trainer_pieces - Following parameters are Frozen  (without gradient):\n","2020-11-09 17:00:53,818 - INFO - allennlp.training.trainer_pieces - Following parameters are Tunable (with gradient):\n","2020-11-09 17:00:53,818 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight\n","2020-11-09 17:00:53,818 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight\n","2020-11-09 17:00:53,818 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight\n","2020-11-09 17:00:53,818 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight\n","2020-11-09 17:00:53,818 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias\n","2020-11-09 17:00:53,818 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight\n","2020-11-09 17:00:53,818 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias\n","2020-11-09 17:00:53,818 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight\n","2020-11-09 17:00:53,818 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias\n","2020-11-09 17:00:53,818 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight\n","2020-11-09 17:00:53,818 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias\n","2020-11-09 17:00:53,818 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight\n","2020-11-09 17:00:53,818 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias\n","2020-11-09 17:00:53,818 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,818 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,818 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight\n","2020-11-09 17:00:53,818 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias\n","2020-11-09 17:00:53,819 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias\n","2020-11-09 17:00:53,820 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight\n","2020-11-09 17:00:53,821 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias\n","2020-11-09 17:00:53,821 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight\n","2020-11-09 17:00:53,821 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias\n","2020-11-09 17:00:53,821 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight\n","2020-11-09 17:00:53,821 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias\n","2020-11-09 17:00:53,821 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight\n","2020-11-09 17:00:53,821 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias\n","2020-11-09 17:00:53,911 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight\n","2020-11-09 17:00:53,912 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias\n","2020-11-09 17:00:53,912 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,912 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,912 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight\n","2020-11-09 17:00:53,912 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias\n","2020-11-09 17:00:53,912 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight\n","2020-11-09 17:00:53,912 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias\n","2020-11-09 17:00:53,912 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight\n","2020-11-09 17:00:53,912 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias\n","2020-11-09 17:00:53,912 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight\n","2020-11-09 17:00:53,912 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias\n","2020-11-09 17:00:53,912 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight\n","2020-11-09 17:00:53,912 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias\n","2020-11-09 17:00:53,913 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight\n","2020-11-09 17:00:53,913 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias\n","2020-11-09 17:00:53,913 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight\n","2020-11-09 17:00:53,913 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias\n","2020-11-09 17:00:53,913 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,913 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,913 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight\n","2020-11-09 17:00:53,913 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias\n","2020-11-09 17:00:53,913 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight\n","2020-11-09 17:00:53,913 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias\n","2020-11-09 17:00:53,913 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight\n","2020-11-09 17:00:53,913 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias\n","2020-11-09 17:00:53,913 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight\n","2020-11-09 17:00:53,914 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias\n","2020-11-09 17:00:53,914 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight\n","2020-11-09 17:00:53,914 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias\n","2020-11-09 17:00:53,914 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight\n","2020-11-09 17:00:53,914 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias\n","2020-11-09 17:00:53,914 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight\n","2020-11-09 17:00:53,914 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias\n","2020-11-09 17:00:53,914 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,914 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,914 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight\n","2020-11-09 17:00:53,914 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias\n","2020-11-09 17:00:53,914 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight\n","2020-11-09 17:00:53,914 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias\n","2020-11-09 17:00:53,915 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight\n","2020-11-09 17:00:53,915 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias\n","2020-11-09 17:00:53,915 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight\n","2020-11-09 17:00:53,915 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias\n","2020-11-09 17:00:53,915 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight\n","2020-11-09 17:00:53,915 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias\n","2020-11-09 17:00:53,915 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight\n","2020-11-09 17:00:53,915 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias\n","2020-11-09 17:00:53,915 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight\n","2020-11-09 17:00:53,915 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias\n","2020-11-09 17:00:53,915 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,915 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,915 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight\n","2020-11-09 17:00:53,916 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias\n","2020-11-09 17:00:53,916 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight\n","2020-11-09 17:00:53,916 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias\n","2020-11-09 17:00:53,916 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight\n","2020-11-09 17:00:53,916 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias\n","2020-11-09 17:00:53,916 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight\n","2020-11-09 17:00:53,916 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias\n","2020-11-09 17:00:53,916 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight\n","2020-11-09 17:00:53,916 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias\n","2020-11-09 17:00:53,916 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight\n","2020-11-09 17:00:53,916 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias\n","2020-11-09 17:00:53,917 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight\n","2020-11-09 17:00:53,917 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias\n","2020-11-09 17:00:53,917 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,917 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,917 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight\n","2020-11-09 17:00:53,917 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias\n","2020-11-09 17:00:53,917 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight\n","2020-11-09 17:00:53,917 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias\n","2020-11-09 17:00:53,917 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight\n","2020-11-09 17:00:53,917 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias\n","2020-11-09 17:00:53,917 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight\n","2020-11-09 17:00:53,917 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias\n","2020-11-09 17:00:53,917 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight\n","2020-11-09 17:00:53,917 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias\n","2020-11-09 17:00:53,917 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight\n","2020-11-09 17:00:53,917 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias\n","2020-11-09 17:00:53,917 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight\n","2020-11-09 17:00:53,917 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias\n","2020-11-09 17:00:53,917 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,917 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,917 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight\n","2020-11-09 17:00:53,918 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias\n","2020-11-09 17:00:53,919 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight\n","2020-11-09 17:00:53,919 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias\n","2020-11-09 17:00:53,919 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight\n","2020-11-09 17:00:53,919 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias\n","2020-11-09 17:00:53,919 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n","2020-11-09 17:00:53,919 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n","2020-11-09 17:00:53,919 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight\n","2020-11-09 17:00:53,919 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias\n","2020-11-09 17:00:53,919 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight\n","2020-11-09 17:00:53,919 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias\n","2020-11-09 17:00:53,919 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight\n","2020-11-09 17:00:53,919 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias\n","2020-11-09 17:00:53,919 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight\n","2020-11-09 17:00:53,919 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias\n","2020-11-09 17:00:53,919 - INFO - allennlp.training.trainer_pieces - _feedforward_layer._linear_layers.0.weight\n","2020-11-09 17:00:53,919 - INFO - allennlp.training.trainer_pieces - _feedforward_layer._linear_layers.0.bias\n","2020-11-09 17:00:53,920 - INFO - allennlp.training.trainer_pieces - _classification_layer.weight\n","2020-11-09 17:00:53,920 - INFO - allennlp.training.trainer_pieces - _classification_layer.bias\n","2020-11-09 17:00:53,920 - INFO - allennlp.common.params - trainer.patience = 3\n","2020-11-09 17:00:53,920 - INFO - allennlp.common.params - trainer.validation_metric = +f1\n","2020-11-09 17:00:53,920 - INFO - allennlp.common.params - trainer.shuffle = True\n","2020-11-09 17:00:53,920 - INFO - allennlp.common.params - trainer.num_epochs = 10\n","2020-11-09 17:00:53,920 - INFO - allennlp.common.params - trainer.cuda_device = 0\n","2020-11-09 17:00:53,920 - INFO - allennlp.common.params - trainer.grad_norm = None\n","2020-11-09 17:00:53,920 - INFO - allennlp.common.params - trainer.grad_clipping = None\n","2020-11-09 17:00:53,920 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None\n","2020-11-09 17:00:53,920 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n","2020-11-09 17:00:53,920 - INFO - allennlp.common.params - trainer.gradient_accumulation_batch_size = 8\n","2020-11-09 17:00:58,811 - INFO - allennlp.common.params - trainer.optimizer.type = bert_adam\n","2020-11-09 17:00:58,811 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n","2020-11-09 17:00:58,812 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n","2020-11-09 17:00:58,812 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups.0.1.weight_decay = 0\n","2020-11-09 17:00:58,813 - INFO - allennlp.training.optimizers - Done constructing parameter groups.\n","2020-11-09 17:00:58,813 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias', '_classification_layer.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_feedforward_layer._linear_layers.0.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias'], {'weight_decay': 0}\n","2020-11-09 17:00:58,835 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight', '_classification_layer.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight', '_feedforward_layer._linear_layers.0.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight'], {}\n","2020-11-09 17:00:58,836 - WARNING - allennlp.training.optimizers - When constructing parameter groups,  layer_norm.weight not match any parameter name\n","2020-11-09 17:00:58,836 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125237762\n","2020-11-09 17:00:58,837 - INFO - allennlp.common.params - trainer.optimizer.infer_type_and_cast = True\n","2020-11-09 17:00:58,837 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n","2020-11-09 17:00:58,837 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n","2020-11-09 17:00:58,837 - INFO - allennlp.common.params - trainer.optimizer.b1 = 0.9\n","2020-11-09 17:00:58,838 - INFO - allennlp.common.params - trainer.optimizer.b2 = 0.98\n","2020-11-09 17:00:58,838 - INFO - allennlp.common.params - trainer.optimizer.e = 1e-06\n","2020-11-09 17:00:58,838 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05\n","2020-11-09 17:00:58,838 - INFO - allennlp.common.params - trainer.optimizer.max_grad_norm = 1\n","2020-11-09 17:00:58,838 - INFO - allennlp.common.params - trainer.optimizer.schedule = warmup_linear\n","2020-11-09 17:00:58,838 - INFO - allennlp.common.params - trainer.optimizer.t_total = -1\n","2020-11-09 17:00:58,838 - INFO - allennlp.common.params - trainer.optimizer.warmup = 0.06\n","2020-11-09 17:00:58,838 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1\n","2020-11-09 17:00:58,838 - WARNING - pytorch_pretrained_bert.optimization - t_total value of -1 results in schedule not being applied\n","2020-11-09 17:00:58,840 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 0\n","2020-11-09 17:00:58,840 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None\n","2020-11-09 17:00:58,840 - INFO - allennlp.common.params - trainer.model_save_interval = None\n","2020-11-09 17:00:58,840 - INFO - allennlp.common.params - trainer.summary_interval = 100\n","2020-11-09 17:00:58,840 - INFO - allennlp.common.params - trainer.histogram_interval = None\n","2020-11-09 17:00:58,840 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True\n","2020-11-09 17:00:58,840 - INFO - allennlp.common.params - trainer.should_log_learning_rate = False\n","2020-11-09 17:00:58,840 - INFO - allennlp.common.params - trainer.log_batch_size_period = None\n","2020-11-09 17:00:58,842 - INFO - allennlp.training.trainer - Beginning training.\n","2020-11-09 17:00:58,843 - INFO - allennlp.training.trainer - Epoch 0/9\n","2020-11-09 17:00:58,843 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8384.1\n","2020-11-09 17:00:59,004 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1769\n","2020-11-09 17:00:59,007 - INFO - allennlp.training.trainer - Training\n","  0%|          | 0/14407 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","f1: 0.4771, accuracy: 0.8525, loss: 0.4201 ||: 100%|##########| 14407/14407 [51:08<00:00,  4.70it/s]\n","2020-11-09 17:52:07,472 - INFO - allennlp.training.trainer - Validating\n","f1: 0.4685, accuracy: 0.8536, loss: 0.4131 ||: 100%|##########| 79/79 [00:20<00:00,  3.93it/s]\n","2020-11-09 17:52:27,572 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 17:52:27,584 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  1769.000  |       N/A\n","2020-11-09 17:52:27,585 - INFO - allennlp.training.tensorboard_writer - loss            |     0.420  |     0.413\n","2020-11-09 17:52:27,585 - INFO - allennlp.training.tensorboard_writer - f1              |     0.477  |     0.469\n","2020-11-09 17:52:27,587 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.852  |     0.854\n","2020-11-09 17:52:27,587 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  8384.100  |       N/A\n","2020-11-09 17:52:33,109 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/amazon_nas_04/best.th'.\n","2020-11-09 17:52:34,997 - INFO - allennlp.training.trainer - Epoch duration: 0:51:36.154555\n","2020-11-09 17:52:34,999 - INFO - allennlp.training.trainer - Estimated training time remaining: 7:44:25\n","2020-11-09 17:52:34,999 - INFO - allennlp.training.trainer - Epoch 1/9\n","2020-11-09 17:52:34,999 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8825.3\n","2020-11-09 17:52:35,162 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 6161\n","2020-11-09 17:52:35,165 - INFO - allennlp.training.trainer - Training\n","f1: 0.4653, accuracy: 0.8533, loss: 0.4242 ||: 100%|##########| 14407/14407 [51:00<00:00,  4.71it/s]\n","2020-11-09 18:43:35,397 - INFO - allennlp.training.trainer - Validating\n","f1: 0.4605, accuracy: 0.8534, loss: 0.4265 ||: 100%|##########| 79/79 [00:18<00:00,  4.22it/s]\n","2020-11-09 18:43:54,116 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 18:43:54,117 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  6161.000  |       N/A\n","2020-11-09 18:43:54,117 - INFO - allennlp.training.tensorboard_writer - loss            |     0.424  |     0.426\n","2020-11-09 18:43:54,118 - INFO - allennlp.training.tensorboard_writer - f1              |     0.465  |     0.460\n","2020-11-09 18:43:54,118 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.853  |     0.853\n","2020-11-09 18:43:54,119 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  8825.300  |       N/A\n","2020-11-09 18:44:00,152 - INFO - allennlp.training.trainer - Epoch duration: 0:51:25.152761\n","2020-11-09 18:44:00,152 - INFO - allennlp.training.trainer - Estimated training time remaining: 6:52:05\n","2020-11-09 18:44:00,153 - INFO - allennlp.training.trainer - Epoch 2/9\n","2020-11-09 18:44:00,153 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8828.616\n","2020-11-09 18:44:00,313 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 12005\n","2020-11-09 18:44:00,316 - INFO - allennlp.training.trainer - Training\n","f1: 0.4609, accuracy: 0.8533, loss: 0.4224 ||: 100%|##########| 14407/14407 [50:48<00:00,  4.73it/s]\n","2020-11-09 19:34:48,587 - INFO - allennlp.training.trainer - Validating\n","f1: 0.4605, accuracy: 0.8534, loss: 0.4184 ||: 100%|##########| 79/79 [00:18<00:00,  4.22it/s]\n","2020-11-09 19:35:07,298 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 19:35:07,298 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  12005.000  |       N/A\n","2020-11-09 19:35:07,299 - INFO - allennlp.training.tensorboard_writer - loss            |     0.422  |     0.418\n","2020-11-09 19:35:07,299 - INFO - allennlp.training.tensorboard_writer - f1              |     0.461  |     0.460\n","2020-11-09 19:35:07,300 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.853  |     0.853\n","2020-11-09 19:35:07,300 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  8828.616  |       N/A\n","2020-11-09 19:35:13,285 - INFO - allennlp.training.trainer - Epoch duration: 0:51:13.132640\n","2020-11-09 19:35:13,285 - INFO - allennlp.training.trainer - Estimated training time remaining: 5:59:53\n","2020-11-09 19:35:13,286 - INFO - allennlp.training.trainer - Epoch 3/9\n","2020-11-09 19:35:13,286 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8828.628\n","2020-11-09 19:35:13,448 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 12005\n","2020-11-09 19:35:13,451 - INFO - allennlp.training.trainer - Training\n","f1: 0.4648, accuracy: 0.8529, loss: 0.4201 ||: 100%|##########| 14407/14407 [50:48<00:00,  4.73it/s]\n","2020-11-09 20:26:01,531 - INFO - allennlp.training.trainer - Validating\n","f1: 0.4605, accuracy: 0.8534, loss: 0.4411 ||: 100%|##########| 79/79 [00:18<00:00,  4.22it/s]\n","2020-11-09 20:26:20,255 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.\n","2020-11-09 20:26:20,256 - INFO - allennlp.training.checkpointer - loading best weights\n","2020-11-09 20:26:20,635 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.\n","2020-11-09 20:26:20,636 - INFO - allennlp.training.util - Iterating over dataset\n","f1: 0.47, accuracy: 0.85, loss: 0.42 ||: 100%|##########| 391/391 [01:35<00:00,  4.07it/s]\n","2020-11-09 20:27:56,598 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/amazon_nas_04/model.tar.gz\n","2020-11-09 20:28:24,438 - INFO - allennlp.common.util - Metrics: {\n","  \"best_epoch\": 0,\n","  \"peak_cpu_memory_MB\": 8828.628,\n","  \"peak_gpu_0_memory_MB\": 12005,\n","  \"training_duration\": \"2:34:08.458716\",\n","  \"training_start_epoch\": 0,\n","  \"training_epochs\": 2,\n","  \"epoch\": 2,\n","  \"training_f1\": 0.46087978724972345,\n","  \"training_accuracy\": 0.8532594077274818,\n","  \"training_loss\": 0.4224434301195588,\n","  \"training_cpu_memory_MB\": 8828.616,\n","  \"training_gpu_0_memory_MB\": 12005,\n","  \"validation_f1\": 0.46045106649398804,\n","  \"validation_accuracy\": 0.8534,\n","  \"validation_loss\": 0.4183606588387791,\n","  \"best_validation_f1\": 0.4685225849971175,\n","  \"best_validation_accuracy\": 0.8536,\n","  \"best_validation_loss\": 0.41313217184211637,\n","  \"test_f1\": 0.47174352686852217,\n","  \"test_accuracy\": 0.85384,\n","  \"test_loss\": 0.41533657222452675\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HR9zCpBZu8DC","executionInfo":{"status":"ok","timestamp":1604954144227,"user_tz":300,"elapsed":5819,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"be824d86-3dff-4fc0-b7cf-bc2468465bb8","colab":{"base_uri":"https://localhost:8080/"}},"source":["!curl -Lo train.jsonl https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/chemprot/train.jsonl\n","!curl -Lo dev.jsonl https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/chemprot/dev.jsonl\n","!curl -Lo test.jsonl https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/chemprot/test.jsonl"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 1094k  100 1094k    0     0   623k      0  0:00:01  0:00:01 --:--:--  623k\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  662k  100  662k    0     0   428k      0  0:00:01  0:00:01 --:--:--  428k\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  937k  100  937k    0     0   598k      0  0:00:01  0:00:01 --:--:--  598k\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gEJeVcNruKbk"},"source":["import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IX-VI2EoupmG"},"source":["import pandas as pd\n","import json\n","data = []\n","with open(\"train.jsonl\", 'r', encoding='utf-8') as f:\n","    for line in f:\n","       data.append(json.loads(line))\n","df = pd.DataFrame(data)\n","df.text.to_csv(\"train.txt\", header=False, index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pOP3hC5huvxX"},"source":["df = pd.DataFrame(data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RzDFxkkGu1AT"},"source":["df.text.to_csv(\"train.txt\", header=False, index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8p-k9gvuu_iz","executionInfo":{"status":"ok","timestamp":1604954721206,"user_tz":300,"elapsed":764,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"1f1ece1b-77d4-44f6-e3a4-cc17ad222a76","colab":{"base_uri":"https://localhost:8080/"}},"source":["!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["ADAPTIVE_PRETRAINING.md  environments\t  scatter.pdf\t   train.jsonl\n","DATA_SELECTION.md\t environment.yml  scripts\t   train.txt\n","dev.jsonl\t\t mlm_study\t  search_space\n","dev.txt\t\t\t model_logs\t  test.jsonl\n","dont_stop_pretraining\t README.md\t  training_config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3LyjhuTpwPpc"},"source":["data = []\n","with open(\"dev.jsonl\", 'r', encoding='utf-8') as f:\n","    for line in f:\n","       data.append(json.loads(line))\n","df = pd.DataFrame(data)\n","df.text.to_csv(\"dev.txt\", header=False, index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fsK2n5ervAd7","executionInfo":{"status":"ok","timestamp":1604954535472,"user_tz":300,"elapsed":4086,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"2241a184-3ba3-4228-f26e-53ad27f91cd8","colab":{"base_uri":"https://localhost:8080/"}},"source":["!python -m scripts.run_language_modeling --train_data_file train.txt --line_by_line \\\n","                                        --output_dir roberta-tapt \\\n","                                        --model_type roberta-base \\\n","                                        --tokenizer_name roberta-base \\\n","                                        --mlm \\\n","                                        --per_gpu_train_batch_size 8 \\\n","                                        --gradient_accumulation_steps 8  \\\n","                                        --model_name_or_path roberta-base \\\n","                                        --eval_data_file ./dev.sample \\\n","                                        --do_eval \\\n","                                        --evaluate_during_training  \\\n","                                        --do_train \\\n","                                        --num_train_epochs 100  \\\n","                                        --learning_rate 0.0001 \\\n","                                        --logging_steps 50"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-11-09 20:42:12.841614: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n","    \"__main__\", mod_spec)\n","  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n","    exec(code, run_globals)\n","  File \"/content/dont-stop-pretraining/scripts/run_language_modeling.py\", line 43, in <module>\n","    from transformers import (\n","ImportError: cannot import name 'MODEL_WITH_LM_HEAD_MAPPING'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qH_spEyw1W9c","executionInfo":{"status":"ok","timestamp":1604956049501,"user_tz":300,"elapsed":10248,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"24c25723-3087-4a9e-aeac-e4e0abf1a4a7","colab":{"base_uri":"https://localhost:8080/"}},"source":["!git clone https://github.com/huggingface/transformers.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'transformers'...\n","remote: Enumerating objects: 86, done.\u001b[K\n","remote: Counting objects: 100% (86/86), done.\u001b[K\n","remote: Compressing objects: 100% (74/74), done.\u001b[K\n","remote: Total 50369 (delta 33), reused 28 (delta 5), pack-reused 50283\u001b[K\n","Receiving objects: 100% (50369/50369), 37.32 MiB | 6.33 MiB/s, done.\n","Resolving deltas: 100% (35125/35125), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"udHFn_iE1dqq","executionInfo":{"status":"ok","timestamp":1604956828374,"user_tz":300,"elapsed":497,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"a6b15b50-6569-43d9-b27b-6d54d720a93e","colab":{"base_uri":"https://localhost:8080/"}},"source":["%cd ../../.."],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/dont-stop-pretraining\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qv3BWmvY3umU","executionInfo":{"status":"ok","timestamp":1604956776113,"user_tz":300,"elapsed":7542,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"26d908b1-6124-4b02-d4a6-010b3ab94a6d","colab":{"base_uri":"https://localhost:8080/"}},"source":["!git clone https://github.com/huggingface/datasets.git\n","!git clone https://github.com/huggingface/tokenizers.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'datasets'...\n","remote: Enumerating objects: 56, done.\u001b[K\n","remote: Counting objects: 100% (56/56), done.\u001b[K\n","remote: Compressing objects: 100% (40/40), done.\u001b[K\n","remote: Total 14381 (delta 21), reused 32 (delta 8), pack-reused 14325\u001b[K\n","Receiving objects: 100% (14381/14381), 27.80 MiB | 12.30 MiB/s, done.\n","Resolving deltas: 100% (6280/6280), done.\n","Cloning into 'tokenizers'...\n","remote: Enumerating objects: 633, done.\u001b[K\n","remote: Counting objects: 100% (633/633), done.\u001b[K\n","remote: Compressing objects: 100% (485/485), done.\u001b[K\n","remote: Total 12308 (delta 338), reused 295 (delta 130), pack-reused 11675\u001b[K\n","Receiving objects: 100% (12308/12308), 4.01 MiB | 4.05 MiB/s, done.\n","Resolving deltas: 100% (7980/7980), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3zoi6Rpz4B9Z","executionInfo":{"status":"ok","timestamp":1604956750697,"user_tz":300,"elapsed":244,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"2943c925-8731-4101-f3b2-df92920dcecc","colab":{"base_uri":"https://localhost:8080/"}},"source":["%cd transformers/examples/language-modeling"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/dont-stop-pretraining/transformers/examples/language-modeling\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hU3jVxg3vZAQ","executionInfo":{"status":"ok","timestamp":1604956779550,"user_tz":300,"elapsed":631,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"a079a979-4a24-4a9f-9277-cd2d6996ae55","colab":{"base_uri":"https://localhost:8080/"}},"source":["!python -m run_mlm.py --model_name_or_path roberta-base --line_by_line --model_type roberta-base --tokenizer_name roberta-base --per_gpu_train_batch_size 8 --gradient_accumulation_steps 8 --num_train_epochs 100 --learning_rate 0.0001 --logging_steps 50 --train_file train.txt --validation_file dev.txt --do_train --do_eval --output_dir /tmp/test-mlm"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/lib/python3.6/runpy.py\", line 183, in _run_module_as_main\n","    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n","  File \"/usr/lib/python3.6/runpy.py\", line 109, in _get_module_details\n","    __import__(pkg_name)\n","  File \"/content/dont-stop-pretraining/transformers/examples/language-modeling/run_mlm.py\", line 30, in <module>\n","    from datasets import load_dataset\n","ImportError: cannot import name 'load_dataset'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jytpdU5g4eZw","executionInfo":{"status":"ok","timestamp":1604956844749,"user_tz":300,"elapsed":886,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"818b3964-fc06-4f8c-9437-f638e9708830","colab":{"base_uri":"https://localhost:8080/"}},"source":["!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["ADAPTIVE_PRETRAINING.md  dont_stop_pretraining\tREADME.md     tokenizers\n","DATA_SELECTION.md\t environments\t\tscatter.pdf   training_config\n","datasets\t\t environment.yml\tscripts       train.jsonl\n","dev.jsonl\t\t mlm_study\t\tsearch_space  train.txt\n","dev.txt\t\t\t model_logs\t\ttest.jsonl    transformers\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sM0s3rMzwhMt","executionInfo":{"status":"ok","timestamp":1604957103513,"user_tz":300,"elapsed":3805,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"1151e242-18b0-4d9c-c1cf-aa4898d00d67","colab":{"base_uri":"https://localhost:8080/"}},"source":["!python -m scripts.run_language_modeling \\\n","      --train_data_file train.txt \\\n","      --line_by_line  \\\n","      --output_dir roberta-tapt \\\n","      --model_type roberta-base \\\n","      --tokenizer_name roberta-base \\\n","       --mlm --per_gpu_train_batch_size 8 \\\n","       --gradient_accumulation_steps 8  \\\n","       --model_name_or_path roberta-base \\\n","       --eval_data_file dev.txt \\\n","       --do_eval \\\n","       --evaluate_during_training \\\n","       --do_train \\\n","       --num_train_epochs 100 \\\n","       --learning_rate 0.0001 \\\n","       --logging_steps 50"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-11-09 21:25:01.190843: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n","    \"__main__\", mod_spec)\n","  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n","    exec(code, run_globals)\n","  File \"/content/dont-stop-pretraining/scripts/run_language_modeling.py\", line 43, in <module>\n","    from transformers import (\n","ImportError: cannot import name 'MODEL_WITH_LM_HEAD_MAPPING'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E_z0zCRw4mL1","executionInfo":{"status":"error","timestamp":1604957248630,"user_tz":300,"elapsed":2546,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"ca2bb0a0-c9d1-4291-be02-be8f246f6bd4","colab":{"base_uri":"https://localhost:8080/","height":296}},"source":["from transformers import MODEL_WITH_LM_HEAD_MAPPING"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-57-664136e71363>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMODEL_WITH_LM_HEAD_MAPPING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mImportError\u001b[0m: cannot import name 'MODEL_WITH_LM_HEAD_MAPPING'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"bUSyOwNE6BBx"},"source":[""],"execution_count":null,"outputs":[]}]}