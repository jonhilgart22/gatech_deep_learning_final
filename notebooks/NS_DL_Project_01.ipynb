{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL_Project_01.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyP7czBiebYP6oI+mwWEl8DN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"-NZk5BbCV9_x","executionInfo":{"status":"ok","timestamp":1604865103753,"user_tz":300,"elapsed":134022,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"2b00891b-12f3-42e2-b391-418784f22f0b","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install git+https://github.com/kernelmachine/allennlp.git@4ae123d2c3bfb1ea3ce7362cb6c5bca3d094ffa7\n","!pip install transformers==2.4.1\n","!pip install pytorch-transformers==1.2.0\n","!git clone https://github.com/allenai/dont-stop-pretraining"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/kernelmachine/allennlp.git@4ae123d2c3bfb1ea3ce7362cb6c5bca3d094ffa7\n","  Cloning https://github.com/kernelmachine/allennlp.git (to revision 4ae123d2c3bfb1ea3ce7362cb6c5bca3d094ffa7) to /tmp/pip-req-build-baipshty\n","  Running command git clone -q https://github.com/kernelmachine/allennlp.git /tmp/pip-req-build-baipshty\n","  Running command git checkout -q 4ae123d2c3bfb1ea3ce7362cb6c5bca3d094ffa7\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (3.2.2)\n","Collecting tensorboardX>=1.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n","\u001b[K     |████████████████████████████████| 317kB 8.2MB/s \n","\u001b[?25hCollecting jsonpickle\n","  Downloading https://files.pythonhosted.org/packages/af/ca/4fee219cc4113a5635e348ad951cf8a2e47fed2e3342312493f5b73d0007/jsonpickle-1.4.1-py2.py3-none-any.whl\n","Collecting numpydoc>=0.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/1d/9e398c53d6ae27d5ab312ddc16a9ffe1bee0dfdf1d6ec88c40b0ca97582e/numpydoc-1.1.0-py3-none-any.whl (47kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.7MB/s \n","\u001b[?25hCollecting parsimonious>=0.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/fc/067a3f89869a41009e1a7cdfb14725f8ddd246f30f63c645e8ef8a1c56f4/parsimonious-0.8.1.tar.gz (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.7MB/s \n","\u001b[?25hCollecting boto3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/54/099a2ea5d4b2d5931a26f280a7585f613b1fafaac9189e489a9e25004a01/boto3-1.16.13-py2.py3-none-any.whl (129kB)\n","\u001b[K     |████████████████████████████████| 133kB 16.2MB/s \n","\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (2018.9)\n","Requirement already satisfied: sqlparse>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (0.4.1)\n","Collecting responses>=0.7\n","  Downloading https://files.pythonhosted.org/packages/c1/04/8a5258cfd851c9c89ae5c12c6952c05d42ca8c0788b999806e0c78d06c54/responses-0.12.0-py2.py3-none-any.whl\n","Collecting conllu==1.3.1\n","  Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (1.18.5)\n","Collecting pytorch-transformers==1.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/89/ad0d6bb932d0a51793eaabcf1617a36ff530dc9ab9e38f765a35dc293306/pytorch_transformers-1.1.0-py3-none-any.whl (158kB)\n","\u001b[K     |████████████████████████████████| 163kB 19.5MB/s \n","\u001b[?25hCollecting overrides\n","  Downloading https://files.pythonhosted.org/packages/ff/b1/10f69c00947518e6676bbd43e739733048de64b8dd998e9c2d5a71f44c5d/overrides-3.1.0.tar.gz\n","Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (3.6.4)\n","Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (0.5.3)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (3.2.5)\n","Collecting word2number>=1.1\n","  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n","Collecting jsonnet>=0.10.0; sys_platform != \"win32\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/70/ed1ba808a87d896b9f4d25400dda54e089ca7a97e87cee620b3744997c89/jsonnet-0.16.0.tar.gz (256kB)\n","\u001b[K     |████████████████████████████████| 266kB 19.1MB/s \n","\u001b[?25hCollecting unidecode\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n","\u001b[K     |████████████████████████████████| 245kB 23.8MB/s \n","\u001b[?25hCollecting ftfy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/e2/3b51c53dffb1e52d9210ebc01f1fb9f2f6eba9b3201fa971fd3946643c71/ftfy-5.8.tar.gz (64kB)\n","\u001b[K     |████████████████████████████████| 71kB 9.2MB/s \n","\u001b[?25hRequirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (1.1.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (1.4.1)\n","Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (2.23.0)\n","Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (4.41.1)\n","Collecting spacy<2.2,>=2.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/5b/e07dd3bf104237bce4b398558b104c8e500333d6f30eabe3fa9685356b7d/spacy-2.1.9-cp36-cp36m-manylinux1_x86_64.whl (30.8MB)\n","\u001b[K     |████████████████████████████████| 30.9MB 107kB/s \n","\u001b[?25hCollecting gevent>=1.3.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/92/b80b922f08f222faca53c8d278e2e612192bc74b0e1f0db2f80a6ee46982/gevent-20.9.0-cp36-cp36m-manylinux2010_x86_64.whl (5.3MB)\n","\u001b[K     |████████████████████████████████| 5.3MB 63.9MB/s \n","\u001b[?25hCollecting flask-cors>=3.0.7\n","  Downloading https://files.pythonhosted.org/packages/69/7f/d0aeaaafb5c3c76c8d2141dbe2d4f6dca5d6c31872d4e5349768c1958abc/Flask_Cors-3.0.9-py2.py3-none-any.whl\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (0.22.2.post1)\n","Collecting pytorch-pretrained-bert>=0.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\u001b[K     |████████████████████████████████| 133kB 64.8MB/s \n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (2.10.0)\n","Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from allennlp===0.9.1-unreleased) (1.7.0+cu101)\n","Collecting flaky\n","  Downloading https://files.pythonhosted.org/packages/43/0e/2f50064e327f41a1eb811df089f813036e19a64b95e33f8e9e0b96c2447e/flaky-3.7.0-py2.py3-none-any.whl\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp===0.9.1-unreleased) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp===0.9.1-unreleased) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp===0.9.1-unreleased) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp===0.9.1-unreleased) (1.3.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp===0.9.1-unreleased) (1.15.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp===0.9.1-unreleased) (3.12.4)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonpickle->allennlp===0.9.1-unreleased) (2.0.0)\n","Requirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (1.8.5)\n","Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (2.11.2)\n","Collecting s3transfer<0.4.0,>=0.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n","\u001b[K     |████████████████████████████████| 71kB 9.6MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n","Collecting botocore<1.20.0,>=1.19.13\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/40/b5e681d80dc46bafd0dc2e55266190cc432dfd5b72b9e7e1c5743aa6c362/botocore-1.19.13-py2.py3-none-any.whl (6.7MB)\n","\u001b[K     |████████████████████████████████| 6.7MB 57.6MB/s \n","\u001b[?25hCollecting urllib3>=1.25.10\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/aa/4ef5aa67a9a62505db124a5cb5262332d1d4153462eb8fd89c9fa41e5d92/urllib3-1.25.11-py2.py3-none-any.whl (127kB)\n","\u001b[K     |████████████████████████████████| 133kB 50.5MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.1.0->allennlp===0.9.1-unreleased) (2019.12.20)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 55.7MB/s \n","\u001b[?25hRequirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp===0.9.1-unreleased) (8.6.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp===0.9.1-unreleased) (1.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp===0.9.1-unreleased) (50.3.2)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp===0.9.1-unreleased) (20.2.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp===0.9.1-unreleased) (0.7.1)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp===0.9.1-unreleased) (1.9.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->allennlp===0.9.1-unreleased) (0.2.5)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp===0.9.1-unreleased) (7.1.2)\n","Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp===0.9.1-unreleased) (1.0.1)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp===0.9.1-unreleased) (1.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp===0.9.1-unreleased) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp===0.9.1-unreleased) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp===0.9.1-unreleased) (2.10)\n","Collecting preshed<2.1.0,>=2.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/93/f222fb957764a283203525ef20e62008675fd0a14ffff8cc1b1490147c63/preshed-2.0.1-cp36-cp36m-manylinux1_x86_64.whl (83kB)\n","\u001b[K     |████████████████████████████████| 92kB 13.4MB/s \n","\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp===0.9.1-unreleased) (0.8.0)\n","Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp===0.9.1-unreleased) (1.0.2)\n","Collecting plac<1.0.0,>=0.9.6\n","  Downloading https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp===0.9.1-unreleased) (2.0.4)\n","Collecting blis<0.3.0,>=0.2.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/46/b1d0bb71d308e820ed30316c5f0a017cb5ef5f4324bcbc7da3cf9d3b075c/blis-0.2.4-cp36-cp36m-manylinux1_x86_64.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 53.3MB/s \n","\u001b[?25hCollecting thinc<7.1.0,>=7.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/a5/9ace20422e7bb1bdcad31832ea85c52a09900cd4a7ce711246bfb92206ba/thinc-7.0.8-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 50.0MB/s \n","\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp===0.9.1-unreleased) (1.0.3)\n","Collecting zope.event\n","  Downloading https://files.pythonhosted.org/packages/9e/85/b45408c64f3b888976f1d5b37eed8d746b8d5729a66a49ec846fda27d371/zope.event-4.5.0-py2.py3-none-any.whl\n","Collecting zope.interface\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/b0/da8afd9b3bd50c7665ecdac062f182982af1173c9081f9af7261091c5588/zope.interface-5.2.0-cp36-cp36m-manylinux2010_x86_64.whl (236kB)\n","\u001b[K     |████████████████████████████████| 245kB 64.0MB/s \n","\u001b[?25hCollecting greenlet>=0.4.17; platform_python_implementation == \"CPython\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d0/532e160c777b42f6f393f9de8c88abb8af6c892037c55e4d3a8a211324dd/greenlet-0.4.17-cp36-cp36m-manylinux1_x86_64.whl (44kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.5MB/s \n","\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp===0.9.1-unreleased) (0.17.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->allennlp===0.9.1-unreleased) (3.7.4.3)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->allennlp===0.9.1-unreleased) (0.7)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->allennlp===0.9.1-unreleased) (0.16.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonpickle->allennlp===0.9.1-unreleased) (3.4.0)\n","Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (0.16)\n","Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (2.6.1)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (0.7.12)\n","Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (1.2.4)\n","Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (2.8.0)\n","Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (2.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (20.4)\n","Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (1.2.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (1.1.1)\n","Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.6/dist-packages (from sphinxcontrib-websupport->sphinx>=1.6.5->numpydoc>=0.8.0->allennlp===0.9.1-unreleased) (1.1.4)\n","Building wheels for collected packages: allennlp\n","  Building wheel for allennlp (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for allennlp: filename=allennlp-0.9.1_unreleased-cp36-none-any.whl size=7535392 sha256=19b1cb1d201a7891f7c7fccdadfb5d2cc18bfbd289bb27fbfb23ecfbced7b24c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-dlekyq6a/wheels/16/b3/9b/fceece1cbc3a6ac0c759db090cb239c3f4cba5bb369bb933c3\n","Successfully built allennlp\n","Building wheels for collected packages: parsimonious, overrides, word2number, jsonnet, ftfy\n","  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for parsimonious: filename=parsimonious-0.8.1-cp36-none-any.whl size=42709 sha256=b14f3cb4aef821f1b0b5faee841b2b9b8dc25e3c4cb533d38c5a7665b7e098a3\n","  Stored in directory: /root/.cache/pip/wheels/b7/8d/e7/a0e74217da5caeb3c1c7689639b6d28ddbf9985b840bc96a9a\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for overrides: filename=overrides-3.1.0-cp36-none-any.whl size=10174 sha256=60d21270127f319e82bcb01770ffe68fcb7c25d941206e74361607bd99c98019\n","  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n","  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for word2number: filename=word2number-1.1-cp36-none-any.whl size=5588 sha256=17f688df574ccf624b42b693ec4fbeabdf039fa086d143243bf79b55f6e2a7cb\n","  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n","  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jsonnet: filename=jsonnet-0.16.0-cp36-cp36m-linux_x86_64.whl size=3321599 sha256=622303b4e0979af5594c15f45b41c260d0777e0af0363bcc17868e90a914cec7\n","  Stored in directory: /root/.cache/pip/wheels/64/a9/43/bc5e0463deeec89dfca928a2a64595f1bdb520c891f6fbd09c\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ftfy: filename=ftfy-5.8-cp36-none-any.whl size=45612 sha256=0612f373e46f9686b1f4891c51236df84f590baae92086d630dbb07a8722f6de\n","  Stored in directory: /root/.cache/pip/wheels/ba/c0/ef/f28c4da5ac84a4e06ac256ca9182fc34fa57fefffdbc68425b\n","Successfully built parsimonious overrides word2number jsonnet ftfy\n","\u001b[31mERROR: en-core-web-sm 2.2.5 has requirement spacy>=2.2.2, but you'll have spacy 2.1.9 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","Installing collected packages: tensorboardX, jsonpickle, numpydoc, parsimonious, urllib3, jmespath, botocore, s3transfer, boto3, responses, conllu, sentencepiece, pytorch-transformers, overrides, word2number, jsonnet, unidecode, ftfy, preshed, plac, blis, thinc, spacy, zope.event, zope.interface, greenlet, gevent, flask-cors, pytorch-pretrained-bert, flaky, allennlp\n","  Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Found existing installation: preshed 3.0.2\n","    Uninstalling preshed-3.0.2:\n","      Successfully uninstalled preshed-3.0.2\n","  Found existing installation: plac 1.1.3\n","    Uninstalling plac-1.1.3:\n","      Successfully uninstalled plac-1.1.3\n","  Found existing installation: blis 0.4.1\n","    Uninstalling blis-0.4.1:\n","      Successfully uninstalled blis-0.4.1\n","  Found existing installation: thinc 7.4.0\n","    Uninstalling thinc-7.4.0:\n","      Successfully uninstalled thinc-7.4.0\n","  Found existing installation: spacy 2.2.4\n","    Uninstalling spacy-2.2.4:\n","      Successfully uninstalled spacy-2.2.4\n","Successfully installed allennlp-0.9.1-unreleased blis-0.2.4 boto3-1.16.13 botocore-1.19.13 conllu-1.3.1 flaky-3.7.0 flask-cors-3.0.9 ftfy-5.8 gevent-20.9.0 greenlet-0.4.17 jmespath-0.10.0 jsonnet-0.16.0 jsonpickle-1.4.1 numpydoc-1.1.0 overrides-3.1.0 parsimonious-0.8.1 plac-0.9.6 preshed-2.0.1 pytorch-pretrained-bert-0.6.2 pytorch-transformers-1.1.0 responses-0.12.0 s3transfer-0.3.3 sentencepiece-0.1.94 spacy-2.1.9 tensorboardX-2.1 thinc-7.0.8 unidecode-1.1.1 urllib3-1.25.11 word2number-1.1 zope.event-4.5.0 zope.interface-5.2.0\n","Collecting transformers==2.4.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n","\u001b[K     |████████████████████████████████| 481kB 8.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.4.1) (1.18.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.4.1) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.4.1) (3.0.12)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.4.1) (0.1.94)\n","Collecting tokenizers==0.0.11\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.1MB 34.5MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.4.1) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 57.7MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.4.1) (2019.12.20)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.4.1) (1.16.13)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.4.1) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.4.1) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.4.1) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.4.1) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.4.1) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.4.1) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.4.1) (0.17.0)\n","Requirement already satisfied: botocore<1.20.0,>=1.19.13 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.4.1) (1.19.13)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.4.1) (0.3.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.4.1) (0.10.0)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.13->boto3->transformers==2.4.1) (2.8.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=d77d2598a230ecb4761e5fab3563bb93b0fb3fdbca5561cc41d872946d579e55\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.0.11 transformers-2.4.1\n","Collecting pytorch-transformers==1.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n","\u001b[K     |████████████████████████████████| 184kB 6.7MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.2.0) (2019.12.20)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.2.0) (1.7.0+cu101)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.2.0) (1.16.13)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.2.0) (1.18.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.2.0) (4.41.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.2.0) (0.0.43)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.2.0) (0.1.94)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.2.0) (2.23.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch-transformers==1.2.0) (0.16.0)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch-transformers==1.2.0) (0.7)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch-transformers==1.2.0) (3.7.4.3)\n","Requirement already satisfied: botocore<1.20.0,>=1.19.13 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers==1.2.0) (1.19.13)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers==1.2.0) (0.10.0)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers==1.2.0) (0.3.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers==1.2.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers==1.2.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers==1.2.0) (0.17.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers==1.2.0) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers==1.2.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers==1.2.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers==1.2.0) (2020.6.20)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.13->boto3->pytorch-transformers==1.2.0) (2.8.1)\n","\u001b[31mERROR: allennlp 0.9.1-unreleased has requirement pytorch-transformers==1.1.0, but you'll have pytorch-transformers 1.2.0 which is incompatible.\u001b[0m\n","Installing collected packages: pytorch-transformers\n","  Found existing installation: pytorch-transformers 1.1.0\n","    Uninstalling pytorch-transformers-1.1.0:\n","      Successfully uninstalled pytorch-transformers-1.1.0\n","Successfully installed pytorch-transformers-1.2.0\n","Cloning into 'dont-stop-pretraining'...\n","remote: Enumerating objects: 439, done.\u001b[K\n","remote: Total 439 (delta 0), reused 0 (delta 0), pack-reused 439\u001b[K\n","Receiving objects: 100% (439/439), 566.01 KiB | 1.28 MiB/s, done.\n","Resolving deltas: 100% (232/232), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_6LWu1DfWDaw","executionInfo":{"status":"ok","timestamp":1604865108797,"user_tz":300,"elapsed":764,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"3d442e9e-15fd-4ca8-be38-f56d9ac90e65","colab":{"base_uri":"https://localhost:8080/"}},"source":["%cd /content/dont-stop-pretraining\n","!pwd"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/content/dont-stop-pretraining\n","/content/dont-stop-pretraining\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fPSriF8OXpbT","executionInfo":{"status":"ok","timestamp":1604865111515,"user_tz":300,"elapsed":502,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"6cd213e7-3451-40a9-dee5-e8193324db40","colab":{"base_uri":"https://localhost:8080/"}},"source":["import torch\n","if torch.cuda.is_available():\n","  device = torch.device(\"cuda\")\n","else:\n","  device = torch.device(\"cpu\")\n","print(device)\n","\n","!nvidia-smi"],"execution_count":8,"outputs":[{"output_type":"stream","text":["cuda\n","Sun Nov  8 19:51:50 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    25W / 300W |     10MiB / 16130MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uWjKXbiiX31i","executionInfo":{"status":"ok","timestamp":1604870395536,"user_tz":300,"elapsed":4806021,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"2c54b739-1541-455c-f265-577c42e93427","colab":{"base_uri":"https://localhost:8080/"}},"source":["!python -m scripts.train \\\n","        --config training_config/classifier.jsonnet \\\n","        --serialization_dir model_logs/imdb_nas_02 \\\n","        --hyperparameters ROBERTA_CLASSIFIER_MINI \\\n","        --dataset imdb \\\n","        --model roberta-base \\\n","        --device 0 \\\n","        --perf +f1 \\\n","        --evaluate_on_test"],"execution_count":13,"outputs":[{"output_type":"stream","text":["2020-11-08 19:59:51,859 - INFO - pytorch_pretrained_bert.modeling - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-08 19:59:52,312 - INFO - pytorch_transformers.modeling_bert - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-08 19:59:52,315 - INFO - pytorch_transformers.modeling_xlnet - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-08 19:59:52,788 - INFO - allennlp.common.params - random_seed = 974611\n","2020-11-08 19:59:52,788 - INFO - allennlp.common.params - numpy_seed = 974611\n","2020-11-08 19:59:52,788 - INFO - allennlp.common.params - pytorch_seed = 974611\n","2020-11-08 19:59:52,795 - INFO - allennlp.common.checks - Pytorch version: 1.7.0+cu101\n","2020-11-08 19:59:52,797 - INFO - allennlp.common.params - evaluate_on_test = True\n","2020-11-08 19:59:52,797 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}, 'type': 'text_classification_json_with_sampling'} and extras set()\n","2020-11-08 19:59:52,797 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling\n","2020-11-08 19:59:52,797 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.data.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}} and extras set()\n","2020-11-08 19:59:52,797 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras set()\n","2020-11-08 19:59:52,797 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.type = pretrained_transformer\n","2020-11-08 19:59:52,798 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base'} and extras set()\n","2020-11-08 19:59:52,798 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.model_name = roberta-base\n","2020-11-08 19:59:52,798 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.do_lowercase = False\n","2020-11-08 19:59:52,798 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.namespace = tags\n","2020-11-08 19:59:52,798 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.token_min_padding_length = 0\n","2020-11-08 19:59:53,547 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-08 19:59:53,547 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-08 19:59:53,627 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 1\n","2020-11-08 19:59:53,628 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'} and extras set()\n","2020-11-08 19:59:53,628 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer\n","2020-11-08 19:59:53,628 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>']} and extras set()\n","2020-11-08 19:59:53,628 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base\n","2020-11-08 19:59:53,628 - INFO - allennlp.common.params - dataset_reader.tokenizer.do_lowercase = False\n","2020-11-08 19:59:53,628 - INFO - allennlp.common.params - dataset_reader.tokenizer.start_tokens = ['<s>']\n","2020-11-08 19:59:53,628 - INFO - allennlp.common.params - dataset_reader.tokenizer.end_tokens = ['</s>']\n","2020-11-08 19:59:54,365 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-08 19:59:54,365 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-08 19:59:54,438 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512\n","2020-11-08 19:59:54,438 - INFO - allennlp.common.params - dataset_reader.sample = None\n","2020-11-08 19:59:54,438 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False\n","2020-11-08 19:59:54,438 - INFO - allennlp.common.params - dataset_reader.lazy = False\n","2020-11-08 19:59:54,438 - INFO - allennlp.training.util - Using a separate dataset reader to load validation and test data.\n","2020-11-08 19:59:54,439 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}, 'type': 'text_classification_json_with_sampling'} and extras set()\n","2020-11-08 19:59:54,439 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling\n","2020-11-08 19:59:54,439 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.data.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}} and extras set()\n","2020-11-08 19:59:54,439 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras set()\n","2020-11-08 19:59:54,439 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.type = pretrained_transformer\n","2020-11-08 19:59:54,439 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base'} and extras set()\n","2020-11-08 19:59:54,440 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.model_name = roberta-base\n","2020-11-08 19:59:54,440 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.do_lowercase = False\n","2020-11-08 19:59:54,440 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.namespace = tags\n","2020-11-08 19:59:54,440 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.token_min_padding_length = 0\n","2020-11-08 19:59:55,165 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-08 19:59:55,165 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-08 19:59:55,240 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 1\n","2020-11-08 19:59:55,241 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'} and extras set()\n","2020-11-08 19:59:55,241 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer\n","2020-11-08 19:59:55,241 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>']} and extras set()\n","2020-11-08 19:59:55,241 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base\n","2020-11-08 19:59:55,241 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.do_lowercase = False\n","2020-11-08 19:59:55,241 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.start_tokens = ['<s>']\n","2020-11-08 19:59:55,241 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.end_tokens = ['</s>']\n","2020-11-08 19:59:55,967 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-08 19:59:55,967 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-08 19:59:56,042 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512\n","2020-11-08 19:59:56,042 - INFO - allennlp.common.params - validation_dataset_reader.sample = None\n","2020-11-08 19:59:56,042 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False\n","2020-11-08 19:59:56,042 - INFO - allennlp.common.params - validation_dataset_reader.lazy = False\n","2020-11-08 19:59:56,042 - INFO - allennlp.common.params - train_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/imdb/train.jsonl\n","2020-11-08 19:59:56,042 - INFO - allennlp.training.util - Reading training data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/imdb/train.jsonl\n","20000it [00:33, 599.16it/s]\n","2020-11-08 20:00:29,423 - INFO - allennlp.common.params - validation_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/imdb/dev.jsonl\n","2020-11-08 20:00:29,423 - INFO - allennlp.training.util - Reading validation data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/imdb/dev.jsonl\n","5000it [00:10, 493.00it/s]\n","2020-11-08 20:00:39,566 - INFO - allennlp.common.params - test_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/imdb/test.jsonl\n","2020-11-08 20:00:39,566 - INFO - allennlp.training.util - Reading test data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/imdb/test.jsonl\n","25000it [00:37, 670.12it/s]\n","2020-11-08 20:01:16,984 - INFO - allennlp.training.trainer_pieces - From dataset instances, validation, train, test will be considered for vocabulary creation.\n","2020-11-08 20:01:16,984 - INFO - allennlp.common.params - vocabulary.type = None\n","2020-11-08 20:01:16,984 - INFO - allennlp.common.params - vocabulary.extend = False\n","2020-11-08 20:01:16,984 - INFO - allennlp.common.params - vocabulary.directory_path = None\n","2020-11-08 20:01:16,984 - INFO - allennlp.common.params - vocabulary.min_count = None\n","2020-11-08 20:01:16,985 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None\n","2020-11-08 20:01:16,985 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')\n","2020-11-08 20:01:16,985 - INFO - allennlp.common.params - vocabulary.pretrained_files = {}\n","2020-11-08 20:01:16,985 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None\n","2020-11-08 20:01:16,985 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False\n","2020-11-08 20:01:16,985 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None\n","2020-11-08 20:01:16,985 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n","50000it [00:01, 33838.21it/s]\n","2020-11-08 20:01:18,463 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'dropout': '0.1', 'feedforward_layer': {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1}, 'seq2vec_encoder': {'embedding_dim': 768, 'type': 'cls_pooler'}, 'text_field_embedder': {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'type': 'basic_classifier_with_f1'} and extras {'vocab'}\n","2020-11-08 20:01:18,463 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1\n","2020-11-08 20:01:18,464 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.models.basic_classifier_with_f1.BasicClassifierWithF1'> from params {'dropout': '0.1', 'feedforward_layer': {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1}, 'seq2vec_encoder': {'embedding_dim': 768, 'type': 'cls_pooler'}, 'text_field_embedder': {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}} and extras {'vocab'}\n","2020-11-08 20:01:18,464 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}} and extras {'vocab'}\n","2020-11-08 20:01:18,464 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n","2020-11-08 20:01:18,464 - INFO - allennlp.common.params - model.text_field_embedder.embedder_to_indexer_map = None\n","2020-11-08 20:01:18,464 - INFO - allennlp.common.params - model.text_field_embedder.allow_unmatched_keys = False\n","2020-11-08 20:01:18,464 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders = None\n","2020-11-08 20:01:18,465 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras {'vocab'}\n","2020-11-08 20:01:18,465 - INFO - allennlp.common.params - model.text_field_embedder.roberta.type = pretrained_transformer\n","2020-11-08 20:01:18,465 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.pretrained_transformer_embedder.PretrainedTransformerEmbedder'> from params {'model_name': 'roberta-base'} and extras {'vocab'}\n","2020-11-08 20:01:18,465 - INFO - allennlp.common.params - model.text_field_embedder.roberta.model_name = roberta-base\n","2020-11-08 20:01:18,853 - INFO - pytorch_transformers.modeling_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/pytorch_transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n","2020-11-08 20:01:18,854 - INFO - pytorch_transformers.modeling_utils - Model config {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 1,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","2020-11-08 20:01:19,231 - INFO - pytorch_transformers.modeling_utils - loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n","2020-11-08 20:01:23,521 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'embedding_dim': 768, 'type': 'cls_pooler'} and extras {'vocab'}\n","2020-11-08 20:01:23,521 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler\n","2020-11-08 20:01:23,521 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.modules.seq2vec_encoders.cls_pooler.CLSPooler'> from params {'embedding_dim': 768} and extras {'vocab'}\n","2020-11-08 20:01:23,522 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768\n","2020-11-08 20:01:23,522 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1} and extras {'vocab'}\n","2020-11-08 20:01:23,522 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768\n","2020-11-08 20:01:23,522 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1\n","2020-11-08 20:01:23,522 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768\n","2020-11-08 20:01:23,522 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh\n","2020-11-08 20:01:23,523 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0\n","2020-11-08 20:01:23,528 - INFO - allennlp.common.params - model.dropout = 0.1\n","2020-11-08 20:01:23,528 - INFO - allennlp.common.params - model.num_labels = None\n","2020-11-08 20:01:23,528 - INFO - allennlp.common.params - model.label_namespace = labels\n","2020-11-08 20:01:23,528 - INFO - allennlp.nn.initializers - Initializing parameters\n","2020-11-08 20:01:23,530 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n","2020-11-08 20:01:23,530 - INFO - allennlp.nn.initializers -    _classification_layer.bias\n","2020-11-08 20:01:23,530 - INFO - allennlp.nn.initializers -    _classification_layer.weight\n","2020-11-08 20:01:23,530 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias\n","2020-11-08 20:01:23,530 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight\n","2020-11-08 20:01:23,530 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias\n","2020-11-08 20:01:23,530 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight\n","2020-11-08 20:01:23,530 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight\n","2020-11-08 20:01:23,530 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight\n","2020-11-08 20:01:23,530 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight\n","2020-11-08 20:01:23,530 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias\n","2020-11-08 20:01:23,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight\n","2020-11-08 20:01:23,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias\n","2020-11-08 20:01:23,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight\n","2020-11-08 20:01:23,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias\n","2020-11-08 20:01:23,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight\n","2020-11-08 20:01:23,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias\n","2020-11-08 20:01:23,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight\n","2020-11-08 20:01:23,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias\n","2020-11-08 20:01:23,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight\n","2020-11-08 20:01:23,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias\n","2020-11-08 20:01:23,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight\n","2020-11-08 20:01:23,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias\n","2020-11-08 20:01:23,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight\n","2020-11-08 20:01:23,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,532 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias\n","2020-11-08 20:01:23,532 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight\n","2020-11-08 20:01:23,532 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias\n","2020-11-08 20:01:23,532 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight\n","2020-11-08 20:01:23,532 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias\n","2020-11-08 20:01:23,532 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight\n","2020-11-08 20:01:23,532 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias\n","2020-11-08 20:01:23,532 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight\n","2020-11-08 20:01:23,532 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias\n","2020-11-08 20:01:23,532 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight\n","2020-11-08 20:01:23,532 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias\n","2020-11-08 20:01:23,532 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight\n","2020-11-08 20:01:23,532 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias\n","2020-11-08 20:01:23,532 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight\n","2020-11-08 20:01:23,532 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,532 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,532 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias\n","2020-11-08 20:01:23,532 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight\n","2020-11-08 20:01:23,533 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias\n","2020-11-08 20:01:23,533 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight\n","2020-11-08 20:01:23,533 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias\n","2020-11-08 20:01:23,533 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight\n","2020-11-08 20:01:23,533 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias\n","2020-11-08 20:01:23,533 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight\n","2020-11-08 20:01:23,533 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias\n","2020-11-08 20:01:23,533 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight\n","2020-11-08 20:01:23,533 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias\n","2020-11-08 20:01:23,533 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight\n","2020-11-08 20:01:23,533 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias\n","2020-11-08 20:01:23,533 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight\n","2020-11-08 20:01:23,533 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,533 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,533 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias\n","2020-11-08 20:01:23,533 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight\n","2020-11-08 20:01:23,533 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias\n","2020-11-08 20:01:23,533 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight\n","2020-11-08 20:01:23,534 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias\n","2020-11-08 20:01:23,534 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight\n","2020-11-08 20:01:23,534 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias\n","2020-11-08 20:01:23,534 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight\n","2020-11-08 20:01:23,534 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias\n","2020-11-08 20:01:23,534 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight\n","2020-11-08 20:01:23,534 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias\n","2020-11-08 20:01:23,534 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight\n","2020-11-08 20:01:23,534 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias\n","2020-11-08 20:01:23,534 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight\n","2020-11-08 20:01:23,534 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,534 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,534 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias\n","2020-11-08 20:01:23,534 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight\n","2020-11-08 20:01:23,534 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias\n","2020-11-08 20:01:23,534 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight\n","2020-11-08 20:01:23,534 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias\n","2020-11-08 20:01:23,534 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight\n","2020-11-08 20:01:23,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias\n","2020-11-08 20:01:23,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight\n","2020-11-08 20:01:23,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias\n","2020-11-08 20:01:23,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight\n","2020-11-08 20:01:23,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias\n","2020-11-08 20:01:23,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight\n","2020-11-08 20:01:23,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias\n","2020-11-08 20:01:23,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight\n","2020-11-08 20:01:23,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias\n","2020-11-08 20:01:23,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight\n","2020-11-08 20:01:23,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias\n","2020-11-08 20:01:23,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight\n","2020-11-08 20:01:23,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias\n","2020-11-08 20:01:23,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight\n","2020-11-08 20:01:23,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias\n","2020-11-08 20:01:23,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight\n","2020-11-08 20:01:23,536 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias\n","2020-11-08 20:01:23,536 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight\n","2020-11-08 20:01:23,536 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias\n","2020-11-08 20:01:23,536 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight\n","2020-11-08 20:01:23,536 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias\n","2020-11-08 20:01:23,536 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight\n","2020-11-08 20:01:23,536 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,600 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,601 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias\n","2020-11-08 20:01:23,601 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight\n","2020-11-08 20:01:23,601 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias\n","2020-11-08 20:01:23,601 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight\n","2020-11-08 20:01:23,601 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias\n","2020-11-08 20:01:23,601 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight\n","2020-11-08 20:01:23,601 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias\n","2020-11-08 20:01:23,601 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight\n","2020-11-08 20:01:23,601 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias\n","2020-11-08 20:01:23,601 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight\n","2020-11-08 20:01:23,601 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias\n","2020-11-08 20:01:23,601 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight\n","2020-11-08 20:01:23,601 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias\n","2020-11-08 20:01:23,602 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight\n","2020-11-08 20:01:23,602 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,602 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,602 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias\n","2020-11-08 20:01:23,602 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight\n","2020-11-08 20:01:23,602 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias\n","2020-11-08 20:01:23,602 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight\n","2020-11-08 20:01:23,602 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias\n","2020-11-08 20:01:23,602 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight\n","2020-11-08 20:01:23,602 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias\n","2020-11-08 20:01:23,602 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight\n","2020-11-08 20:01:23,602 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias\n","2020-11-08 20:01:23,602 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight\n","2020-11-08 20:01:23,603 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias\n","2020-11-08 20:01:23,603 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight\n","2020-11-08 20:01:23,603 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias\n","2020-11-08 20:01:23,603 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight\n","2020-11-08 20:01:23,603 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,603 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,603 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias\n","2020-11-08 20:01:23,603 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight\n","2020-11-08 20:01:23,603 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias\n","2020-11-08 20:01:23,603 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight\n","2020-11-08 20:01:23,603 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias\n","2020-11-08 20:01:23,603 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight\n","2020-11-08 20:01:23,603 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias\n","2020-11-08 20:01:23,604 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight\n","2020-11-08 20:01:23,604 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias\n","2020-11-08 20:01:23,604 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight\n","2020-11-08 20:01:23,604 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias\n","2020-11-08 20:01:23,604 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight\n","2020-11-08 20:01:23,604 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias\n","2020-11-08 20:01:23,604 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight\n","2020-11-08 20:01:23,604 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,604 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,604 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias\n","2020-11-08 20:01:23,604 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight\n","2020-11-08 20:01:23,604 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias\n","2020-11-08 20:01:23,604 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight\n","2020-11-08 20:01:23,604 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias\n","2020-11-08 20:01:23,605 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight\n","2020-11-08 20:01:23,605 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias\n","2020-11-08 20:01:23,605 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight\n","2020-11-08 20:01:23,605 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias\n","2020-11-08 20:01:23,605 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight\n","2020-11-08 20:01:23,605 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias\n","2020-11-08 20:01:23,605 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight\n","2020-11-08 20:01:23,605 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias\n","2020-11-08 20:01:23,605 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight\n","2020-11-08 20:01:23,605 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,605 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,605 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias\n","2020-11-08 20:01:23,605 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight\n","2020-11-08 20:01:23,605 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias\n","2020-11-08 20:01:23,606 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight\n","2020-11-08 20:01:23,606 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias\n","2020-11-08 20:01:23,606 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight\n","2020-11-08 20:01:23,606 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias\n","2020-11-08 20:01:23,606 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight\n","2020-11-08 20:01:23,606 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias\n","2020-11-08 20:01:23,606 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight\n","2020-11-08 20:01:23,606 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias\n","2020-11-08 20:01:23,606 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight\n","2020-11-08 20:01:23,606 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias\n","2020-11-08 20:01:23,606 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight\n","2020-11-08 20:01:23,607 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,607 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,607 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias\n","2020-11-08 20:01:23,607 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight\n","2020-11-08 20:01:23,607 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias\n","2020-11-08 20:01:23,607 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight\n","2020-11-08 20:01:23,607 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias\n","2020-11-08 20:01:23,607 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight\n","2020-11-08 20:01:23,607 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias\n","2020-11-08 20:01:23,607 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight\n","2020-11-08 20:01:23,607 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias\n","2020-11-08 20:01:23,607 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight\n","2020-11-08 20:01:23,607 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias\n","2020-11-08 20:01:23,608 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight\n","2020-11-08 20:01:23,608 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias\n","2020-11-08 20:01:23,608 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight\n","2020-11-08 20:01:23,608 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias\n","2020-11-08 20:01:23,608 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight\n","2020-11-08 20:01:23,610 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 8, 'sorting_keys': [['tokens', 'num_tokens']], 'type': 'bucket'} and extras set()\n","2020-11-08 20:01:23,610 - INFO - allennlp.common.params - iterator.type = bucket\n","2020-11-08 20:01:23,610 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 8, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()\n","2020-11-08 20:01:23,610 - INFO - allennlp.common.params - iterator.sorting_keys = [['tokens', 'num_tokens']]\n","2020-11-08 20:01:23,610 - INFO - allennlp.common.params - iterator.padding_noise = 0.1\n","2020-11-08 20:01:23,610 - INFO - allennlp.common.params - iterator.biggest_batch_first = False\n","2020-11-08 20:01:23,610 - INFO - allennlp.common.params - iterator.batch_size = 8\n","2020-11-08 20:01:23,610 - INFO - allennlp.common.params - iterator.instances_per_epoch = None\n","2020-11-08 20:01:23,610 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None\n","2020-11-08 20:01:23,610 - INFO - allennlp.common.params - iterator.cache_instances = False\n","2020-11-08 20:01:23,610 - INFO - allennlp.common.params - iterator.track_epoch = False\n","2020-11-08 20:01:23,611 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None\n","2020-11-08 20:01:23,611 - INFO - allennlp.common.params - iterator.skip_smaller_batches = False\n","2020-11-08 20:01:23,611 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'sorting_keys': [['tokens', 'num_tokens']], 'type': 'bucket'} and extras set()\n","2020-11-08 20:01:23,611 - INFO - allennlp.common.params - validation_iterator.type = bucket\n","2020-11-08 20:01:23,611 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 64, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()\n","2020-11-08 20:01:23,611 - INFO - allennlp.common.params - validation_iterator.sorting_keys = [['tokens', 'num_tokens']]\n","2020-11-08 20:01:23,611 - INFO - allennlp.common.params - validation_iterator.padding_noise = 0.1\n","2020-11-08 20:01:23,611 - INFO - allennlp.common.params - validation_iterator.biggest_batch_first = False\n","2020-11-08 20:01:23,611 - INFO - allennlp.common.params - validation_iterator.batch_size = 64\n","2020-11-08 20:01:23,611 - INFO - allennlp.common.params - validation_iterator.instances_per_epoch = None\n","2020-11-08 20:01:23,611 - INFO - allennlp.common.params - validation_iterator.max_instances_in_memory = None\n","2020-11-08 20:01:23,611 - INFO - allennlp.common.params - validation_iterator.cache_instances = False\n","2020-11-08 20:01:23,611 - INFO - allennlp.common.params - validation_iterator.track_epoch = False\n","2020-11-08 20:01:23,611 - INFO - allennlp.common.params - validation_iterator.maximum_samples_per_batch = None\n","2020-11-08 20:01:23,611 - INFO - allennlp.common.params - validation_iterator.skip_smaller_batches = False\n","2020-11-08 20:01:23,612 - INFO - allennlp.common.params - trainer.no_grad = ()\n","2020-11-08 20:01:23,614 - INFO - allennlp.training.trainer_pieces - Following parameters are Frozen  (without gradient):\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - Following parameters are Tunable (with gradient):\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias\n","2020-11-08 20:01:23,615 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias\n","2020-11-08 20:01:23,616 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight\n","2020-11-08 20:01:23,617 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias\n","2020-11-08 20:01:23,617 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight\n","2020-11-08 20:01:23,617 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias\n","2020-11-08 20:01:23,617 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight\n","2020-11-08 20:01:23,617 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias\n","2020-11-08 20:01:23,617 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight\n","2020-11-08 20:01:23,617 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias\n","2020-11-08 20:01:23,617 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,617 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,617 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight\n","2020-11-08 20:01:23,617 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias\n","2020-11-08 20:01:23,617 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight\n","2020-11-08 20:01:23,617 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias\n","2020-11-08 20:01:23,617 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight\n","2020-11-08 20:01:23,617 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias\n","2020-11-08 20:01:23,617 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight\n","2020-11-08 20:01:23,617 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias\n","2020-11-08 20:01:23,617 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight\n","2020-11-08 20:01:23,617 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias\n","2020-11-08 20:01:23,617 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight\n","2020-11-08 20:01:23,617 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias\n","2020-11-08 20:01:23,709 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight\n","2020-11-08 20:01:23,709 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias\n","2020-11-08 20:01:23,709 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,709 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,709 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight\n","2020-11-08 20:01:23,709 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias\n","2020-11-08 20:01:23,709 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight\n","2020-11-08 20:01:23,710 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias\n","2020-11-08 20:01:23,710 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight\n","2020-11-08 20:01:23,710 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias\n","2020-11-08 20:01:23,710 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight\n","2020-11-08 20:01:23,710 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias\n","2020-11-08 20:01:23,710 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight\n","2020-11-08 20:01:23,710 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias\n","2020-11-08 20:01:23,710 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight\n","2020-11-08 20:01:23,710 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias\n","2020-11-08 20:01:23,710 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight\n","2020-11-08 20:01:23,710 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias\n","2020-11-08 20:01:23,710 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,710 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,710 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight\n","2020-11-08 20:01:23,710 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias\n","2020-11-08 20:01:23,711 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight\n","2020-11-08 20:01:23,711 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias\n","2020-11-08 20:01:23,711 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight\n","2020-11-08 20:01:23,711 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias\n","2020-11-08 20:01:23,711 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight\n","2020-11-08 20:01:23,711 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias\n","2020-11-08 20:01:23,711 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight\n","2020-11-08 20:01:23,711 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias\n","2020-11-08 20:01:23,711 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight\n","2020-11-08 20:01:23,711 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias\n","2020-11-08 20:01:23,711 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight\n","2020-11-08 20:01:23,711 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias\n","2020-11-08 20:01:23,711 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,711 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,711 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight\n","2020-11-08 20:01:23,712 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias\n","2020-11-08 20:01:23,712 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight\n","2020-11-08 20:01:23,712 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias\n","2020-11-08 20:01:23,712 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight\n","2020-11-08 20:01:23,712 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias\n","2020-11-08 20:01:23,712 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight\n","2020-11-08 20:01:23,712 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias\n","2020-11-08 20:01:23,712 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight\n","2020-11-08 20:01:23,712 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias\n","2020-11-08 20:01:23,712 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight\n","2020-11-08 20:01:23,712 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias\n","2020-11-08 20:01:23,712 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight\n","2020-11-08 20:01:23,712 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias\n","2020-11-08 20:01:23,712 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,713 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,713 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight\n","2020-11-08 20:01:23,713 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias\n","2020-11-08 20:01:23,713 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight\n","2020-11-08 20:01:23,713 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias\n","2020-11-08 20:01:23,713 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight\n","2020-11-08 20:01:23,713 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias\n","2020-11-08 20:01:23,713 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight\n","2020-11-08 20:01:23,713 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias\n","2020-11-08 20:01:23,713 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight\n","2020-11-08 20:01:23,713 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias\n","2020-11-08 20:01:23,713 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight\n","2020-11-08 20:01:23,713 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias\n","2020-11-08 20:01:23,713 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight\n","2020-11-08 20:01:23,714 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias\n","2020-11-08 20:01:23,714 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,714 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,714 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight\n","2020-11-08 20:01:23,714 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias\n","2020-11-08 20:01:23,714 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight\n","2020-11-08 20:01:23,714 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias\n","2020-11-08 20:01:23,714 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight\n","2020-11-08 20:01:23,714 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias\n","2020-11-08 20:01:23,714 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight\n","2020-11-08 20:01:23,714 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias\n","2020-11-08 20:01:23,714 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight\n","2020-11-08 20:01:23,714 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias\n","2020-11-08 20:01:23,714 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight\n","2020-11-08 20:01:23,714 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias\n","2020-11-08 20:01:23,715 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight\n","2020-11-08 20:01:23,715 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias\n","2020-11-08 20:01:23,715 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,715 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,715 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight\n","2020-11-08 20:01:23,715 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias\n","2020-11-08 20:01:23,715 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight\n","2020-11-08 20:01:23,715 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias\n","2020-11-08 20:01:23,715 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight\n","2020-11-08 20:01:23,715 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias\n","2020-11-08 20:01:23,715 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight\n","2020-11-08 20:01:23,715 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias\n","2020-11-08 20:01:23,715 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight\n","2020-11-08 20:01:23,715 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias\n","2020-11-08 20:01:23,715 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight\n","2020-11-08 20:01:23,716 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias\n","2020-11-08 20:01:23,716 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight\n","2020-11-08 20:01:23,716 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias\n","2020-11-08 20:01:23,716 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,716 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,716 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight\n","2020-11-08 20:01:23,716 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias\n","2020-11-08 20:01:23,716 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight\n","2020-11-08 20:01:23,716 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias\n","2020-11-08 20:01:23,716 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight\n","2020-11-08 20:01:23,716 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias\n","2020-11-08 20:01:23,716 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight\n","2020-11-08 20:01:23,716 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias\n","2020-11-08 20:01:23,716 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight\n","2020-11-08 20:01:23,716 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias\n","2020-11-08 20:01:23,717 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight\n","2020-11-08 20:01:23,717 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias\n","2020-11-08 20:01:23,717 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight\n","2020-11-08 20:01:23,717 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias\n","2020-11-08 20:01:23,717 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n","2020-11-08 20:01:23,717 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n","2020-11-08 20:01:23,717 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight\n","2020-11-08 20:01:23,717 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias\n","2020-11-08 20:01:23,717 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight\n","2020-11-08 20:01:23,717 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias\n","2020-11-08 20:01:23,717 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight\n","2020-11-08 20:01:23,717 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias\n","2020-11-08 20:01:23,717 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight\n","2020-11-08 20:01:23,717 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias\n","2020-11-08 20:01:23,718 - INFO - allennlp.training.trainer_pieces - _feedforward_layer._linear_layers.0.weight\n","2020-11-08 20:01:23,718 - INFO - allennlp.training.trainer_pieces - _feedforward_layer._linear_layers.0.bias\n","2020-11-08 20:01:23,718 - INFO - allennlp.training.trainer_pieces - _classification_layer.weight\n","2020-11-08 20:01:23,718 - INFO - allennlp.training.trainer_pieces - _classification_layer.bias\n","2020-11-08 20:01:23,718 - INFO - allennlp.common.params - trainer.patience = 3\n","2020-11-08 20:01:23,718 - INFO - allennlp.common.params - trainer.validation_metric = +f1\n","2020-11-08 20:01:23,718 - INFO - allennlp.common.params - trainer.shuffle = True\n","2020-11-08 20:01:23,718 - INFO - allennlp.common.params - trainer.num_epochs = 10\n","2020-11-08 20:01:23,718 - INFO - allennlp.common.params - trainer.cuda_device = 0\n","2020-11-08 20:01:23,718 - INFO - allennlp.common.params - trainer.grad_norm = None\n","2020-11-08 20:01:23,718 - INFO - allennlp.common.params - trainer.grad_clipping = None\n","2020-11-08 20:01:23,718 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None\n","2020-11-08 20:01:23,719 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n","2020-11-08 20:01:23,719 - INFO - allennlp.common.params - trainer.gradient_accumulation_batch_size = 8\n","2020-11-08 20:01:28,391 - INFO - allennlp.common.params - trainer.optimizer.type = bert_adam\n","2020-11-08 20:01:28,391 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n","2020-11-08 20:01:28,391 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n","2020-11-08 20:01:28,391 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups.0.1.weight_decay = 0\n","2020-11-08 20:01:28,392 - INFO - allennlp.training.optimizers - Done constructing parameter groups.\n","2020-11-08 20:01:28,392 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias', '_classification_layer.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias', '_feedforward_layer._linear_layers.0.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias'], {'weight_decay': 0}\n","2020-11-08 20:01:28,436 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight', '_classification_layer.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight', '_feedforward_layer._linear_layers.0.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight'], {}\n","2020-11-08 20:01:28,436 - WARNING - allennlp.training.optimizers - When constructing parameter groups,  layer_norm.weight not match any parameter name\n","2020-11-08 20:01:28,437 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125237762\n","2020-11-08 20:01:28,438 - INFO - allennlp.common.params - trainer.optimizer.infer_type_and_cast = True\n","2020-11-08 20:01:28,438 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n","2020-11-08 20:01:28,438 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n","2020-11-08 20:01:28,438 - INFO - allennlp.common.params - trainer.optimizer.b1 = 0.9\n","2020-11-08 20:01:28,438 - INFO - allennlp.common.params - trainer.optimizer.b2 = 0.98\n","2020-11-08 20:01:28,438 - INFO - allennlp.common.params - trainer.optimizer.e = 1e-06\n","2020-11-08 20:01:28,438 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05\n","2020-11-08 20:01:28,438 - INFO - allennlp.common.params - trainer.optimizer.max_grad_norm = 1\n","2020-11-08 20:01:28,438 - INFO - allennlp.common.params - trainer.optimizer.schedule = warmup_linear\n","2020-11-08 20:01:28,438 - INFO - allennlp.common.params - trainer.optimizer.t_total = -1\n","2020-11-08 20:01:28,438 - INFO - allennlp.common.params - trainer.optimizer.warmup = 0.06\n","2020-11-08 20:01:28,438 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1\n","2020-11-08 20:01:28,438 - WARNING - pytorch_pretrained_bert.optimization - t_total value of -1 results in schedule not being applied\n","2020-11-08 20:01:28,440 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 0\n","2020-11-08 20:01:28,440 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None\n","2020-11-08 20:01:28,440 - INFO - allennlp.common.params - trainer.model_save_interval = None\n","2020-11-08 20:01:28,440 - INFO - allennlp.common.params - trainer.summary_interval = 100\n","2020-11-08 20:01:28,440 - INFO - allennlp.common.params - trainer.histogram_interval = None\n","2020-11-08 20:01:28,440 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True\n","2020-11-08 20:01:28,440 - INFO - allennlp.common.params - trainer.should_log_learning_rate = False\n","2020-11-08 20:01:28,440 - INFO - allennlp.common.params - trainer.log_batch_size_period = None\n","2020-11-08 20:01:28,442 - INFO - allennlp.training.trainer - Beginning training.\n","2020-11-08 20:01:28,442 - INFO - allennlp.training.trainer - Epoch 0/9\n","2020-11-08 20:01:28,443 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 6700.608\n","2020-11-08 20:01:28,566 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1769\n","2020-11-08 20:01:28,570 - INFO - allennlp.training.trainer - Training\n","  0%|          | 0/2500 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","f1: 0.8989, accuracy: 0.8989, loss: 0.2751 ||: 100%|##########| 2500/2500 [10:29<00:00,  3.97it/s]\n","2020-11-08 20:11:58,354 - INFO - allennlp.training.trainer - Validating\n","f1: 0.8887, accuracy: 0.8896, loss: 0.4110 ||: 100%|##########| 79/79 [00:30<00:00,  2.62it/s]\n","2020-11-08 20:12:28,525 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-08 20:12:28,526 - INFO - allennlp.training.tensorboard_writer - f1              |     0.899  |     0.889\n","2020-11-08 20:12:28,533 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  1769.000  |       N/A\n","2020-11-08 20:12:28,534 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.899  |     0.890\n","2020-11-08 20:12:28,535 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  6700.608  |       N/A\n","2020-11-08 20:12:28,535 - INFO - allennlp.training.tensorboard_writer - loss            |     0.275  |     0.411\n","2020-11-08 20:12:34,377 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/imdb_nas_02/best.th'.\n","2020-11-08 20:12:35,745 - INFO - allennlp.training.trainer - Epoch duration: 0:11:07.302548\n","2020-11-08 20:12:35,748 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:40:05\n","2020-11-08 20:12:35,748 - INFO - allennlp.training.trainer - Epoch 1/9\n","2020-11-08 20:12:35,748 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 6730.104\n","2020-11-08 20:12:35,874 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 9005\n","2020-11-08 20:12:35,878 - INFO - allennlp.training.trainer - Training\n","f1: 0.9348, accuracy: 0.9348, loss: 0.2062 ||: 100%|##########| 2500/2500 [10:20<00:00,  4.03it/s]\n","2020-11-08 20:22:55,947 - INFO - allennlp.training.trainer - Validating\n","f1: 0.9185, accuracy: 0.9186, loss: 0.2618 ||: 100%|##########| 79/79 [00:28<00:00,  2.80it/s]\n","2020-11-08 20:23:24,164 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-08 20:23:24,164 - INFO - allennlp.training.tensorboard_writer - f1              |     0.935  |     0.919\n","2020-11-08 20:23:24,164 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  9005.000  |       N/A\n","2020-11-08 20:23:24,165 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.935  |     0.919\n","2020-11-08 20:23:24,166 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  6730.104  |       N/A\n","2020-11-08 20:23:24,166 - INFO - allennlp.training.tensorboard_writer - loss            |     0.206  |     0.262\n","2020-11-08 20:23:29,503 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/imdb_nas_02/best.th'.\n","2020-11-08 20:23:31,499 - INFO - allennlp.training.trainer - Epoch duration: 0:10:55.751254\n","2020-11-08 20:23:31,499 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:28:12\n","2020-11-08 20:23:31,499 - INFO - allennlp.training.trainer - Epoch 2/9\n","2020-11-08 20:23:31,500 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 6731.132\n","2020-11-08 20:23:31,619 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 11173\n","2020-11-08 20:23:31,622 - INFO - allennlp.training.trainer - Training\n","f1: 0.9433, accuracy: 0.9434, loss: 0.1820 ||: 100%|##########| 2500/2500 [10:09<00:00,  4.10it/s]\n","2020-11-08 20:33:41,038 - INFO - allennlp.training.trainer - Validating\n","f1: 0.9261, accuracy: 0.9262, loss: 0.2416 ||: 100%|##########| 79/79 [00:28<00:00,  2.80it/s]\n","2020-11-08 20:34:09,227 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-08 20:34:09,227 - INFO - allennlp.training.tensorboard_writer - f1              |     0.943  |     0.926\n","2020-11-08 20:34:09,228 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  11173.000  |       N/A\n","2020-11-08 20:34:09,229 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.943  |     0.926\n","2020-11-08 20:34:09,230 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  6731.132  |       N/A\n","2020-11-08 20:34:09,230 - INFO - allennlp.training.tensorboard_writer - loss            |     0.182  |     0.242\n","2020-11-08 20:34:14,379 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/imdb_nas_02/best.th'.\n","2020-11-08 20:34:18,174 - INFO - allennlp.training.trainer - Epoch duration: 0:10:46.674758\n","2020-11-08 20:34:18,174 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:16:36\n","2020-11-08 20:34:18,175 - INFO - allennlp.training.trainer - Epoch 3/9\n","2020-11-08 20:34:18,175 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 6731.144\n","2020-11-08 20:34:18,302 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 11173\n","2020-11-08 20:34:18,305 - INFO - allennlp.training.trainer - Training\n","f1: 0.9615, accuracy: 0.9615, loss: 0.1423 ||: 100%|##########| 2500/2500 [10:05<00:00,  4.13it/s]\n","2020-11-08 20:44:23,388 - INFO - allennlp.training.trainer - Validating\n","f1: 0.9334, accuracy: 0.9334, loss: 0.2533 ||: 100%|##########| 79/79 [00:28<00:00,  2.81it/s]\n","2020-11-08 20:44:51,547 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-08 20:44:51,547 - INFO - allennlp.training.tensorboard_writer - f1              |     0.961  |     0.933\n","2020-11-08 20:44:51,548 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  11173.000  |       N/A\n","2020-11-08 20:44:51,549 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.962  |     0.933\n","2020-11-08 20:44:51,549 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  6731.144  |       N/A\n","2020-11-08 20:44:51,550 - INFO - allennlp.training.tensorboard_writer - loss            |     0.142  |     0.253\n","2020-11-08 20:44:57,052 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/imdb_nas_02/best.th'.\n","2020-11-08 20:44:58,779 - INFO - allennlp.training.trainer - Epoch duration: 0:10:40.604051\n","2020-11-08 20:44:58,779 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:05:15\n","2020-11-08 20:44:58,779 - INFO - allennlp.training.trainer - Epoch 4/9\n","2020-11-08 20:44:58,779 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 6731.148\n","2020-11-08 20:44:58,900 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 11173\n","2020-11-08 20:44:58,904 - INFO - allennlp.training.trainer - Training\n","f1: 0.9694, accuracy: 0.9694, loss: 0.1132 ||: 100%|##########| 2500/2500 [10:05<00:00,  4.13it/s]\n","2020-11-08 20:55:04,325 - INFO - allennlp.training.trainer - Validating\n","f1: 0.9304, accuracy: 0.9304, loss: 0.3072 ||: 100%|##########| 79/79 [00:28<00:00,  2.80it/s]\n","2020-11-08 20:55:32,525 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-08 20:55:32,525 - INFO - allennlp.training.tensorboard_writer - f1              |     0.969  |     0.930\n","2020-11-08 20:55:32,525 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  11173.000  |       N/A\n","2020-11-08 20:55:32,526 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.969  |     0.930\n","2020-11-08 20:55:32,527 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  6731.148  |       N/A\n","2020-11-08 20:55:32,528 - INFO - allennlp.training.tensorboard_writer - loss            |     0.113  |     0.307\n","2020-11-08 20:55:37,913 - INFO - allennlp.training.trainer - Epoch duration: 0:10:39.134165\n","2020-11-08 20:55:37,913 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:54:09\n","2020-11-08 20:55:37,914 - INFO - allennlp.training.trainer - Epoch 5/9\n","2020-11-08 20:55:37,914 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 6731.164\n","2020-11-08 20:55:38,038 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 11173\n","2020-11-08 20:55:38,041 - INFO - allennlp.training.trainer - Training\n","f1: 0.9763, accuracy: 0.9763, loss: 0.0946 ||: 100%|##########| 2500/2500 [10:10<00:00,  4.09it/s]\n","2020-11-08 21:05:48,821 - INFO - allennlp.training.trainer - Validating\n","f1: 0.9294, accuracy: 0.9294, loss: 0.3321 ||: 100%|##########| 79/79 [00:28<00:00,  2.81it/s]\n","2020-11-08 21:06:16,980 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-08 21:06:16,981 - INFO - allennlp.training.tensorboard_writer - f1              |     0.976  |     0.929\n","2020-11-08 21:06:16,982 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  11173.000  |       N/A\n","2020-11-08 21:06:16,982 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.976  |     0.929\n","2020-11-08 21:06:16,982 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  6731.164  |       N/A\n","2020-11-08 21:06:16,983 - INFO - allennlp.training.tensorboard_writer - loss            |     0.095  |     0.332\n","2020-11-08 21:06:22,094 - INFO - allennlp.training.trainer - Epoch duration: 0:10:44.180459\n","2020-11-08 21:06:22,094 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:43:15\n","2020-11-08 21:06:22,094 - INFO - allennlp.training.trainer - Epoch 6/9\n","2020-11-08 21:06:22,094 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 6731.164\n","2020-11-08 21:06:22,221 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 11173\n","2020-11-08 21:06:22,224 - INFO - allennlp.training.trainer - Training\n","f1: 0.9783, accuracy: 0.9783, loss: 0.0887 ||: 100%|##########| 2500/2500 [10:11<00:00,  4.09it/s]\n","2020-11-08 21:16:33,735 - INFO - allennlp.training.trainer - Validating\n","f1: 0.9150, accuracy: 0.9152, loss: 0.3315 ||: 100%|##########| 79/79 [00:28<00:00,  2.80it/s]\n","2020-11-08 21:17:01,928 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.\n","2020-11-08 21:17:01,930 - INFO - allennlp.training.checkpointer - loading best weights\n","2020-11-08 21:17:02,272 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.\n","2020-11-08 21:17:02,273 - INFO - allennlp.training.util - Iterating over dataset\n","f1: 0.93, accuracy: 0.93, loss: 0.25 ||: 100%|##########| 391/391 [02:22<00:00,  2.74it/s]\n","2020-11-08 21:19:25,233 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/imdb_nas_02/model.tar.gz\n","2020-11-08 21:19:49,930 - INFO - allennlp.common.util - Metrics: {\n","  \"best_epoch\": 3,\n","  \"peak_cpu_memory_MB\": 6731.164,\n","  \"peak_gpu_0_memory_MB\": 11173,\n","  \"training_duration\": \"1:04:48.540857\",\n","  \"training_start_epoch\": 0,\n","  \"training_epochs\": 5,\n","  \"epoch\": 5,\n","  \"training_f1\": 0.9762999713420868,\n","  \"training_accuracy\": 0.9763,\n","  \"training_loss\": 0.09457805987573228,\n","  \"training_cpu_memory_MB\": 6731.164,\n","  \"training_gpu_0_memory_MB\": 11173,\n","  \"validation_f1\": 0.9293952584266663,\n","  \"validation_accuracy\": 0.9294,\n","  \"validation_loss\": 0.3321104533822995,\n","  \"best_validation_f1\": 0.9333887696266174,\n","  \"best_validation_accuracy\": 0.9334,\n","  \"best_validation_loss\": 0.2532793358911442,\n","  \"test_f1\": 0.9333075881004333,\n","  \"test_accuracy\": 0.93332,\n","  \"test_loss\": 0.24674800104792693\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dhklKbc2cSB-","executionInfo":{"status":"ok","timestamp":1604884261792,"user_tz":300,"elapsed":12317990,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"207b8e85-4532-4c84-b014-98a190c7700c","colab":{"base_uri":"https://localhost:8080/"}},"source":["!python -m scripts.train \\\n","        --config training_config/classifier.jsonnet \\\n","        --serialization_dir model_logs/amazon_nas_01 \\\n","        --hyperparameters ROBERTA_CLASSIFIER_MINI \\\n","        --dataset amazon \\\n","        --model roberta-base \\\n","        --device 0 \\\n","        --perf +f1 \\\n","        --evaluate_on_test"],"execution_count":14,"outputs":[{"output_type":"stream","text":["2020-11-08 21:45:45,799 - INFO - pytorch_pretrained_bert.modeling - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-08 21:45:46,209 - INFO - pytorch_transformers.modeling_bert - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-08 21:45:46,212 - INFO - pytorch_transformers.modeling_xlnet - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-08 21:45:46,643 - INFO - allennlp.common.params - random_seed = 696112\n","2020-11-08 21:45:46,643 - INFO - allennlp.common.params - numpy_seed = 696112\n","2020-11-08 21:45:46,643 - INFO - allennlp.common.params - pytorch_seed = 696112\n","2020-11-08 21:45:46,650 - INFO - allennlp.common.checks - Pytorch version: 1.7.0+cu101\n","2020-11-08 21:45:46,652 - INFO - allennlp.common.params - evaluate_on_test = True\n","2020-11-08 21:45:46,652 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}, 'type': 'text_classification_json_with_sampling'} and extras set()\n","2020-11-08 21:45:46,652 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling\n","2020-11-08 21:45:46,652 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.data.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}} and extras set()\n","2020-11-08 21:45:46,652 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras set()\n","2020-11-08 21:45:46,653 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.type = pretrained_transformer\n","2020-11-08 21:45:46,653 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base'} and extras set()\n","2020-11-08 21:45:46,653 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.model_name = roberta-base\n","2020-11-08 21:45:46,653 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.do_lowercase = False\n","2020-11-08 21:45:46,653 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.namespace = tags\n","2020-11-08 21:45:46,653 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.token_min_padding_length = 0\n","2020-11-08 21:45:47,388 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-08 21:45:47,389 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-08 21:45:47,458 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 1\n","2020-11-08 21:45:47,459 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'} and extras set()\n","2020-11-08 21:45:47,459 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer\n","2020-11-08 21:45:47,459 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>']} and extras set()\n","2020-11-08 21:45:47,459 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base\n","2020-11-08 21:45:47,459 - INFO - allennlp.common.params - dataset_reader.tokenizer.do_lowercase = False\n","2020-11-08 21:45:47,459 - INFO - allennlp.common.params - dataset_reader.tokenizer.start_tokens = ['<s>']\n","2020-11-08 21:45:47,459 - INFO - allennlp.common.params - dataset_reader.tokenizer.end_tokens = ['</s>']\n","2020-11-08 21:45:48,207 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-08 21:45:48,207 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-08 21:45:48,274 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512\n","2020-11-08 21:45:48,274 - INFO - allennlp.common.params - dataset_reader.sample = None\n","2020-11-08 21:45:48,274 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False\n","2020-11-08 21:45:48,274 - INFO - allennlp.common.params - dataset_reader.lazy = False\n","2020-11-08 21:45:48,274 - INFO - allennlp.training.util - Using a separate dataset reader to load validation and test data.\n","2020-11-08 21:45:48,274 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}, 'type': 'text_classification_json_with_sampling'} and extras set()\n","2020-11-08 21:45:48,275 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling\n","2020-11-08 21:45:48,275 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.data.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}} and extras set()\n","2020-11-08 21:45:48,275 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras set()\n","2020-11-08 21:45:48,275 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.type = pretrained_transformer\n","2020-11-08 21:45:48,275 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base'} and extras set()\n","2020-11-08 21:45:48,275 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.model_name = roberta-base\n","2020-11-08 21:45:48,275 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.do_lowercase = False\n","2020-11-08 21:45:48,275 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.namespace = tags\n","2020-11-08 21:45:48,275 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.token_min_padding_length = 0\n","2020-11-08 21:45:49,052 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-08 21:45:49,052 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-08 21:45:49,125 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 1\n","2020-11-08 21:45:49,125 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'} and extras set()\n","2020-11-08 21:45:49,125 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer\n","2020-11-08 21:45:49,126 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>']} and extras set()\n","2020-11-08 21:45:49,126 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base\n","2020-11-08 21:45:49,126 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.do_lowercase = False\n","2020-11-08 21:45:49,126 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.start_tokens = ['<s>']\n","2020-11-08 21:45:49,126 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.end_tokens = ['</s>']\n","2020-11-08 21:45:49,890 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-08 21:45:49,890 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-08 21:45:49,956 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512\n","2020-11-08 21:45:49,956 - INFO - allennlp.common.params - validation_dataset_reader.sample = None\n","2020-11-08 21:45:49,956 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False\n","2020-11-08 21:45:49,956 - INFO - allennlp.common.params - validation_dataset_reader.lazy = False\n","2020-11-08 21:45:49,956 - INFO - allennlp.common.params - train_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/amazon/train.jsonl\n","2020-11-08 21:45:49,956 - INFO - allennlp.training.util - Reading training data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/amazon/train.jsonl\n","0it [00:00, ?it/s]2020-11-08 21:45:50,636 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/amazon/train.jsonl not found in cache, downloading to /tmp/tmp51qehkpn\n","\n","  0%|          | 0/104941358 [00:00<?, ?B/s]\u001b[A\n","  0%|          | 17408/104941358 [00:00<15:54, 109886.54B/s]\u001b[A\n","  0%|          | 52224/104941358 [00:00<13:31, 129189.18B/s]\u001b[A\n","  0%|          | 103424/104941358 [00:00<11:04, 157720.66B/s]\u001b[A\n","  0%|          | 226304/104941358 [00:00<08:25, 207173.81B/s]\u001b[A\n","  0%|          | 470016/104941358 [00:00<06:13, 279745.28B/s]\u001b[A\n","  1%|          | 992256/104941358 [00:00<04:29, 385528.47B/s]\u001b[A\n","  2%|1         | 2001920/104941358 [00:01<03:11, 536763.60B/s]\u001b[A\n","  4%|3         | 4039680/104941358 [00:01<02:13, 753251.30B/s]\u001b[A\n","  6%|6         | 6530048/104941358 [00:01<01:33, 1054303.67B/s]\u001b[A\n","  8%|8         | 8774656/104941358 [00:01<01:05, 1459394.97B/s]\u001b[A\n"," 11%|#         | 11133952/104941358 [00:01<00:46, 2000284.25B/s]\u001b[A\n"," 13%|#2        | 13444096/104941358 [00:01<00:33, 2697907.43B/s]\u001b[A\n"," 15%|#4        | 15721472/104941358 [00:02<00:25, 3565945.19B/s]\u001b[A\n"," 17%|#7        | 18064384/104941358 [00:02<00:18, 4614259.70B/s]\u001b[A\n"," 19%|#9        | 20374528/104941358 [00:02<00:14, 5800695.49B/s]\u001b[A\n"," 22%|##1       | 22684672/104941358 [00:02<00:11, 7073147.55B/s]\u001b[A\n"," 24%|##3       | 24929280/104941358 [00:02<00:09, 8316883.74B/s]\u001b[A\n"," 26%|##5       | 27173888/104941358 [00:02<00:08, 9479328.49B/s]\u001b[A\n"," 28%|##8       | 29484032/104941358 [00:03<00:07, 10576822.36B/s]\u001b[A\n"," 30%|###       | 31728640/104941358 [00:03<00:06, 11429379.55B/s]\u001b[A\n"," 32%|###2      | 33989632/104941358 [00:03<00:05, 12136778.22B/s]\u001b[A\n"," 34%|###4      | 36119552/104941358 [00:03<00:05, 12482765.64B/s]\u001b[A\n"," 37%|###6      | 38364160/104941358 [00:03<00:05, 12922462.03B/s]\u001b[A\n"," 39%|###8      | 40608768/104941358 [00:03<00:04, 13249655.18B/s]\u001b[A\n"," 41%|####      | 42804224/104941358 [00:03<00:04, 13404928.87B/s]\u001b[A\n"," 43%|####2     | 45016064/104941358 [00:04<00:04, 13542814.29B/s]\u001b[A\n"," 45%|####5     | 47227904/104941358 [00:04<00:04, 13642460.37B/s]\u001b[A\n"," 47%|####7     | 49423360/104941358 [00:04<00:04, 13679393.37B/s]\u001b[A\n"," 49%|####9     | 51586048/104941358 [00:04<00:03, 13650417.85B/s]\u001b[A\n"," 51%|#####1    | 53830656/104941358 [00:04<00:03, 13784026.06B/s]\u001b[A\n"," 53%|#####3    | 55976960/104941358 [00:04<00:03, 13686022.77B/s]\u001b[A\n"," 55%|#####5    | 58188800/104941358 [00:05<00:03, 13751327.00B/s]\u001b[A\n"," 58%|#####7    | 60367872/104941358 [00:05<00:03, 13728434.26B/s]\u001b[A\n"," 60%|#####9    | 62530560/104941358 [00:05<00:03, 13687401.45B/s]\u001b[A\n"," 62%|######1   | 64742400/104941358 [00:05<00:02, 13740617.67B/s]\u001b[A\n"," 64%|######3   | 66921472/104941358 [00:05<00:02, 13725096.30B/s]\u001b[A\n"," 66%|######5   | 69133312/104941358 [00:05<00:02, 13773325.87B/s]\u001b[A\n"," 68%|######7   | 71296000/104941358 [00:06<00:02, 13710128.77B/s]\u001b[A\n"," 70%|#######   | 73475072/104941358 [00:06<00:02, 13707536.85B/s]\u001b[A\n"," 72%|#######2  | 75670528/104941358 [00:06<00:02, 13725270.01B/s]\u001b[A\n"," 74%|#######4  | 77882368/104941358 [00:06<00:01, 13773632.36B/s]\u001b[A\n"," 76%|#######6  | 80061440/104941358 [00:06<00:01, 13743709.46B/s]\u001b[A\n"," 78%|#######8  | 82322432/104941358 [00:06<00:01, 13875910.91B/s]\u001b[A\n"," 81%|########  | 84583424/104941358 [00:07<00:01, 13975429.06B/s]\u001b[A\n"," 83%|########2 | 86828032/104941358 [00:07<00:01, 14008914.81B/s]\u001b[A\n"," 85%|########4 | 89089024/104941358 [00:07<00:01, 14064247.37B/s]\u001b[A\n"," 87%|########7 | 91317248/104941358 [00:07<00:00, 14038010.51B/s]\u001b[A\n"," 89%|########9 | 93611008/104941358 [00:07<00:00, 14143415.68B/s]\u001b[A\n"," 91%|#########1| 95822848/104941358 [00:07<00:00, 14062413.90B/s]\u001b[A\n"," 93%|#########3| 98034688/104941358 [00:07<00:00, 14005774.04B/s]\u001b[A\n"," 96%|#########5| 100312064/104941358 [00:08<00:00, 14095785.64B/s]\u001b[A\n"," 98%|#########7| 102556672/104941358 [00:08<00:00, 14091193.77B/s]\u001b[A\n","100%|##########| 104941358/104941358 [00:08<00:00, 12430718.57B/s]\n","2020-11-08 21:45:59,881 - INFO - allennlp.common.file_utils - copying /tmp/tmp51qehkpn to cache at /root/.allennlp/cache/200c315c21ba2b6318279c6cdead8c6fcc3d41639f604ec02def7b3306cc1c84.24c5781b6fa94d26b3d681a9166e5b0ff61ebc8ade50e772ad90c71c4993dab8\n","2020-11-08 21:45:59,972 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/200c315c21ba2b6318279c6cdead8c6fcc3d41639f604ec02def7b3306cc1c84.24c5781b6fa94d26b3d681a9166e5b0ff61ebc8ade50e772ad90c71c4993dab8\n","2020-11-08 21:45:59,973 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmp51qehkpn\n","115251it [01:56, 985.25it/s] \n","2020-11-08 21:47:46,933 - INFO - allennlp.common.params - validation_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/amazon/dev.jsonl\n","2020-11-08 21:47:46,933 - INFO - allennlp.training.util - Reading validation data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/amazon/dev.jsonl\n","0it [00:00, ?it/s]2020-11-08 21:47:47,624 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/amazon/dev.jsonl not found in cache, downloading to /tmp/tmp51_u5icn\n","\n","  0%|          | 0/4632574 [00:00<?, ?B/s]\u001b[A\n","  0%|          | 17408/4632574 [00:00<00:42, 109836.62B/s]\u001b[A\n","  1%|1         | 52224/4632574 [00:00<00:35, 129120.02B/s]\u001b[A\n","  2%|1         | 87040/4632574 [00:00<00:30, 147176.74B/s]\u001b[A\n","  4%|3         | 174080/4632574 [00:00<00:23, 188460.40B/s]\u001b[A\n","  8%|7         | 365568/4632574 [00:00<00:16, 252292.43B/s]\u001b[A\n"," 16%|#5        | 731136/4632574 [00:00<00:11, 344219.52B/s]\u001b[A\n"," 32%|###1      | 1479680/4632574 [00:01<00:06, 476781.29B/s]\u001b[A\n","100%|##########| 4632574/4632574 [00:01<00:00, 3587570.19B/s]\n","2020-11-08 21:47:49,672 - INFO - allennlp.common.file_utils - copying /tmp/tmp51_u5icn to cache at /root/.allennlp/cache/06ad43ec10dfd657da681d1d7df033b19c8021697abd4d393b82f0f38e1b6e20.7ac46c0a1818dea557db9efab3895099a98ddbc222f81df9a48cf73a6cb7a007\n","2020-11-08 21:47:49,677 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/06ad43ec10dfd657da681d1d7df033b19c8021697abd4d393b82f0f38e1b6e20.7ac46c0a1818dea557db9efab3895099a98ddbc222f81df9a48cf73a6cb7a007\n","2020-11-08 21:47:49,677 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmp51_u5icn\n","5000it [00:07, 683.11it/s] \n","2020-11-08 21:47:54,253 - INFO - allennlp.common.params - test_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/amazon/test.jsonl\n","2020-11-08 21:47:54,253 - INFO - allennlp.training.util - Reading test data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/amazon/test.jsonl\n","0it [00:00, ?it/s]2020-11-08 21:47:54,930 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/amazon/test.jsonl not found in cache, downloading to /tmp/tmp84duzhe5\n","\n","  0%|          | 0/22784750 [00:00<?, ?B/s]\u001b[A\n","  0%|          | 17408/22784750 [00:00<03:31, 107672.82B/s]\u001b[A\n","  0%|          | 52224/22784750 [00:00<02:59, 126533.03B/s]\u001b[A\n","  0%|          | 104448/22784750 [00:00<02:26, 154842.91B/s]\u001b[A\n","  1%|1         | 242688/22784750 [00:00<01:49, 205182.46B/s]\u001b[A\n","  2%|2         | 504832/22784750 [00:00<01:20, 277936.29B/s]\u001b[A\n","  5%|4         | 1027072/22784750 [00:00<00:56, 382843.19B/s]\u001b[A\n","  9%|9         | 2101248/22784750 [00:01<00:38, 533634.88B/s]\u001b[A\n"," 18%|#8        | 4214784/22784750 [00:01<00:24, 749138.90B/s]\u001b[A\n"," 29%|##9       | 6623232/22784750 [00:01<00:15, 1047499.23B/s]\u001b[A\n"," 39%|###8      | 8835072/22784750 [00:01<00:09, 1448503.56B/s]\u001b[A\n"," 49%|####8     | 11079680/22784750 [00:01<00:05, 1980173.45B/s]\u001b[A\n"," 59%|#####8    | 13340672/22784750 [00:01<00:03, 2665970.60B/s]\u001b[A\n"," 68%|######8   | 15536128/22784750 [00:02<00:02, 3511028.74B/s]\u001b[A\n"," 78%|#######7  | 17698816/22784750 [00:02<00:01, 4504913.34B/s]\u001b[A\n"," 87%|########7 | 19910656/22784750 [00:02<00:00, 5634501.17B/s]\u001b[A\n","100%|##########| 22784750/22784750 [00:02<00:00, 8732280.77B/s]\n","2020-11-08 21:47:58,287 - INFO - allennlp.common.file_utils - copying /tmp/tmp84duzhe5 to cache at /root/.allennlp/cache/5d8ad0c71281730236dc5e81129e871727329d92ff61b1b86b2360ebf57dcd84.fe6ce9746b04d11cf1a96d843ad53b4391e612af3e8a1bdef8dd1d5dc6c0d98d\n","2020-11-08 21:47:58,308 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/5d8ad0c71281730236dc5e81129e871727329d92ff61b1b86b2360ebf57dcd84.fe6ce9746b04d11cf1a96d843ad53b4391e612af3e8a1bdef8dd1d5dc6c0d98d\n","2020-11-08 21:47:58,308 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmp84duzhe5\n","25000it [00:28, 878.28it/s] \n","2020-11-08 21:48:22,958 - INFO - allennlp.training.trainer_pieces - From dataset instances, validation, test, train will be considered for vocabulary creation.\n","2020-11-08 21:48:22,958 - INFO - allennlp.common.params - vocabulary.type = None\n","2020-11-08 21:48:22,958 - INFO - allennlp.common.params - vocabulary.extend = False\n","2020-11-08 21:48:22,958 - INFO - allennlp.common.params - vocabulary.directory_path = None\n","2020-11-08 21:48:22,959 - INFO - allennlp.common.params - vocabulary.min_count = None\n","2020-11-08 21:48:22,959 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None\n","2020-11-08 21:48:22,959 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')\n","2020-11-08 21:48:22,959 - INFO - allennlp.common.params - vocabulary.pretrained_files = {}\n","2020-11-08 21:48:22,959 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None\n","2020-11-08 21:48:22,959 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False\n","2020-11-08 21:48:22,959 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None\n","2020-11-08 21:48:22,959 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n","145251it [00:02, 48959.67it/s]\n","2020-11-08 21:48:25,926 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'dropout': '0.1', 'feedforward_layer': {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1}, 'seq2vec_encoder': {'embedding_dim': 768, 'type': 'cls_pooler'}, 'text_field_embedder': {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'type': 'basic_classifier_with_f1'} and extras {'vocab'}\n","2020-11-08 21:48:25,926 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1\n","2020-11-08 21:48:25,927 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.models.basic_classifier_with_f1.BasicClassifierWithF1'> from params {'dropout': '0.1', 'feedforward_layer': {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1}, 'seq2vec_encoder': {'embedding_dim': 768, 'type': 'cls_pooler'}, 'text_field_embedder': {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}} and extras {'vocab'}\n","2020-11-08 21:48:25,927 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}} and extras {'vocab'}\n","2020-11-08 21:48:25,927 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n","2020-11-08 21:48:25,927 - INFO - allennlp.common.params - model.text_field_embedder.embedder_to_indexer_map = None\n","2020-11-08 21:48:25,927 - INFO - allennlp.common.params - model.text_field_embedder.allow_unmatched_keys = False\n","2020-11-08 21:48:25,927 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders = None\n","2020-11-08 21:48:25,927 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras {'vocab'}\n","2020-11-08 21:48:25,928 - INFO - allennlp.common.params - model.text_field_embedder.roberta.type = pretrained_transformer\n","2020-11-08 21:48:25,928 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.pretrained_transformer_embedder.PretrainedTransformerEmbedder'> from params {'model_name': 'roberta-base'} and extras {'vocab'}\n","2020-11-08 21:48:25,928 - INFO - allennlp.common.params - model.text_field_embedder.roberta.model_name = roberta-base\n","2020-11-08 21:48:26,302 - INFO - pytorch_transformers.modeling_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/pytorch_transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n","2020-11-08 21:48:26,303 - INFO - pytorch_transformers.modeling_utils - Model config {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 1,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","2020-11-08 21:48:26,680 - INFO - pytorch_transformers.modeling_utils - loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n","2020-11-08 21:48:30,757 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'embedding_dim': 768, 'type': 'cls_pooler'} and extras {'vocab'}\n","2020-11-08 21:48:30,757 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler\n","2020-11-08 21:48:30,757 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.modules.seq2vec_encoders.cls_pooler.CLSPooler'> from params {'embedding_dim': 768} and extras {'vocab'}\n","2020-11-08 21:48:30,757 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768\n","2020-11-08 21:48:30,758 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1} and extras {'vocab'}\n","2020-11-08 21:48:30,758 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768\n","2020-11-08 21:48:30,758 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1\n","2020-11-08 21:48:30,758 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768\n","2020-11-08 21:48:30,758 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh\n","2020-11-08 21:48:30,758 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0\n","2020-11-08 21:48:30,763 - INFO - allennlp.common.params - model.dropout = 0.1\n","2020-11-08 21:48:30,763 - INFO - allennlp.common.params - model.num_labels = None\n","2020-11-08 21:48:30,763 - INFO - allennlp.common.params - model.label_namespace = labels\n","2020-11-08 21:48:30,763 - INFO - allennlp.nn.initializers - Initializing parameters\n","2020-11-08 21:48:30,765 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n","2020-11-08 21:48:30,765 - INFO - allennlp.nn.initializers -    _classification_layer.bias\n","2020-11-08 21:48:30,765 - INFO - allennlp.nn.initializers -    _classification_layer.weight\n","2020-11-08 21:48:30,765 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias\n","2020-11-08 21:48:30,765 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight\n","2020-11-08 21:48:30,765 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias\n","2020-11-08 21:48:30,765 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight\n","2020-11-08 21:48:30,765 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight\n","2020-11-08 21:48:30,765 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias\n","2020-11-08 21:48:30,766 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias\n","2020-11-08 21:48:30,767 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight\n","2020-11-08 21:48:30,768 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias\n","2020-11-08 21:48:30,769 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight\n","2020-11-08 21:48:30,769 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,769 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,769 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias\n","2020-11-08 21:48:30,769 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight\n","2020-11-08 21:48:30,769 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias\n","2020-11-08 21:48:30,769 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight\n","2020-11-08 21:48:30,769 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias\n","2020-11-08 21:48:30,769 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight\n","2020-11-08 21:48:30,769 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias\n","2020-11-08 21:48:30,769 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight\n","2020-11-08 21:48:30,769 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias\n","2020-11-08 21:48:30,769 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight\n","2020-11-08 21:48:30,769 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias\n","2020-11-08 21:48:30,769 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight\n","2020-11-08 21:48:30,769 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias\n","2020-11-08 21:48:30,769 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight\n","2020-11-08 21:48:30,769 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,791 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,791 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias\n","2020-11-08 21:48:30,791 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight\n","2020-11-08 21:48:30,791 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias\n","2020-11-08 21:48:30,791 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight\n","2020-11-08 21:48:30,791 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias\n","2020-11-08 21:48:30,791 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight\n","2020-11-08 21:48:30,791 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias\n","2020-11-08 21:48:30,792 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight\n","2020-11-08 21:48:30,792 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias\n","2020-11-08 21:48:30,792 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight\n","2020-11-08 21:48:30,792 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias\n","2020-11-08 21:48:30,792 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight\n","2020-11-08 21:48:30,792 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias\n","2020-11-08 21:48:30,792 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight\n","2020-11-08 21:48:30,792 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,792 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,792 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias\n","2020-11-08 21:48:30,792 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight\n","2020-11-08 21:48:30,792 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias\n","2020-11-08 21:48:30,792 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight\n","2020-11-08 21:48:30,792 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias\n","2020-11-08 21:48:30,793 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight\n","2020-11-08 21:48:30,793 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias\n","2020-11-08 21:48:30,793 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight\n","2020-11-08 21:48:30,793 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias\n","2020-11-08 21:48:30,793 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight\n","2020-11-08 21:48:30,793 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias\n","2020-11-08 21:48:30,793 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight\n","2020-11-08 21:48:30,793 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias\n","2020-11-08 21:48:30,793 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight\n","2020-11-08 21:48:30,793 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,793 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,793 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias\n","2020-11-08 21:48:30,793 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight\n","2020-11-08 21:48:30,793 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias\n","2020-11-08 21:48:30,794 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight\n","2020-11-08 21:48:30,794 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias\n","2020-11-08 21:48:30,794 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight\n","2020-11-08 21:48:30,794 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias\n","2020-11-08 21:48:30,794 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight\n","2020-11-08 21:48:30,794 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias\n","2020-11-08 21:48:30,794 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight\n","2020-11-08 21:48:30,794 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias\n","2020-11-08 21:48:30,794 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight\n","2020-11-08 21:48:30,794 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias\n","2020-11-08 21:48:30,794 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight\n","2020-11-08 21:48:30,794 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,795 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,795 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias\n","2020-11-08 21:48:30,795 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight\n","2020-11-08 21:48:30,795 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias\n","2020-11-08 21:48:30,795 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight\n","2020-11-08 21:48:30,795 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias\n","2020-11-08 21:48:30,795 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight\n","2020-11-08 21:48:30,795 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias\n","2020-11-08 21:48:30,795 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight\n","2020-11-08 21:48:30,795 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias\n","2020-11-08 21:48:30,795 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight\n","2020-11-08 21:48:30,795 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias\n","2020-11-08 21:48:30,795 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight\n","2020-11-08 21:48:30,795 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias\n","2020-11-08 21:48:30,796 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight\n","2020-11-08 21:48:30,796 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,796 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,796 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias\n","2020-11-08 21:48:30,796 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight\n","2020-11-08 21:48:30,796 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias\n","2020-11-08 21:48:30,796 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight\n","2020-11-08 21:48:30,796 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias\n","2020-11-08 21:48:30,796 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight\n","2020-11-08 21:48:30,796 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias\n","2020-11-08 21:48:30,796 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight\n","2020-11-08 21:48:30,796 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias\n","2020-11-08 21:48:30,796 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight\n","2020-11-08 21:48:30,796 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias\n","2020-11-08 21:48:30,796 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight\n","2020-11-08 21:48:30,797 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias\n","2020-11-08 21:48:30,797 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight\n","2020-11-08 21:48:30,797 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,797 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,797 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias\n","2020-11-08 21:48:30,797 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight\n","2020-11-08 21:48:30,797 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias\n","2020-11-08 21:48:30,797 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight\n","2020-11-08 21:48:30,797 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias\n","2020-11-08 21:48:30,797 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight\n","2020-11-08 21:48:30,797 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias\n","2020-11-08 21:48:30,797 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight\n","2020-11-08 21:48:30,797 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias\n","2020-11-08 21:48:30,797 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight\n","2020-11-08 21:48:30,798 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias\n","2020-11-08 21:48:30,798 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight\n","2020-11-08 21:48:30,798 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias\n","2020-11-08 21:48:30,798 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight\n","2020-11-08 21:48:30,798 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias\n","2020-11-08 21:48:30,798 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight\n","2020-11-08 21:48:30,799 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 8, 'sorting_keys': [['tokens', 'num_tokens']], 'type': 'bucket'} and extras set()\n","2020-11-08 21:48:30,799 - INFO - allennlp.common.params - iterator.type = bucket\n","2020-11-08 21:48:30,799 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 8, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()\n","2020-11-08 21:48:30,800 - INFO - allennlp.common.params - iterator.sorting_keys = [['tokens', 'num_tokens']]\n","2020-11-08 21:48:30,800 - INFO - allennlp.common.params - iterator.padding_noise = 0.1\n","2020-11-08 21:48:30,800 - INFO - allennlp.common.params - iterator.biggest_batch_first = False\n","2020-11-08 21:48:30,800 - INFO - allennlp.common.params - iterator.batch_size = 8\n","2020-11-08 21:48:30,800 - INFO - allennlp.common.params - iterator.instances_per_epoch = None\n","2020-11-08 21:48:30,800 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None\n","2020-11-08 21:48:30,800 - INFO - allennlp.common.params - iterator.cache_instances = False\n","2020-11-08 21:48:30,800 - INFO - allennlp.common.params - iterator.track_epoch = False\n","2020-11-08 21:48:30,800 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None\n","2020-11-08 21:48:30,800 - INFO - allennlp.common.params - iterator.skip_smaller_batches = False\n","2020-11-08 21:48:30,800 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'sorting_keys': [['tokens', 'num_tokens']], 'type': 'bucket'} and extras set()\n","2020-11-08 21:48:30,800 - INFO - allennlp.common.params - validation_iterator.type = bucket\n","2020-11-08 21:48:30,800 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 64, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()\n","2020-11-08 21:48:30,800 - INFO - allennlp.common.params - validation_iterator.sorting_keys = [['tokens', 'num_tokens']]\n","2020-11-08 21:48:30,800 - INFO - allennlp.common.params - validation_iterator.padding_noise = 0.1\n","2020-11-08 21:48:30,801 - INFO - allennlp.common.params - validation_iterator.biggest_batch_first = False\n","2020-11-08 21:48:30,801 - INFO - allennlp.common.params - validation_iterator.batch_size = 64\n","2020-11-08 21:48:30,801 - INFO - allennlp.common.params - validation_iterator.instances_per_epoch = None\n","2020-11-08 21:48:30,801 - INFO - allennlp.common.params - validation_iterator.max_instances_in_memory = None\n","2020-11-08 21:48:30,801 - INFO - allennlp.common.params - validation_iterator.cache_instances = False\n","2020-11-08 21:48:30,801 - INFO - allennlp.common.params - validation_iterator.track_epoch = False\n","2020-11-08 21:48:30,801 - INFO - allennlp.common.params - validation_iterator.maximum_samples_per_batch = None\n","2020-11-08 21:48:30,801 - INFO - allennlp.common.params - validation_iterator.skip_smaller_batches = False\n","2020-11-08 21:48:30,801 - INFO - allennlp.common.params - trainer.no_grad = ()\n","2020-11-08 21:48:30,803 - INFO - allennlp.training.trainer_pieces - Following parameters are Frozen  (without gradient):\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - Following parameters are Tunable (with gradient):\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight\n","2020-11-08 21:48:30,804 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight\n","2020-11-08 21:48:30,805 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias\n","2020-11-08 21:48:30,806 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight\n","2020-11-08 21:48:30,806 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias\n","2020-11-08 21:48:30,806 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight\n","2020-11-08 21:48:30,806 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias\n","2020-11-08 21:48:30,806 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,806 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,806 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight\n","2020-11-08 21:48:30,806 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias\n","2020-11-08 21:48:30,806 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight\n","2020-11-08 21:48:30,806 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias\n","2020-11-08 21:48:30,806 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight\n","2020-11-08 21:48:30,806 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias\n","2020-11-08 21:48:30,806 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight\n","2020-11-08 21:48:30,806 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias\n","2020-11-08 21:48:30,806 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight\n","2020-11-08 21:48:30,806 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias\n","2020-11-08 21:48:30,806 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight\n","2020-11-08 21:48:30,806 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias\n","2020-11-08 21:48:30,899 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight\n","2020-11-08 21:48:30,899 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias\n","2020-11-08 21:48:30,899 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,899 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,899 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight\n","2020-11-08 21:48:30,899 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias\n","2020-11-08 21:48:30,899 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight\n","2020-11-08 21:48:30,899 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias\n","2020-11-08 21:48:30,899 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight\n","2020-11-08 21:48:30,900 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias\n","2020-11-08 21:48:30,900 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight\n","2020-11-08 21:48:30,900 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias\n","2020-11-08 21:48:30,900 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight\n","2020-11-08 21:48:30,900 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias\n","2020-11-08 21:48:30,900 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight\n","2020-11-08 21:48:30,900 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias\n","2020-11-08 21:48:30,900 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight\n","2020-11-08 21:48:30,900 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias\n","2020-11-08 21:48:30,900 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,900 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,900 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight\n","2020-11-08 21:48:30,900 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias\n","2020-11-08 21:48:30,900 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight\n","2020-11-08 21:48:30,900 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias\n","2020-11-08 21:48:30,901 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight\n","2020-11-08 21:48:30,901 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias\n","2020-11-08 21:48:30,901 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight\n","2020-11-08 21:48:30,901 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias\n","2020-11-08 21:48:30,901 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight\n","2020-11-08 21:48:30,901 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias\n","2020-11-08 21:48:30,901 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight\n","2020-11-08 21:48:30,901 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias\n","2020-11-08 21:48:30,901 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight\n","2020-11-08 21:48:30,901 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias\n","2020-11-08 21:48:30,901 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,901 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,901 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight\n","2020-11-08 21:48:30,901 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias\n","2020-11-08 21:48:30,901 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight\n","2020-11-08 21:48:30,902 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias\n","2020-11-08 21:48:30,902 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight\n","2020-11-08 21:48:30,902 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias\n","2020-11-08 21:48:30,902 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight\n","2020-11-08 21:48:30,902 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias\n","2020-11-08 21:48:30,902 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight\n","2020-11-08 21:48:30,902 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias\n","2020-11-08 21:48:30,902 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight\n","2020-11-08 21:48:30,902 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias\n","2020-11-08 21:48:30,902 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight\n","2020-11-08 21:48:30,902 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias\n","2020-11-08 21:48:30,902 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,902 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,902 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight\n","2020-11-08 21:48:30,902 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias\n","2020-11-08 21:48:30,903 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight\n","2020-11-08 21:48:30,903 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias\n","2020-11-08 21:48:30,903 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight\n","2020-11-08 21:48:30,903 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias\n","2020-11-08 21:48:30,903 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight\n","2020-11-08 21:48:30,903 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias\n","2020-11-08 21:48:30,903 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight\n","2020-11-08 21:48:30,903 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias\n","2020-11-08 21:48:30,903 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight\n","2020-11-08 21:48:30,903 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias\n","2020-11-08 21:48:30,903 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight\n","2020-11-08 21:48:30,903 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias\n","2020-11-08 21:48:30,903 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,903 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,903 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight\n","2020-11-08 21:48:30,903 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias\n","2020-11-08 21:48:30,904 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight\n","2020-11-08 21:48:30,904 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias\n","2020-11-08 21:48:30,904 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight\n","2020-11-08 21:48:30,904 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias\n","2020-11-08 21:48:30,904 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight\n","2020-11-08 21:48:30,904 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias\n","2020-11-08 21:48:30,904 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight\n","2020-11-08 21:48:30,904 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias\n","2020-11-08 21:48:30,904 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight\n","2020-11-08 21:48:30,904 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias\n","2020-11-08 21:48:30,904 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight\n","2020-11-08 21:48:30,904 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias\n","2020-11-08 21:48:30,904 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,904 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,904 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight\n","2020-11-08 21:48:30,905 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias\n","2020-11-08 21:48:30,905 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight\n","2020-11-08 21:48:30,905 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias\n","2020-11-08 21:48:30,905 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight\n","2020-11-08 21:48:30,905 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias\n","2020-11-08 21:48:30,905 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight\n","2020-11-08 21:48:30,905 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias\n","2020-11-08 21:48:30,905 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight\n","2020-11-08 21:48:30,905 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias\n","2020-11-08 21:48:30,905 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight\n","2020-11-08 21:48:30,905 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias\n","2020-11-08 21:48:30,905 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight\n","2020-11-08 21:48:30,905 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias\n","2020-11-08 21:48:30,905 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,905 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,905 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight\n","2020-11-08 21:48:30,906 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias\n","2020-11-08 21:48:30,906 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight\n","2020-11-08 21:48:30,906 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias\n","2020-11-08 21:48:30,906 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight\n","2020-11-08 21:48:30,906 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias\n","2020-11-08 21:48:30,906 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight\n","2020-11-08 21:48:30,906 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias\n","2020-11-08 21:48:30,906 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight\n","2020-11-08 21:48:30,906 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias\n","2020-11-08 21:48:30,906 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight\n","2020-11-08 21:48:30,906 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias\n","2020-11-08 21:48:30,906 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight\n","2020-11-08 21:48:30,906 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias\n","2020-11-08 21:48:30,906 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n","2020-11-08 21:48:30,906 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n","2020-11-08 21:48:30,907 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight\n","2020-11-08 21:48:30,907 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias\n","2020-11-08 21:48:30,907 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight\n","2020-11-08 21:48:30,907 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias\n","2020-11-08 21:48:30,907 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight\n","2020-11-08 21:48:30,907 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias\n","2020-11-08 21:48:30,907 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight\n","2020-11-08 21:48:30,907 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias\n","2020-11-08 21:48:30,907 - INFO - allennlp.training.trainer_pieces - _feedforward_layer._linear_layers.0.weight\n","2020-11-08 21:48:30,907 - INFO - allennlp.training.trainer_pieces - _feedforward_layer._linear_layers.0.bias\n","2020-11-08 21:48:30,907 - INFO - allennlp.training.trainer_pieces - _classification_layer.weight\n","2020-11-08 21:48:30,907 - INFO - allennlp.training.trainer_pieces - _classification_layer.bias\n","2020-11-08 21:48:30,908 - INFO - allennlp.common.params - trainer.patience = 3\n","2020-11-08 21:48:30,908 - INFO - allennlp.common.params - trainer.validation_metric = +f1\n","2020-11-08 21:48:30,908 - INFO - allennlp.common.params - trainer.shuffle = True\n","2020-11-08 21:48:30,908 - INFO - allennlp.common.params - trainer.num_epochs = 10\n","2020-11-08 21:48:30,908 - INFO - allennlp.common.params - trainer.cuda_device = 0\n","2020-11-08 21:48:30,908 - INFO - allennlp.common.params - trainer.grad_norm = None\n","2020-11-08 21:48:30,908 - INFO - allennlp.common.params - trainer.grad_clipping = None\n","2020-11-08 21:48:30,908 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None\n","2020-11-08 21:48:30,908 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n","2020-11-08 21:48:30,908 - INFO - allennlp.common.params - trainer.gradient_accumulation_batch_size = 8\n","2020-11-08 21:48:35,297 - INFO - allennlp.common.params - trainer.optimizer.type = bert_adam\n","2020-11-08 21:48:35,297 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n","2020-11-08 21:48:35,297 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n","2020-11-08 21:48:35,297 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups.0.1.weight_decay = 0\n","2020-11-08 21:48:35,298 - INFO - allennlp.training.optimizers - Done constructing parameter groups.\n","2020-11-08 21:48:35,298 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias', '_classification_layer.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias', '_feedforward_layer._linear_layers.0.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight'], {'weight_decay': 0}\n","2020-11-08 21:48:35,326 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight', '_feedforward_layer._linear_layers.0.weight', '_classification_layer.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight'], {}\n","2020-11-08 21:48:35,327 - WARNING - allennlp.training.optimizers - When constructing parameter groups,  layer_norm.weight not match any parameter name\n","2020-11-08 21:48:35,327 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125237762\n","2020-11-08 21:48:35,328 - INFO - allennlp.common.params - trainer.optimizer.infer_type_and_cast = True\n","2020-11-08 21:48:35,328 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n","2020-11-08 21:48:35,328 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n","2020-11-08 21:48:35,328 - INFO - allennlp.common.params - trainer.optimizer.b1 = 0.9\n","2020-11-08 21:48:35,329 - INFO - allennlp.common.params - trainer.optimizer.b2 = 0.98\n","2020-11-08 21:48:35,329 - INFO - allennlp.common.params - trainer.optimizer.e = 1e-06\n","2020-11-08 21:48:35,329 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05\n","2020-11-08 21:48:35,329 - INFO - allennlp.common.params - trainer.optimizer.max_grad_norm = 1\n","2020-11-08 21:48:35,329 - INFO - allennlp.common.params - trainer.optimizer.schedule = warmup_linear\n","2020-11-08 21:48:35,329 - INFO - allennlp.common.params - trainer.optimizer.t_total = -1\n","2020-11-08 21:48:35,329 - INFO - allennlp.common.params - trainer.optimizer.warmup = 0.06\n","2020-11-08 21:48:35,329 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1\n","2020-11-08 21:48:35,329 - WARNING - pytorch_pretrained_bert.optimization - t_total value of -1 results in schedule not being applied\n","2020-11-08 21:48:35,330 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 0\n","2020-11-08 21:48:35,330 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None\n","2020-11-08 21:48:35,330 - INFO - allennlp.common.params - trainer.model_save_interval = None\n","2020-11-08 21:48:35,330 - INFO - allennlp.common.params - trainer.summary_interval = 100\n","2020-11-08 21:48:35,330 - INFO - allennlp.common.params - trainer.histogram_interval = None\n","2020-11-08 21:48:35,330 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True\n","2020-11-08 21:48:35,330 - INFO - allennlp.common.params - trainer.should_log_learning_rate = False\n","2020-11-08 21:48:35,330 - INFO - allennlp.common.params - trainer.log_batch_size_period = None\n","2020-11-08 21:48:35,333 - INFO - allennlp.training.trainer - Beginning training.\n","2020-11-08 21:48:35,333 - INFO - allennlp.training.trainer - Epoch 0/9\n","2020-11-08 21:48:35,333 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8383.012\n","2020-11-08 21:48:35,479 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1769\n","2020-11-08 21:48:35,482 - INFO - allennlp.training.trainer - Training\n","  0%|          | 0/14407 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","f1: 0.4946, accuracy: 0.8522, loss: 0.4015 ||: 100%|##########| 14407/14407 [49:37<00:00,  4.84it/s]\n","2020-11-08 22:38:12,955 - INFO - allennlp.training.trainer - Validating\n","f1: 0.4633, accuracy: 0.8538, loss: 0.4160 ||: 100%|##########| 79/79 [00:19<00:00,  3.99it/s]\n","2020-11-08 22:38:32,765 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-08 22:38:32,766 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  1769.000  |       N/A\n","2020-11-08 22:38:32,767 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.852  |     0.854\n","2020-11-08 22:38:32,768 - INFO - allennlp.training.tensorboard_writer - loss            |     0.402  |     0.416\n","2020-11-08 22:38:32,768 - INFO - allennlp.training.tensorboard_writer - f1              |     0.495  |     0.463\n","2020-11-08 22:38:32,768 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  8383.012  |       N/A\n","2020-11-08 22:38:38,311 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/amazon_nas_01/best.th'.\n","2020-11-08 22:38:39,872 - INFO - allennlp.training.trainer - Epoch duration: 0:50:04.539084\n","2020-11-08 22:38:39,874 - INFO - allennlp.training.trainer - Estimated training time remaining: 7:30:40\n","2020-11-08 22:38:39,874 - INFO - allennlp.training.trainer - Epoch 1/9\n","2020-11-08 22:38:39,874 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8822.564\n","2020-11-08 22:38:40,704 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 7899\n","2020-11-08 22:38:40,708 - INFO - allennlp.training.trainer - Training\n","f1: 0.4614, accuracy: 0.8531, loss: 0.4188 ||: 100%|##########| 14407/14407 [50:12<00:00,  4.78it/s]\n","2020-11-08 23:28:53,230 - INFO - allennlp.training.trainer - Validating\n","f1: 0.4605, accuracy: 0.8534, loss: 0.4193 ||: 100%|##########| 79/79 [00:18<00:00,  4.26it/s]\n","2020-11-08 23:29:11,786 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-08 23:29:11,787 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  7899.000  |       N/A\n","2020-11-08 23:29:11,787 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.853  |     0.853\n","2020-11-08 23:29:11,787 - INFO - allennlp.training.tensorboard_writer - loss            |     0.419  |     0.419\n","2020-11-08 23:29:11,788 - INFO - allennlp.training.tensorboard_writer - f1              |     0.461  |     0.460\n","2020-11-08 23:29:11,789 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  8822.564  |       N/A\n","2020-11-08 23:29:17,620 - INFO - allennlp.training.trainer - Epoch duration: 0:50:37.746031\n","2020-11-08 23:29:17,621 - INFO - allennlp.training.trainer - Estimated training time remaining: 6:42:49\n","2020-11-08 23:29:17,621 - INFO - allennlp.training.trainer - Epoch 2/9\n","2020-11-08 23:29:17,621 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8825.924\n","2020-11-08 23:29:17,783 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 11277\n","2020-11-08 23:29:17,786 - INFO - allennlp.training.trainer - Training\n","f1: 0.4611, accuracy: 0.8530, loss: 0.4167 ||: 100%|##########| 14407/14407 [48:44<00:00,  4.93it/s]\n","2020-11-09 00:18:02,423 - INFO - allennlp.training.trainer - Validating\n","f1: 0.4605, accuracy: 0.8534, loss: 0.4164 ||: 100%|##########| 79/79 [00:18<00:00,  4.25it/s]\n","2020-11-09 00:18:21,011 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 00:18:21,012 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  11277.000  |       N/A\n","2020-11-09 00:18:21,013 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.853  |     0.853\n","2020-11-09 00:18:21,013 - INFO - allennlp.training.tensorboard_writer - loss            |     0.417  |     0.416\n","2020-11-09 00:18:21,013 - INFO - allennlp.training.tensorboard_writer - f1              |     0.461  |     0.460\n","2020-11-09 00:18:21,015 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  8825.924  |       N/A\n","2020-11-09 00:18:26,542 - INFO - allennlp.training.trainer - Epoch duration: 0:49:08.921372\n","2020-11-09 00:18:26,542 - INFO - allennlp.training.trainer - Estimated training time remaining: 5:49:39\n","2020-11-09 00:18:26,542 - INFO - allennlp.training.trainer - Epoch 3/9\n","2020-11-09 00:18:26,542 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8825.924\n","2020-11-09 00:18:26,707 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 11277\n","2020-11-09 00:18:26,710 - INFO - allennlp.training.trainer - Training\n","f1: 0.4618, accuracy: 0.8530, loss: 0.4193 ||: 100%|##########| 14407/14407 [49:59<00:00,  4.80it/s]\n","2020-11-09 01:08:26,429 - INFO - allennlp.training.trainer - Validating\n","f1: 0.4605, accuracy: 0.8534, loss: 0.4294 ||: 100%|##########| 79/79 [00:18<00:00,  4.23it/s]\n","2020-11-09 01:08:45,087 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.\n","2020-11-09 01:08:45,088 - INFO - allennlp.training.checkpointer - loading best weights\n","2020-11-09 01:08:45,495 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.\n","2020-11-09 01:08:45,496 - INFO - allennlp.training.util - Iterating over dataset\n","f1: 0.46, accuracy: 0.85, loss: 0.42 ||: 100%|##########| 391/391 [01:35<00:00,  4.08it/s]\n","2020-11-09 01:10:21,349 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/amazon_nas_01/model.tar.gz\n","2020-11-09 01:10:48,890 - INFO - allennlp.common.util - Metrics: {\n","  \"best_epoch\": 0,\n","  \"peak_cpu_memory_MB\": 8825.924,\n","  \"peak_gpu_0_memory_MB\": 11277,\n","  \"training_duration\": \"2:29:45.682370\",\n","  \"training_start_epoch\": 0,\n","  \"training_epochs\": 2,\n","  \"epoch\": 2,\n","  \"training_f1\": 0.4611085128854029,\n","  \"training_accuracy\": 0.853042489869936,\n","  \"training_loss\": 0.4167136814201921,\n","  \"training_cpu_memory_MB\": 8825.924,\n","  \"training_gpu_0_memory_MB\": 11277,\n","  \"validation_f1\": 0.46045106649398804,\n","  \"validation_accuracy\": 0.8534,\n","  \"validation_loss\": 0.416424483815326,\n","  \"best_validation_f1\": 0.46327154571190476,\n","  \"best_validation_accuracy\": 0.8538,\n","  \"best_validation_loss\": 0.4160105521920361,\n","  \"test_f1\": 0.4634904956910759,\n","  \"test_accuracy\": 0.85364,\n","  \"test_loss\": 0.4192020057717248\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b9t7FMWEq0be","executionInfo":{"status":"ok","timestamp":1604886167659,"user_tz":300,"elapsed":682,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"c1cea962-232c-4077-944c-75cc7c16c7e0","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(\"do the rest\")"],"execution_count":15,"outputs":[{"output_type":"stream","text":["do the rest\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"anH0mWh50nY-","executionInfo":{"status":"ok","timestamp":1604887164589,"user_tz":300,"elapsed":997606,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"a4727d22-8b06-489b-f2e4-916bc1576e99","colab":{"base_uri":"https://localhost:8080/"}},"source":["!python -m scripts.train \\\n","        --config training_config/classifier.jsonnet \\\n","        --serialization_dir model_logs/chemprot_nas_01 \\\n","        --hyperparameters ROBERTA_CLASSIFIER_MINI \\\n","        --dataset chemprot \\\n","        --model roberta-base \\\n","        --device 0 \\\n","        --perf +f1 \\\n","        --evaluate_on_test"],"execution_count":16,"outputs":[{"output_type":"stream","text":["2020-11-09 01:42:49,612 - INFO - pytorch_pretrained_bert.modeling - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-09 01:42:50,038 - INFO - pytorch_transformers.modeling_bert - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-09 01:42:50,041 - INFO - pytorch_transformers.modeling_xlnet - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-09 01:42:50,494 - INFO - allennlp.common.params - random_seed = 38992\n","2020-11-09 01:42:50,495 - INFO - allennlp.common.params - numpy_seed = 38992\n","2020-11-09 01:42:50,495 - INFO - allennlp.common.params - pytorch_seed = 38992\n","2020-11-09 01:42:50,502 - INFO - allennlp.common.checks - Pytorch version: 1.7.0+cu101\n","2020-11-09 01:42:50,504 - INFO - allennlp.common.params - evaluate_on_test = True\n","2020-11-09 01:42:50,504 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}, 'type': 'text_classification_json_with_sampling'} and extras set()\n","2020-11-09 01:42:50,504 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling\n","2020-11-09 01:42:50,505 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.data.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}} and extras set()\n","2020-11-09 01:42:50,505 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 01:42:50,505 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.type = pretrained_transformer\n","2020-11-09 01:42:50,505 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base'} and extras set()\n","2020-11-09 01:42:50,505 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.model_name = roberta-base\n","2020-11-09 01:42:50,505 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.do_lowercase = False\n","2020-11-09 01:42:50,505 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.namespace = tags\n","2020-11-09 01:42:50,505 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.token_min_padding_length = 0\n","2020-11-09 01:42:51,320 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 01:42:51,320 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 01:42:51,393 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 1\n","2020-11-09 01:42:51,394 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 01:42:51,394 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer\n","2020-11-09 01:42:51,394 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>']} and extras set()\n","2020-11-09 01:42:51,394 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base\n","2020-11-09 01:42:51,394 - INFO - allennlp.common.params - dataset_reader.tokenizer.do_lowercase = False\n","2020-11-09 01:42:51,394 - INFO - allennlp.common.params - dataset_reader.tokenizer.start_tokens = ['<s>']\n","2020-11-09 01:42:51,394 - INFO - allennlp.common.params - dataset_reader.tokenizer.end_tokens = ['</s>']\n","2020-11-09 01:42:52,131 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 01:42:52,131 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 01:42:52,199 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512\n","2020-11-09 01:42:52,199 - INFO - allennlp.common.params - dataset_reader.sample = None\n","2020-11-09 01:42:52,199 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False\n","2020-11-09 01:42:52,199 - INFO - allennlp.common.params - dataset_reader.lazy = False\n","2020-11-09 01:42:52,199 - INFO - allennlp.training.util - Using a separate dataset reader to load validation and test data.\n","2020-11-09 01:42:52,200 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}, 'type': 'text_classification_json_with_sampling'} and extras set()\n","2020-11-09 01:42:52,200 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling\n","2020-11-09 01:42:52,200 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.data.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}} and extras set()\n","2020-11-09 01:42:52,200 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 01:42:52,200 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.type = pretrained_transformer\n","2020-11-09 01:42:52,200 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base'} and extras set()\n","2020-11-09 01:42:52,200 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.model_name = roberta-base\n","2020-11-09 01:42:52,200 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.do_lowercase = False\n","2020-11-09 01:42:52,200 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.namespace = tags\n","2020-11-09 01:42:52,201 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.token_min_padding_length = 0\n","2020-11-09 01:42:52,953 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 01:42:52,953 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 01:42:53,025 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 1\n","2020-11-09 01:42:53,025 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 01:42:53,025 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer\n","2020-11-09 01:42:53,026 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>']} and extras set()\n","2020-11-09 01:42:53,026 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base\n","2020-11-09 01:42:53,026 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.do_lowercase = False\n","2020-11-09 01:42:53,026 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.start_tokens = ['<s>']\n","2020-11-09 01:42:53,026 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.end_tokens = ['</s>']\n","2020-11-09 01:42:53,762 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 01:42:53,762 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 01:42:53,832 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512\n","2020-11-09 01:42:53,832 - INFO - allennlp.common.params - validation_dataset_reader.sample = None\n","2020-11-09 01:42:53,832 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False\n","2020-11-09 01:42:53,832 - INFO - allennlp.common.params - validation_dataset_reader.lazy = False\n","2020-11-09 01:42:53,832 - INFO - allennlp.common.params - train_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/chemprot/train.jsonl\n","2020-11-09 01:42:53,832 - INFO - allennlp.training.util - Reading training data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/chemprot/train.jsonl\n","0it [00:00, ?it/s]2020-11-09 01:42:54,521 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/chemprot/train.jsonl not found in cache, downloading to /tmp/tmpfv9wm801\n","\n","  0%|          | 0/1121208 [00:00<?, ?B/s]\u001b[A\n","  2%|1         | 17408/1121208 [00:00<00:10, 108253.74B/s]\u001b[A\n","  5%|4         | 52224/1121208 [00:00<00:08, 127249.01B/s]\u001b[A\n","  9%|9         | 104448/1121208 [00:00<00:06, 155611.48B/s]\u001b[A\n"," 20%|##        | 226304/1121208 [00:00<00:04, 204267.28B/s]\u001b[A\n"," 43%|####3     | 486400/1121208 [00:00<00:02, 276761.24B/s]\u001b[A\n","100%|##########| 1121208/1121208 [00:00<00:00, 1156648.69B/s]\n","2020-11-09 01:42:56,189 - INFO - allennlp.common.file_utils - copying /tmp/tmpfv9wm801 to cache at /root/.allennlp/cache/716d38fb449c79462d70c88fd3e0865f08b214d18319e6d16d4c22e33c619c55.be27ec07ed3a606f6aaf96736f1d2e446095092be8cc948530d836ac17b80a67\n","2020-11-09 01:42:56,190 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/716d38fb449c79462d70c88fd3e0865f08b214d18319e6d16d4c22e33c619c55.be27ec07ed3a606f6aaf96736f1d2e446095092be8cc948530d836ac17b80a67\n","2020-11-09 01:42:56,191 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmpfv9wm801\n","4169it [00:04, 995.59it/s]\n","2020-11-09 01:42:58,020 - INFO - allennlp.common.params - validation_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/chemprot/dev.jsonl\n","2020-11-09 01:42:58,021 - INFO - allennlp.training.util - Reading validation data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/chemprot/dev.jsonl\n","0it [00:00, ?it/s]2020-11-09 01:42:58,714 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/chemprot/dev.jsonl not found in cache, downloading to /tmp/tmpytu1ae3h\n","\n","  0%|          | 0/678657 [00:00<?, ?B/s]\u001b[A\n","  3%|2         | 17408/678657 [00:00<00:06, 110097.48B/s]\u001b[A\n","  8%|7         | 52224/678657 [00:00<00:04, 129006.95B/s]\u001b[A\n"," 13%|#2        | 87040/678657 [00:00<00:04, 147661.88B/s]\u001b[A\n"," 31%|###       | 208896/678657 [00:00<00:02, 194858.36B/s]\u001b[A\n","100%|##########| 678657/678657 [00:00<00:00, 850574.33B/s]\n","2020-11-09 01:43:00,265 - INFO - allennlp.common.file_utils - copying /tmp/tmpytu1ae3h to cache at /root/.allennlp/cache/d7f0fae887a96b974a39c84847a68b01a923a0185062c8e1aed35b3c0242a15e.e287a76cd74ca791e7ecdcf6b9cca7ec53c694f8dd5c614ce9dd73fb72f76a7f\n","2020-11-09 01:43:00,266 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/d7f0fae887a96b974a39c84847a68b01a923a0185062c8e1aed35b3c0242a15e.e287a76cd74ca791e7ecdcf6b9cca7ec53c694f8dd5c614ce9dd73fb72f76a7f\n","2020-11-09 01:43:00,266 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmpytu1ae3h\n","2427it [00:03, 726.61it/s]\n","2020-11-09 01:43:01,361 - INFO - allennlp.common.params - test_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/chemprot/test.jsonl\n","2020-11-09 01:43:01,361 - INFO - allennlp.training.util - Reading test data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/chemprot/test.jsonl\n","0it [00:00, ?it/s]2020-11-09 01:43:02,034 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/chemprot/test.jsonl not found in cache, downloading to /tmp/tmpxz3li65m\n","\n","  0%|          | 0/960369 [00:00<?, ?B/s]\u001b[A\n","  2%|1         | 17408/960369 [00:00<00:08, 107920.93B/s]\u001b[A\n","  5%|5         | 52224/960369 [00:00<00:07, 127077.50B/s]\u001b[A\n"," 11%|#         | 104448/960369 [00:00<00:05, 155401.44B/s]\u001b[A\n"," 24%|##3       | 226304/960369 [00:00<00:03, 204019.38B/s]\u001b[A\n","100%|##########| 960369/960369 [00:00<00:00, 1184565.53B/s]\n","2020-11-09 01:43:03,578 - INFO - allennlp.common.file_utils - copying /tmp/tmpxz3li65m to cache at /root/.allennlp/cache/ffa6f4e2eb7b1e0dd23d9ddee4192e099e935c9c181592b7b66a59202598cb01.bca84e5bf51bc8f9ef945e52ba25ed628d3b45af2c995894476bfa5257a740bb\n","2020-11-09 01:43:03,580 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/ffa6f4e2eb7b1e0dd23d9ddee4192e099e935c9c181592b7b66a59202598cb01.bca84e5bf51bc8f9ef945e52ba25ed628d3b45af2c995894476bfa5257a740bb\n","2020-11-09 01:43:03,580 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmpxz3li65m\n","3469it [00:03, 914.49it/s]\n","2020-11-09 01:43:05,183 - INFO - allennlp.training.trainer_pieces - From dataset instances, test, train, validation will be considered for vocabulary creation.\n","2020-11-09 01:43:05,184 - INFO - allennlp.common.params - vocabulary.type = None\n","2020-11-09 01:43:05,184 - INFO - allennlp.common.params - vocabulary.extend = False\n","2020-11-09 01:43:05,184 - INFO - allennlp.common.params - vocabulary.directory_path = None\n","2020-11-09 01:43:05,184 - INFO - allennlp.common.params - vocabulary.min_count = None\n","2020-11-09 01:43:05,184 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None\n","2020-11-09 01:43:05,184 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')\n","2020-11-09 01:43:05,184 - INFO - allennlp.common.params - vocabulary.pretrained_files = {}\n","2020-11-09 01:43:05,184 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None\n","2020-11-09 01:43:05,184 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False\n","2020-11-09 01:43:05,184 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None\n","2020-11-09 01:43:05,184 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n","10065it [00:00, 112697.13it/s]\n","2020-11-09 01:43:05,274 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'dropout': '0.1', 'feedforward_layer': {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1}, 'seq2vec_encoder': {'embedding_dim': 768, 'type': 'cls_pooler'}, 'text_field_embedder': {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'type': 'basic_classifier_with_f1'} and extras {'vocab'}\n","2020-11-09 01:43:05,274 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1\n","2020-11-09 01:43:05,274 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.models.basic_classifier_with_f1.BasicClassifierWithF1'> from params {'dropout': '0.1', 'feedforward_layer': {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1}, 'seq2vec_encoder': {'embedding_dim': 768, 'type': 'cls_pooler'}, 'text_field_embedder': {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}} and extras {'vocab'}\n","2020-11-09 01:43:05,274 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}} and extras {'vocab'}\n","2020-11-09 01:43:05,275 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n","2020-11-09 01:43:05,275 - INFO - allennlp.common.params - model.text_field_embedder.embedder_to_indexer_map = None\n","2020-11-09 01:43:05,275 - INFO - allennlp.common.params - model.text_field_embedder.allow_unmatched_keys = False\n","2020-11-09 01:43:05,275 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders = None\n","2020-11-09 01:43:05,275 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras {'vocab'}\n","2020-11-09 01:43:05,275 - INFO - allennlp.common.params - model.text_field_embedder.roberta.type = pretrained_transformer\n","2020-11-09 01:43:05,275 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.pretrained_transformer_embedder.PretrainedTransformerEmbedder'> from params {'model_name': 'roberta-base'} and extras {'vocab'}\n","2020-11-09 01:43:05,275 - INFO - allennlp.common.params - model.text_field_embedder.roberta.model_name = roberta-base\n","2020-11-09 01:43:05,650 - INFO - pytorch_transformers.modeling_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/pytorch_transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n","2020-11-09 01:43:05,650 - INFO - pytorch_transformers.modeling_utils - Model config {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 1,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","2020-11-09 01:43:06,021 - INFO - pytorch_transformers.modeling_utils - loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n","2020-11-09 01:43:10,234 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'embedding_dim': 768, 'type': 'cls_pooler'} and extras {'vocab'}\n","2020-11-09 01:43:10,235 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler\n","2020-11-09 01:43:10,235 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.modules.seq2vec_encoders.cls_pooler.CLSPooler'> from params {'embedding_dim': 768} and extras {'vocab'}\n","2020-11-09 01:43:10,235 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768\n","2020-11-09 01:43:10,235 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1} and extras {'vocab'}\n","2020-11-09 01:43:10,235 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768\n","2020-11-09 01:43:10,236 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1\n","2020-11-09 01:43:10,236 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768\n","2020-11-09 01:43:10,236 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh\n","2020-11-09 01:43:10,236 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0\n","2020-11-09 01:43:10,241 - INFO - allennlp.common.params - model.dropout = 0.1\n","2020-11-09 01:43:10,241 - INFO - allennlp.common.params - model.num_labels = None\n","2020-11-09 01:43:10,241 - INFO - allennlp.common.params - model.label_namespace = labels\n","2020-11-09 01:43:10,242 - INFO - allennlp.nn.initializers - Initializing parameters\n","2020-11-09 01:43:10,243 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n","2020-11-09 01:43:10,244 - INFO - allennlp.nn.initializers -    _classification_layer.bias\n","2020-11-09 01:43:10,244 - INFO - allennlp.nn.initializers -    _classification_layer.weight\n","2020-11-09 01:43:10,244 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias\n","2020-11-09 01:43:10,244 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight\n","2020-11-09 01:43:10,244 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias\n","2020-11-09 01:43:10,244 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight\n","2020-11-09 01:43:10,244 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight\n","2020-11-09 01:43:10,244 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight\n","2020-11-09 01:43:10,244 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight\n","2020-11-09 01:43:10,244 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,244 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,244 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias\n","2020-11-09 01:43:10,244 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight\n","2020-11-09 01:43:10,244 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias\n","2020-11-09 01:43:10,244 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight\n","2020-11-09 01:43:10,244 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias\n","2020-11-09 01:43:10,245 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight\n","2020-11-09 01:43:10,245 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias\n","2020-11-09 01:43:10,245 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight\n","2020-11-09 01:43:10,245 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias\n","2020-11-09 01:43:10,245 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight\n","2020-11-09 01:43:10,245 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias\n","2020-11-09 01:43:10,245 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight\n","2020-11-09 01:43:10,245 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias\n","2020-11-09 01:43:10,245 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight\n","2020-11-09 01:43:10,245 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,245 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,245 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias\n","2020-11-09 01:43:10,245 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight\n","2020-11-09 01:43:10,245 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias\n","2020-11-09 01:43:10,245 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight\n","2020-11-09 01:43:10,245 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias\n","2020-11-09 01:43:10,245 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight\n","2020-11-09 01:43:10,246 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias\n","2020-11-09 01:43:10,246 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight\n","2020-11-09 01:43:10,246 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias\n","2020-11-09 01:43:10,246 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight\n","2020-11-09 01:43:10,246 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias\n","2020-11-09 01:43:10,246 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight\n","2020-11-09 01:43:10,246 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias\n","2020-11-09 01:43:10,246 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight\n","2020-11-09 01:43:10,246 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,246 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,246 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias\n","2020-11-09 01:43:10,246 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight\n","2020-11-09 01:43:10,246 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias\n","2020-11-09 01:43:10,246 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight\n","2020-11-09 01:43:10,246 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias\n","2020-11-09 01:43:10,246 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight\n","2020-11-09 01:43:10,247 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias\n","2020-11-09 01:43:10,247 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight\n","2020-11-09 01:43:10,247 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias\n","2020-11-09 01:43:10,247 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight\n","2020-11-09 01:43:10,247 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias\n","2020-11-09 01:43:10,247 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight\n","2020-11-09 01:43:10,247 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias\n","2020-11-09 01:43:10,247 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight\n","2020-11-09 01:43:10,247 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,247 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,247 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias\n","2020-11-09 01:43:10,247 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight\n","2020-11-09 01:43:10,247 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias\n","2020-11-09 01:43:10,247 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight\n","2020-11-09 01:43:10,247 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias\n","2020-11-09 01:43:10,247 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight\n","2020-11-09 01:43:10,248 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias\n","2020-11-09 01:43:10,248 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight\n","2020-11-09 01:43:10,248 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias\n","2020-11-09 01:43:10,248 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight\n","2020-11-09 01:43:10,248 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias\n","2020-11-09 01:43:10,248 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight\n","2020-11-09 01:43:10,248 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias\n","2020-11-09 01:43:10,248 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight\n","2020-11-09 01:43:10,248 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,248 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,248 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias\n","2020-11-09 01:43:10,248 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight\n","2020-11-09 01:43:10,248 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias\n","2020-11-09 01:43:10,248 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight\n","2020-11-09 01:43:10,248 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias\n","2020-11-09 01:43:10,249 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight\n","2020-11-09 01:43:10,249 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias\n","2020-11-09 01:43:10,249 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight\n","2020-11-09 01:43:10,249 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias\n","2020-11-09 01:43:10,249 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight\n","2020-11-09 01:43:10,249 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias\n","2020-11-09 01:43:10,249 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight\n","2020-11-09 01:43:10,249 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias\n","2020-11-09 01:43:10,249 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight\n","2020-11-09 01:43:10,249 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,249 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,249 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias\n","2020-11-09 01:43:10,249 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight\n","2020-11-09 01:43:10,249 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias\n","2020-11-09 01:43:10,249 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight\n","2020-11-09 01:43:10,249 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias\n","2020-11-09 01:43:10,250 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight\n","2020-11-09 01:43:10,250 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias\n","2020-11-09 01:43:10,250 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight\n","2020-11-09 01:43:10,250 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias\n","2020-11-09 01:43:10,250 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight\n","2020-11-09 01:43:10,250 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias\n","2020-11-09 01:43:10,250 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight\n","2020-11-09 01:43:10,250 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias\n","2020-11-09 01:43:10,250 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight\n","2020-11-09 01:43:10,250 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,299 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,299 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias\n","2020-11-09 01:43:10,299 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight\n","2020-11-09 01:43:10,299 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias\n","2020-11-09 01:43:10,300 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight\n","2020-11-09 01:43:10,300 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias\n","2020-11-09 01:43:10,300 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight\n","2020-11-09 01:43:10,300 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias\n","2020-11-09 01:43:10,300 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight\n","2020-11-09 01:43:10,300 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias\n","2020-11-09 01:43:10,300 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight\n","2020-11-09 01:43:10,300 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias\n","2020-11-09 01:43:10,300 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight\n","2020-11-09 01:43:10,300 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias\n","2020-11-09 01:43:10,300 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight\n","2020-11-09 01:43:10,300 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,300 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,300 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias\n","2020-11-09 01:43:10,300 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight\n","2020-11-09 01:43:10,300 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias\n","2020-11-09 01:43:10,301 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight\n","2020-11-09 01:43:10,301 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias\n","2020-11-09 01:43:10,301 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight\n","2020-11-09 01:43:10,301 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias\n","2020-11-09 01:43:10,301 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight\n","2020-11-09 01:43:10,301 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias\n","2020-11-09 01:43:10,301 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight\n","2020-11-09 01:43:10,301 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias\n","2020-11-09 01:43:10,301 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight\n","2020-11-09 01:43:10,301 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias\n","2020-11-09 01:43:10,301 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight\n","2020-11-09 01:43:10,301 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,301 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,301 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias\n","2020-11-09 01:43:10,302 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight\n","2020-11-09 01:43:10,302 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias\n","2020-11-09 01:43:10,302 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight\n","2020-11-09 01:43:10,302 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias\n","2020-11-09 01:43:10,302 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight\n","2020-11-09 01:43:10,302 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias\n","2020-11-09 01:43:10,302 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight\n","2020-11-09 01:43:10,302 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias\n","2020-11-09 01:43:10,302 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight\n","2020-11-09 01:43:10,302 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias\n","2020-11-09 01:43:10,302 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight\n","2020-11-09 01:43:10,302 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias\n","2020-11-09 01:43:10,302 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight\n","2020-11-09 01:43:10,302 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,302 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,303 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias\n","2020-11-09 01:43:10,303 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight\n","2020-11-09 01:43:10,303 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias\n","2020-11-09 01:43:10,303 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight\n","2020-11-09 01:43:10,303 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias\n","2020-11-09 01:43:10,303 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight\n","2020-11-09 01:43:10,303 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias\n","2020-11-09 01:43:10,303 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight\n","2020-11-09 01:43:10,303 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias\n","2020-11-09 01:43:10,303 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight\n","2020-11-09 01:43:10,303 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias\n","2020-11-09 01:43:10,303 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight\n","2020-11-09 01:43:10,303 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias\n","2020-11-09 01:43:10,303 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight\n","2020-11-09 01:43:10,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias\n","2020-11-09 01:43:10,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight\n","2020-11-09 01:43:10,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias\n","2020-11-09 01:43:10,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight\n","2020-11-09 01:43:10,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias\n","2020-11-09 01:43:10,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight\n","2020-11-09 01:43:10,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias\n","2020-11-09 01:43:10,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight\n","2020-11-09 01:43:10,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias\n","2020-11-09 01:43:10,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight\n","2020-11-09 01:43:10,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias\n","2020-11-09 01:43:10,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight\n","2020-11-09 01:43:10,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias\n","2020-11-09 01:43:10,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight\n","2020-11-09 01:43:10,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias\n","2020-11-09 01:43:10,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight\n","2020-11-09 01:43:10,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias\n","2020-11-09 01:43:10,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight\n","2020-11-09 01:43:10,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias\n","2020-11-09 01:43:10,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight\n","2020-11-09 01:43:10,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias\n","2020-11-09 01:43:10,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight\n","2020-11-09 01:43:10,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias\n","2020-11-09 01:43:10,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight\n","2020-11-09 01:43:10,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias\n","2020-11-09 01:43:10,306 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight\n","2020-11-09 01:43:10,306 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias\n","2020-11-09 01:43:10,306 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight\n","2020-11-09 01:43:10,306 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias\n","2020-11-09 01:43:10,306 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight\n","2020-11-09 01:43:10,307 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 8, 'sorting_keys': [['tokens', 'num_tokens']], 'type': 'bucket'} and extras set()\n","2020-11-09 01:43:10,307 - INFO - allennlp.common.params - iterator.type = bucket\n","2020-11-09 01:43:10,307 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 8, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()\n","2020-11-09 01:43:10,307 - INFO - allennlp.common.params - iterator.sorting_keys = [['tokens', 'num_tokens']]\n","2020-11-09 01:43:10,308 - INFO - allennlp.common.params - iterator.padding_noise = 0.1\n","2020-11-09 01:43:10,308 - INFO - allennlp.common.params - iterator.biggest_batch_first = False\n","2020-11-09 01:43:10,308 - INFO - allennlp.common.params - iterator.batch_size = 8\n","2020-11-09 01:43:10,308 - INFO - allennlp.common.params - iterator.instances_per_epoch = None\n","2020-11-09 01:43:10,308 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None\n","2020-11-09 01:43:10,308 - INFO - allennlp.common.params - iterator.cache_instances = False\n","2020-11-09 01:43:10,308 - INFO - allennlp.common.params - iterator.track_epoch = False\n","2020-11-09 01:43:10,308 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None\n","2020-11-09 01:43:10,308 - INFO - allennlp.common.params - iterator.skip_smaller_batches = False\n","2020-11-09 01:43:10,308 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'sorting_keys': [['tokens', 'num_tokens']], 'type': 'bucket'} and extras set()\n","2020-11-09 01:43:10,308 - INFO - allennlp.common.params - validation_iterator.type = bucket\n","2020-11-09 01:43:10,308 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 64, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()\n","2020-11-09 01:43:10,308 - INFO - allennlp.common.params - validation_iterator.sorting_keys = [['tokens', 'num_tokens']]\n","2020-11-09 01:43:10,308 - INFO - allennlp.common.params - validation_iterator.padding_noise = 0.1\n","2020-11-09 01:43:10,309 - INFO - allennlp.common.params - validation_iterator.biggest_batch_first = False\n","2020-11-09 01:43:10,309 - INFO - allennlp.common.params - validation_iterator.batch_size = 64\n","2020-11-09 01:43:10,309 - INFO - allennlp.common.params - validation_iterator.instances_per_epoch = None\n","2020-11-09 01:43:10,309 - INFO - allennlp.common.params - validation_iterator.max_instances_in_memory = None\n","2020-11-09 01:43:10,309 - INFO - allennlp.common.params - validation_iterator.cache_instances = False\n","2020-11-09 01:43:10,309 - INFO - allennlp.common.params - validation_iterator.track_epoch = False\n","2020-11-09 01:43:10,309 - INFO - allennlp.common.params - validation_iterator.maximum_samples_per_batch = None\n","2020-11-09 01:43:10,309 - INFO - allennlp.common.params - validation_iterator.skip_smaller_batches = False\n","2020-11-09 01:43:10,309 - INFO - allennlp.common.params - trainer.no_grad = ()\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - Following parameters are Frozen  (without gradient):\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - Following parameters are Tunable (with gradient):\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight\n","2020-11-09 01:43:10,312 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias\n","2020-11-09 01:43:10,313 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight\n","2020-11-09 01:43:10,314 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias\n","2020-11-09 01:43:10,314 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight\n","2020-11-09 01:43:10,314 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias\n","2020-11-09 01:43:10,314 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight\n","2020-11-09 01:43:10,314 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias\n","2020-11-09 01:43:10,314 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight\n","2020-11-09 01:43:10,314 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias\n","2020-11-09 01:43:10,314 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight\n","2020-11-09 01:43:10,314 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias\n","2020-11-09 01:43:10,314 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,314 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,314 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight\n","2020-11-09 01:43:10,314 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias\n","2020-11-09 01:43:10,314 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight\n","2020-11-09 01:43:10,314 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias\n","2020-11-09 01:43:10,314 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight\n","2020-11-09 01:43:10,314 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias\n","2020-11-09 01:43:10,314 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight\n","2020-11-09 01:43:10,314 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias\n","2020-11-09 01:43:10,314 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight\n","2020-11-09 01:43:10,314 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias\n","2020-11-09 01:43:10,314 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight\n","2020-11-09 01:43:10,314 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias\n","2020-11-09 01:43:10,407 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight\n","2020-11-09 01:43:10,407 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias\n","2020-11-09 01:43:10,407 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,407 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,407 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight\n","2020-11-09 01:43:10,407 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias\n","2020-11-09 01:43:10,407 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight\n","2020-11-09 01:43:10,407 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias\n","2020-11-09 01:43:10,407 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight\n","2020-11-09 01:43:10,408 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias\n","2020-11-09 01:43:10,408 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight\n","2020-11-09 01:43:10,408 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias\n","2020-11-09 01:43:10,408 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight\n","2020-11-09 01:43:10,408 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias\n","2020-11-09 01:43:10,408 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight\n","2020-11-09 01:43:10,408 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias\n","2020-11-09 01:43:10,408 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight\n","2020-11-09 01:43:10,408 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias\n","2020-11-09 01:43:10,408 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,408 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,408 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight\n","2020-11-09 01:43:10,408 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias\n","2020-11-09 01:43:10,408 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight\n","2020-11-09 01:43:10,409 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias\n","2020-11-09 01:43:10,409 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight\n","2020-11-09 01:43:10,409 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias\n","2020-11-09 01:43:10,409 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight\n","2020-11-09 01:43:10,409 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias\n","2020-11-09 01:43:10,409 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight\n","2020-11-09 01:43:10,409 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias\n","2020-11-09 01:43:10,409 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight\n","2020-11-09 01:43:10,409 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias\n","2020-11-09 01:43:10,409 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight\n","2020-11-09 01:43:10,409 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias\n","2020-11-09 01:43:10,409 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,409 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,409 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight\n","2020-11-09 01:43:10,410 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias\n","2020-11-09 01:43:10,410 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight\n","2020-11-09 01:43:10,410 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias\n","2020-11-09 01:43:10,410 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight\n","2020-11-09 01:43:10,410 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias\n","2020-11-09 01:43:10,410 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight\n","2020-11-09 01:43:10,410 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias\n","2020-11-09 01:43:10,410 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight\n","2020-11-09 01:43:10,410 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias\n","2020-11-09 01:43:10,410 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight\n","2020-11-09 01:43:10,410 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias\n","2020-11-09 01:43:10,410 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight\n","2020-11-09 01:43:10,410 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias\n","2020-11-09 01:43:10,410 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,410 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,411 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight\n","2020-11-09 01:43:10,411 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias\n","2020-11-09 01:43:10,411 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight\n","2020-11-09 01:43:10,411 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias\n","2020-11-09 01:43:10,411 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight\n","2020-11-09 01:43:10,411 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias\n","2020-11-09 01:43:10,411 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight\n","2020-11-09 01:43:10,411 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias\n","2020-11-09 01:43:10,411 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight\n","2020-11-09 01:43:10,411 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias\n","2020-11-09 01:43:10,411 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight\n","2020-11-09 01:43:10,411 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias\n","2020-11-09 01:43:10,411 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight\n","2020-11-09 01:43:10,411 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias\n","2020-11-09 01:43:10,411 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,412 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,412 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight\n","2020-11-09 01:43:10,412 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias\n","2020-11-09 01:43:10,412 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight\n","2020-11-09 01:43:10,412 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias\n","2020-11-09 01:43:10,412 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight\n","2020-11-09 01:43:10,412 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias\n","2020-11-09 01:43:10,412 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight\n","2020-11-09 01:43:10,412 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias\n","2020-11-09 01:43:10,412 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight\n","2020-11-09 01:43:10,412 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias\n","2020-11-09 01:43:10,412 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight\n","2020-11-09 01:43:10,412 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias\n","2020-11-09 01:43:10,412 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight\n","2020-11-09 01:43:10,412 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias\n","2020-11-09 01:43:10,412 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,413 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,413 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight\n","2020-11-09 01:43:10,413 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias\n","2020-11-09 01:43:10,413 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight\n","2020-11-09 01:43:10,413 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias\n","2020-11-09 01:43:10,413 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight\n","2020-11-09 01:43:10,413 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias\n","2020-11-09 01:43:10,413 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight\n","2020-11-09 01:43:10,413 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias\n","2020-11-09 01:43:10,413 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight\n","2020-11-09 01:43:10,413 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias\n","2020-11-09 01:43:10,413 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight\n","2020-11-09 01:43:10,413 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias\n","2020-11-09 01:43:10,413 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight\n","2020-11-09 01:43:10,413 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias\n","2020-11-09 01:43:10,413 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight\n","2020-11-09 01:43:10,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias\n","2020-11-09 01:43:10,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight\n","2020-11-09 01:43:10,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias\n","2020-11-09 01:43:10,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight\n","2020-11-09 01:43:10,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias\n","2020-11-09 01:43:10,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight\n","2020-11-09 01:43:10,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias\n","2020-11-09 01:43:10,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight\n","2020-11-09 01:43:10,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias\n","2020-11-09 01:43:10,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight\n","2020-11-09 01:43:10,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias\n","2020-11-09 01:43:10,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight\n","2020-11-09 01:43:10,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias\n","2020-11-09 01:43:10,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n","2020-11-09 01:43:10,415 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n","2020-11-09 01:43:10,415 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight\n","2020-11-09 01:43:10,415 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias\n","2020-11-09 01:43:10,415 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight\n","2020-11-09 01:43:10,415 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias\n","2020-11-09 01:43:10,415 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight\n","2020-11-09 01:43:10,415 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias\n","2020-11-09 01:43:10,415 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight\n","2020-11-09 01:43:10,415 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias\n","2020-11-09 01:43:10,415 - INFO - allennlp.training.trainer_pieces - _feedforward_layer._linear_layers.0.weight\n","2020-11-09 01:43:10,415 - INFO - allennlp.training.trainer_pieces - _feedforward_layer._linear_layers.0.bias\n","2020-11-09 01:43:10,415 - INFO - allennlp.training.trainer_pieces - _classification_layer.weight\n","2020-11-09 01:43:10,415 - INFO - allennlp.training.trainer_pieces - _classification_layer.bias\n","2020-11-09 01:43:10,415 - INFO - allennlp.common.params - trainer.patience = 3\n","2020-11-09 01:43:10,416 - INFO - allennlp.common.params - trainer.validation_metric = +f1\n","2020-11-09 01:43:10,416 - INFO - allennlp.common.params - trainer.shuffle = True\n","2020-11-09 01:43:10,416 - INFO - allennlp.common.params - trainer.num_epochs = 10\n","2020-11-09 01:43:10,416 - INFO - allennlp.common.params - trainer.cuda_device = 0\n","2020-11-09 01:43:10,416 - INFO - allennlp.common.params - trainer.grad_norm = None\n","2020-11-09 01:43:10,416 - INFO - allennlp.common.params - trainer.grad_clipping = None\n","2020-11-09 01:43:10,416 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None\n","2020-11-09 01:43:10,416 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n","2020-11-09 01:43:10,416 - INFO - allennlp.common.params - trainer.gradient_accumulation_batch_size = 8\n","2020-11-09 01:43:14,980 - INFO - allennlp.common.params - trainer.optimizer.type = bert_adam\n","2020-11-09 01:43:14,980 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n","2020-11-09 01:43:14,980 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n","2020-11-09 01:43:14,980 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups.0.1.weight_decay = 0\n","2020-11-09 01:43:14,981 - INFO - allennlp.training.optimizers - Done constructing parameter groups.\n","2020-11-09 01:43:14,981 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_classification_layer.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias', '_feedforward_layer._linear_layers.0.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight'], {'weight_decay': 0}\n","2020-11-09 01:43:15,034 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight', '_classification_layer.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight', '_feedforward_layer._linear_layers.0.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight'], {}\n","2020-11-09 01:43:15,035 - WARNING - allennlp.training.optimizers - When constructing parameter groups,  layer_norm.weight not match any parameter name\n","2020-11-09 01:43:15,035 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125246221\n","2020-11-09 01:43:15,036 - INFO - allennlp.common.params - trainer.optimizer.infer_type_and_cast = True\n","2020-11-09 01:43:15,036 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n","2020-11-09 01:43:15,036 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n","2020-11-09 01:43:15,036 - INFO - allennlp.common.params - trainer.optimizer.b1 = 0.9\n","2020-11-09 01:43:15,036 - INFO - allennlp.common.params - trainer.optimizer.b2 = 0.98\n","2020-11-09 01:43:15,036 - INFO - allennlp.common.params - trainer.optimizer.e = 1e-06\n","2020-11-09 01:43:15,036 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05\n","2020-11-09 01:43:15,036 - INFO - allennlp.common.params - trainer.optimizer.max_grad_norm = 1\n","2020-11-09 01:43:15,036 - INFO - allennlp.common.params - trainer.optimizer.schedule = warmup_linear\n","2020-11-09 01:43:15,036 - INFO - allennlp.common.params - trainer.optimizer.t_total = -1\n","2020-11-09 01:43:15,036 - INFO - allennlp.common.params - trainer.optimizer.warmup = 0.06\n","2020-11-09 01:43:15,037 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1\n","2020-11-09 01:43:15,037 - WARNING - pytorch_pretrained_bert.optimization - t_total value of -1 results in schedule not being applied\n","2020-11-09 01:43:15,038 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 0\n","2020-11-09 01:43:15,038 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None\n","2020-11-09 01:43:15,038 - INFO - allennlp.common.params - trainer.model_save_interval = None\n","2020-11-09 01:43:15,038 - INFO - allennlp.common.params - trainer.summary_interval = 100\n","2020-11-09 01:43:15,038 - INFO - allennlp.common.params - trainer.histogram_interval = None\n","2020-11-09 01:43:15,038 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True\n","2020-11-09 01:43:15,038 - INFO - allennlp.common.params - trainer.should_log_learning_rate = False\n","2020-11-09 01:43:15,038 - INFO - allennlp.common.params - trainer.log_batch_size_period = None\n","2020-11-09 01:43:15,041 - INFO - allennlp.training.trainer - Beginning training.\n","2020-11-09 01:43:15,041 - INFO - allennlp.training.trainer - Epoch 0/9\n","2020-11-09 01:43:15,041 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4953.56\n","2020-11-09 01:43:15,139 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1769\n","2020-11-09 01:43:15,142 - INFO - allennlp.training.trainer - Training\n","  0%|          | 0/522 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","f1: 0.3314, accuracy: 0.6167, loss: 1.2231 ||: 100%|##########| 522/522 [01:21<00:00,  6.43it/s]\n","2020-11-09 01:44:36,296 - INFO - allennlp.training.trainer - Validating\n","f1: 0.4557, accuracy: 0.7684, loss: 0.7590 ||: 100%|##########| 38/38 [00:03<00:00,  9.71it/s]\n","2020-11-09 01:44:40,212 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 01:44:40,213 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  1769.000  |       N/A\n","2020-11-09 01:44:40,213 - INFO - allennlp.training.tensorboard_writer - loss            |     1.223  |     0.759\n","2020-11-09 01:44:40,214 - INFO - allennlp.training.tensorboard_writer - f1              |     0.331  |     0.456\n","2020-11-09 01:44:40,215 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4953.560  |       N/A\n","2020-11-09 01:44:40,216 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.617  |     0.768\n","2020-11-09 01:44:46,080 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/chemprot_nas_01/best.th'.\n","2020-11-09 01:44:47,358 - INFO - allennlp.training.trainer - Epoch duration: 0:01:32.316964\n","2020-11-09 01:44:47,359 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:13:50\n","2020-11-09 01:44:47,359 - INFO - allennlp.training.trainer - Epoch 1/9\n","2020-11-09 01:44:47,360 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4969.244\n","2020-11-09 01:44:47,453 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 11677\n","2020-11-09 01:44:47,456 - INFO - allennlp.training.trainer - Training\n","f1: 0.5024, accuracy: 0.8024, loss: 0.6525 ||: 100%|##########| 522/522 [01:22<00:00,  6.34it/s]\n","2020-11-09 01:46:09,765 - INFO - allennlp.training.trainer - Validating\n","f1: 0.5108, accuracy: 0.8030, loss: 0.7240 ||: 100%|##########| 38/38 [00:03<00:00, 10.06it/s]\n","2020-11-09 01:46:13,547 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 01:46:13,547 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  11677.000  |       N/A\n","2020-11-09 01:46:13,548 - INFO - allennlp.training.tensorboard_writer - loss            |     0.652  |     0.724\n","2020-11-09 01:46:13,548 - INFO - allennlp.training.tensorboard_writer - f1              |     0.502  |     0.511\n","2020-11-09 01:46:13,548 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4969.244  |       N/A\n","2020-11-09 01:46:13,548 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.802  |     0.803\n","2020-11-09 01:46:19,392 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/chemprot_nas_01/best.th'.\n","2020-11-09 01:46:20,779 - INFO - allennlp.training.trainer - Epoch duration: 0:01:33.419771\n","2020-11-09 01:46:20,779 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:12:22\n","2020-11-09 01:46:20,780 - INFO - allennlp.training.trainer - Epoch 2/9\n","2020-11-09 01:46:20,780 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4969.472\n","2020-11-09 01:46:20,878 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 11677\n","2020-11-09 01:46:20,881 - INFO - allennlp.training.trainer - Training\n","f1: 0.5836, accuracy: 0.8688, loss: 0.4513 ||: 100%|##########| 522/522 [01:21<00:00,  6.40it/s]\n","2020-11-09 01:47:42,496 - INFO - allennlp.training.trainer - Validating\n","f1: 0.5085, accuracy: 0.8208, loss: 0.6943 ||: 100%|##########| 38/38 [00:03<00:00, 10.09it/s]\n","2020-11-09 01:47:46,266 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 01:47:46,267 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  11677.000  |       N/A\n","2020-11-09 01:47:46,267 - INFO - allennlp.training.tensorboard_writer - loss            |     0.451  |     0.694\n","2020-11-09 01:47:46,268 - INFO - allennlp.training.tensorboard_writer - f1              |     0.584  |     0.508\n","2020-11-09 01:47:46,268 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4969.472  |       N/A\n","2020-11-09 01:47:46,270 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.869  |     0.821\n","2020-11-09 01:47:51,946 - INFO - allennlp.training.trainer - Epoch duration: 0:01:31.166421\n","2020-11-09 01:47:51,946 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:10:46\n","2020-11-09 01:47:51,946 - INFO - allennlp.training.trainer - Epoch 3/9\n","2020-11-09 01:47:51,947 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4969.508\n","2020-11-09 01:47:52,048 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 11677\n","2020-11-09 01:47:52,051 - INFO - allennlp.training.trainer - Training\n","f1: 0.6442, accuracy: 0.8983, loss: 0.3371 ||: 100%|##########| 522/522 [01:22<00:00,  6.33it/s]\n","2020-11-09 01:49:14,489 - INFO - allennlp.training.trainer - Validating\n","f1: 0.5177, accuracy: 0.8092, loss: 0.7506 ||: 100%|##########| 38/38 [00:03<00:00, 10.12it/s]\n","2020-11-09 01:49:18,251 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 01:49:18,251 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  11677.000  |       N/A\n","2020-11-09 01:49:18,252 - INFO - allennlp.training.tensorboard_writer - loss            |     0.337  |     0.751\n","2020-11-09 01:49:18,252 - INFO - allennlp.training.tensorboard_writer - f1              |     0.644  |     0.518\n","2020-11-09 01:49:18,253 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4969.508  |       N/A\n","2020-11-09 01:49:18,254 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.898  |     0.809\n","2020-11-09 01:49:24,181 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/chemprot_nas_01/best.th'.\n","2020-11-09 01:49:26,158 - INFO - allennlp.training.trainer - Epoch duration: 0:01:34.211847\n","2020-11-09 01:49:26,159 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:09:16\n","2020-11-09 01:49:26,159 - INFO - allennlp.training.trainer - Epoch 4/9\n","2020-11-09 01:49:26,159 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4969.508\n","2020-11-09 01:49:26,255 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 11677\n","2020-11-09 01:49:26,258 - INFO - allennlp.training.trainer - Training\n","f1: 0.7480, accuracy: 0.9280, loss: 0.2468 ||: 100%|##########| 522/522 [01:22<00:00,  6.36it/s]\n","2020-11-09 01:50:48,308 - INFO - allennlp.training.trainer - Validating\n","f1: 0.5078, accuracy: 0.8039, loss: 0.8580 ||: 100%|##########| 38/38 [00:03<00:00, 10.11it/s]\n","2020-11-09 01:50:52,071 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 01:50:52,071 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  11677.000  |       N/A\n","2020-11-09 01:50:52,072 - INFO - allennlp.training.tensorboard_writer - loss            |     0.247  |     0.858\n","2020-11-09 01:50:52,072 - INFO - allennlp.training.tensorboard_writer - f1              |     0.748  |     0.508\n","2020-11-09 01:50:52,073 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4969.508  |       N/A\n","2020-11-09 01:50:52,074 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.928  |     0.804\n","2020-11-09 01:50:58,395 - INFO - allennlp.training.trainer - Epoch duration: 0:01:32.236189\n","2020-11-09 01:50:58,395 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:07:43\n","2020-11-09 01:50:58,395 - INFO - allennlp.training.trainer - Epoch 5/9\n","2020-11-09 01:50:58,395 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4969.508\n","2020-11-09 01:50:58,491 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 11677\n","2020-11-09 01:50:58,494 - INFO - allennlp.training.trainer - Training\n","f1: 0.7704, accuracy: 0.9391, loss: 0.2187 ||: 100%|##########| 522/522 [01:21<00:00,  6.44it/s]\n","2020-11-09 01:52:19,579 - INFO - allennlp.training.trainer - Validating\n","f1: 0.5215, accuracy: 0.8072, loss: 0.9042 ||: 100%|##########| 38/38 [00:03<00:00, 10.10it/s]\n","2020-11-09 01:52:23,345 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 01:52:23,345 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  11677.000  |       N/A\n","2020-11-09 01:52:23,346 - INFO - allennlp.training.tensorboard_writer - loss            |     0.219  |     0.904\n","2020-11-09 01:52:23,347 - INFO - allennlp.training.tensorboard_writer - f1              |     0.770  |     0.522\n","2020-11-09 01:52:23,347 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4969.508  |       N/A\n","2020-11-09 01:52:23,348 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.939  |     0.807\n","2020-11-09 01:52:28,770 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/chemprot_nas_01/best.th'.\n","2020-11-09 01:52:30,639 - INFO - allennlp.training.trainer - Epoch duration: 0:01:32.243704\n","2020-11-09 01:52:30,639 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:06:10\n","2020-11-09 01:52:30,639 - INFO - allennlp.training.trainer - Epoch 6/9\n","2020-11-09 01:52:30,640 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4969.52\n","2020-11-09 01:52:30,735 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 11677\n","2020-11-09 01:52:30,738 - INFO - allennlp.training.trainer - Training\n","f1: 0.8092, accuracy: 0.9477, loss: 0.1814 ||: 100%|##########| 522/522 [01:22<00:00,  6.34it/s]\n","2020-11-09 01:53:53,084 - INFO - allennlp.training.trainer - Validating\n","f1: 0.5226, accuracy: 0.8109, loss: 0.9154 ||: 100%|##########| 38/38 [00:03<00:00, 10.14it/s]\n","2020-11-09 01:53:56,836 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 01:53:56,836 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  11677.000  |       N/A\n","2020-11-09 01:53:56,837 - INFO - allennlp.training.tensorboard_writer - loss            |     0.181  |     0.915\n","2020-11-09 01:53:56,837 - INFO - allennlp.training.tensorboard_writer - f1              |     0.809  |     0.523\n","2020-11-09 01:53:56,838 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4969.520  |       N/A\n","2020-11-09 01:53:56,838 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.948  |     0.811\n","2020-11-09 01:54:02,556 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/chemprot_nas_01/best.th'.\n","2020-11-09 01:54:03,635 - INFO - allennlp.training.trainer - Epoch duration: 0:01:32.995155\n","2020-11-09 01:54:03,635 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:04:37\n","2020-11-09 01:54:03,635 - INFO - allennlp.training.trainer - Epoch 7/9\n","2020-11-09 01:54:03,635 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4969.536\n","2020-11-09 01:54:03,737 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 11677\n","2020-11-09 01:54:03,740 - INFO - allennlp.training.trainer - Training\n","f1: 0.8179, accuracy: 0.9549, loss: 0.1646 ||: 100%|##########| 522/522 [01:23<00:00,  6.24it/s]\n","2020-11-09 01:55:27,454 - INFO - allennlp.training.trainer - Validating\n","f1: 0.5228, accuracy: 0.8241, loss: 0.9431 ||: 100%|##########| 38/38 [00:03<00:00,  9.99it/s]\n","2020-11-09 01:55:31,264 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 01:55:31,264 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  11677.000  |       N/A\n","2020-11-09 01:55:31,265 - INFO - allennlp.training.tensorboard_writer - loss            |     0.165  |     0.943\n","2020-11-09 01:55:31,265 - INFO - allennlp.training.tensorboard_writer - f1              |     0.818  |     0.523\n","2020-11-09 01:55:31,265 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4969.536  |       N/A\n","2020-11-09 01:55:31,266 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.955  |     0.824\n","2020-11-09 01:55:36,719 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/chemprot_nas_01/best.th'.\n","2020-11-09 01:55:38,616 - INFO - allennlp.training.trainer - Epoch duration: 0:01:34.981034\n","2020-11-09 01:55:38,616 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:03:05\n","2020-11-09 01:55:38,617 - INFO - allennlp.training.trainer - Epoch 8/9\n","2020-11-09 01:55:38,617 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4969.544\n","2020-11-09 01:55:38,714 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 11677\n","2020-11-09 01:55:38,718 - INFO - allennlp.training.trainer - Training\n","f1: 0.8812, accuracy: 0.9631, loss: 0.1253 ||: 100%|##########| 522/522 [01:23<00:00,  6.26it/s]\n","2020-11-09 01:57:02,151 - INFO - allennlp.training.trainer - Validating\n","f1: 0.5264, accuracy: 0.7919, loss: 1.1300 ||: 100%|##########| 38/38 [00:03<00:00,  9.95it/s]\n","2020-11-09 01:57:05,974 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 01:57:05,974 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  11677.000  |       N/A\n","2020-11-09 01:57:05,975 - INFO - allennlp.training.tensorboard_writer - loss            |     0.125  |     1.130\n","2020-11-09 01:57:05,975 - INFO - allennlp.training.tensorboard_writer - f1              |     0.881  |     0.526\n","2020-11-09 01:57:05,976 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4969.544  |       N/A\n","2020-11-09 01:57:05,977 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.963  |     0.792\n","2020-11-09 01:57:11,949 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/chemprot_nas_01/best.th'.\n","2020-11-09 01:57:17,014 - INFO - allennlp.training.trainer - Epoch duration: 0:01:38.397796\n","2020-11-09 01:57:17,015 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:01:33\n","2020-11-09 01:57:17,015 - INFO - allennlp.training.trainer - Epoch 9/9\n","2020-11-09 01:57:17,015 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4969.544\n","2020-11-09 01:57:17,115 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 11677\n","2020-11-09 01:57:17,118 - INFO - allennlp.training.trainer - Training\n","f1: 0.8782, accuracy: 0.9662, loss: 0.1168 ||: 100%|##########| 522/522 [01:22<00:00,  6.35it/s]\n","2020-11-09 01:58:39,353 - INFO - allennlp.training.trainer - Validating\n","f1: 0.5085, accuracy: 0.8088, loss: 1.0413 ||: 100%|##########| 38/38 [00:03<00:00,  9.98it/s]\n","2020-11-09 01:58:43,164 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 01:58:43,164 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  11677.000  |       N/A\n","2020-11-09 01:58:43,165 - INFO - allennlp.training.tensorboard_writer - loss            |     0.117  |     1.041\n","2020-11-09 01:58:43,165 - INFO - allennlp.training.tensorboard_writer - f1              |     0.878  |     0.509\n","2020-11-09 01:58:43,166 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4969.544  |       N/A\n","2020-11-09 01:58:43,166 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.966  |     0.809\n","2020-11-09 01:58:48,910 - INFO - allennlp.training.trainer - Epoch duration: 0:01:31.895645\n","2020-11-09 01:58:48,912 - INFO - allennlp.training.checkpointer - loading best weights\n","2020-11-09 01:58:49,298 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.\n","2020-11-09 01:58:49,299 - INFO - allennlp.training.util - Iterating over dataset\n","f1: 0.52, accuracy: 0.81, loss: 1.01 ||: 100%|##########| 55/55 [00:05<00:00, 10.30it/s]\n","2020-11-09 01:58:54,644 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/chemprot_nas_01/model.tar.gz\n","2020-11-09 01:59:22,539 - INFO - allennlp.common.util - Metrics: {\n","  \"best_epoch\": 8,\n","  \"peak_cpu_memory_MB\": 4969.544,\n","  \"peak_gpu_0_memory_MB\": 11677,\n","  \"training_duration\": \"0:15:28.125611\",\n","  \"training_start_epoch\": 0,\n","  \"training_epochs\": 9,\n","  \"epoch\": 9,\n","  \"training_f1\": 0.8782004782786736,\n","  \"training_accuracy\": 0.9661789397937155,\n","  \"training_loss\": 0.11684878171959422,\n","  \"training_cpu_memory_MB\": 4969.544,\n","  \"training_gpu_0_memory_MB\": 11677,\n","  \"validation_f1\": 0.5085442169354513,\n","  \"validation_accuracy\": 0.8088174701277298,\n","  \"validation_loss\": 1.0413249025219364,\n","  \"best_validation_f1\": 0.5263874754309654,\n","  \"best_validation_accuracy\": 0.7919241862381541,\n","  \"best_validation_loss\": 1.129969732541787,\n","  \"test_f1\": 0.5155970631883695,\n","  \"test_accuracy\": 0.8051311617180744,\n","  \"test_loss\": 1.0145780720959672\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sBbMCJ5kqKch","executionInfo":{"status":"ok","timestamp":1604907672390,"user_tz":300,"elapsed":21505405,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"c20e3e04-7ce6-40ec-d16a-218f575aeea7","colab":{"base_uri":"https://localhost:8080/"}},"source":["!python -m scripts.train \\\n","        --config training_config/classifier.jsonnet \\\n","        --serialization_dir model_logs/rct20k_nas_01 \\\n","        --hyperparameters ROBERTA_CLASSIFIER_MINI \\\n","        --dataset rct-20k \\\n","        --model roberta-base \\\n","        --device 0 \\\n","        --perf +f1 \\\n","        --evaluate_on_test"],"execution_count":17,"outputs":[{"output_type":"stream","text":["2020-11-09 01:59:26,790 - INFO - pytorch_pretrained_bert.modeling - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-09 01:59:27,407 - INFO - pytorch_transformers.modeling_bert - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-09 01:59:27,410 - INFO - pytorch_transformers.modeling_xlnet - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-09 01:59:27,900 - INFO - allennlp.common.params - random_seed = 531439\n","2020-11-09 01:59:27,900 - INFO - allennlp.common.params - numpy_seed = 531439\n","2020-11-09 01:59:27,900 - INFO - allennlp.common.params - pytorch_seed = 531439\n","2020-11-09 01:59:27,907 - INFO - allennlp.common.checks - Pytorch version: 1.7.0+cu101\n","2020-11-09 01:59:27,909 - INFO - allennlp.common.params - evaluate_on_test = True\n","2020-11-09 01:59:27,909 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}, 'type': 'text_classification_json_with_sampling'} and extras set()\n","2020-11-09 01:59:27,909 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling\n","2020-11-09 01:59:27,909 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.data.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}} and extras set()\n","2020-11-09 01:59:27,910 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 01:59:27,910 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.type = pretrained_transformer\n","2020-11-09 01:59:27,910 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base'} and extras set()\n","2020-11-09 01:59:27,910 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.model_name = roberta-base\n","2020-11-09 01:59:27,910 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.do_lowercase = False\n","2020-11-09 01:59:27,910 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.namespace = tags\n","2020-11-09 01:59:27,910 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.token_min_padding_length = 0\n","2020-11-09 01:59:28,649 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 01:59:28,649 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 01:59:28,727 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 1\n","2020-11-09 01:59:28,727 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 01:59:28,727 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer\n","2020-11-09 01:59:28,727 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>']} and extras set()\n","2020-11-09 01:59:28,727 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base\n","2020-11-09 01:59:28,727 - INFO - allennlp.common.params - dataset_reader.tokenizer.do_lowercase = False\n","2020-11-09 01:59:28,727 - INFO - allennlp.common.params - dataset_reader.tokenizer.start_tokens = ['<s>']\n","2020-11-09 01:59:28,728 - INFO - allennlp.common.params - dataset_reader.tokenizer.end_tokens = ['</s>']\n","2020-11-09 01:59:29,467 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 01:59:29,467 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 01:59:29,542 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512\n","2020-11-09 01:59:29,543 - INFO - allennlp.common.params - dataset_reader.sample = None\n","2020-11-09 01:59:29,543 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False\n","2020-11-09 01:59:29,543 - INFO - allennlp.common.params - dataset_reader.lazy = False\n","2020-11-09 01:59:29,543 - INFO - allennlp.training.util - Using a separate dataset reader to load validation and test data.\n","2020-11-09 01:59:29,543 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}, 'type': 'text_classification_json_with_sampling'} and extras set()\n","2020-11-09 01:59:29,543 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling\n","2020-11-09 01:59:29,543 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.data.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}} and extras set()\n","2020-11-09 01:59:29,544 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 01:59:29,544 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.type = pretrained_transformer\n","2020-11-09 01:59:29,544 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base'} and extras set()\n","2020-11-09 01:59:29,544 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.model_name = roberta-base\n","2020-11-09 01:59:29,544 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.do_lowercase = False\n","2020-11-09 01:59:29,545 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.namespace = tags\n","2020-11-09 01:59:29,545 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.token_min_padding_length = 0\n","2020-11-09 01:59:30,317 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 01:59:30,317 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 01:59:30,393 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 1\n","2020-11-09 01:59:30,394 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 01:59:30,394 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer\n","2020-11-09 01:59:30,394 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>']} and extras set()\n","2020-11-09 01:59:30,394 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base\n","2020-11-09 01:59:30,394 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.do_lowercase = False\n","2020-11-09 01:59:30,394 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.start_tokens = ['<s>']\n","2020-11-09 01:59:30,394 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.end_tokens = ['</s>']\n","2020-11-09 01:59:31,236 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 01:59:31,236 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 01:59:31,312 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512\n","2020-11-09 01:59:31,312 - INFO - allennlp.common.params - validation_dataset_reader.sample = None\n","2020-11-09 01:59:31,312 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False\n","2020-11-09 01:59:31,312 - INFO - allennlp.common.params - validation_dataset_reader.lazy = False\n","2020-11-09 01:59:31,312 - INFO - allennlp.common.params - train_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/rct-20k/train.jsonl\n","2020-11-09 01:59:31,312 - INFO - allennlp.training.util - Reading training data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/rct-20k/train.jsonl\n","0it [00:00, ?it/s]2020-11-09 01:59:32,008 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/rct-20k/train.jsonl not found in cache, downloading to /tmp/tmpz3eh2j53\n","\n","  0%|          | 0/36390706 [00:00<?, ?B/s]\u001b[A\n","  0%|          | 17408/36390706 [00:00<05:37, 107747.50B/s]\u001b[A\n","  0%|          | 52224/36390706 [00:00<04:46, 126680.54B/s]\u001b[A\n","  0%|          | 104448/36390706 [00:00<03:54, 154859.87B/s]\u001b[A\n","  1%|          | 226304/36390706 [00:00<02:57, 203253.26B/s]\u001b[A\n","  1%|1         | 470016/36390706 [00:00<02:10, 274438.72B/s]\u001b[A\n","  2%|2         | 905216/36390706 [00:00<01:34, 375580.47B/s]\u001b[A\n","  5%|5         | 1845248/36390706 [00:01<01:06, 522028.42B/s]\u001b[A\n"," 10%|#         | 3707904/36390706 [00:01<00:44, 731511.89B/s]\u001b[A\n"," 18%|#7        | 6444032/36390706 [00:01<00:29, 1025939.13B/s]\u001b[A\n"," 25%|##4       | 8918016/36390706 [00:01<00:19, 1424568.78B/s]\u001b[A\n"," 32%|###1      | 11588608/36390706 [00:01<00:12, 1962221.97B/s]\u001b[A\n"," 39%|###8      | 14062592/36390706 [00:01<00:08, 2656790.15B/s]\u001b[A\n"," 46%|####5     | 16716800/36390706 [00:02<00:05, 3548475.44B/s]\u001b[A\n"," 53%|#####2    | 19256320/36390706 [00:02<00:03, 4620229.86B/s]\u001b[A\n"," 60%|######    | 21926912/36390706 [00:02<00:02, 5891824.58B/s]\u001b[A\n"," 67%|######6   | 24237056/36390706 [00:02<00:01, 7149336.46B/s]\u001b[A\n"," 74%|#######4  | 27038720/36390706 [00:02<00:01, 8672778.55B/s]\u001b[A\n"," 81%|########1 | 29561856/36390706 [00:02<00:00, 9998130.74B/s]\u001b[A\n"," 89%|########8 | 32216064/36390706 [00:03<00:00, 11318096.63B/s]\u001b[A\n","100%|##########| 36390706/36390706 [00:03<00:00, 11158452.62B/s]\n","2020-11-09 01:59:36,039 - INFO - allennlp.common.file_utils - copying /tmp/tmpz3eh2j53 to cache at /root/.allennlp/cache/0ea5c4a7c5ed0b6835bd319bbf10f6ca860c98220119da17ffc802ba3d3b555b.afba64ab09eb274e675f3af638ef2f2fe806242ac675c5f28b488dc0dbc30229\n","2020-11-09 01:59:36,073 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/0ea5c4a7c5ed0b6835bd319bbf10f6ca860c98220119da17ffc802ba3d3b555b.afba64ab09eb274e675f3af638ef2f2fe806242ac675c5f28b488dc0dbc30229\n","2020-11-09 01:59:36,073 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmpz3eh2j53\n","180040it [00:54, 3281.86it/s]\n","2020-11-09 02:00:26,172 - INFO - allennlp.common.params - validation_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/rct-20k/dev.jsonl\n","2020-11-09 02:00:26,172 - INFO - allennlp.training.util - Reading validation data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/rct-20k/dev.jsonl\n","0it [00:00, ?it/s]2020-11-09 02:00:26,867 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/rct-20k/dev.jsonl not found in cache, downloading to /tmp/tmpqnlbqi0f\n","\n","  0%|          | 0/6102878 [00:00<?, ?B/s]\u001b[A\n","  0%|          | 17408/6102878 [00:00<00:55, 110239.60B/s]\u001b[A\n","  1%|          | 52224/6102878 [00:00<00:46, 129611.18B/s]\u001b[A\n","  1%|1         | 87040/6102878 [00:00<00:40, 147822.55B/s]\u001b[A\n","  3%|3         | 191488/6102878 [00:00<00:30, 192646.62B/s]\u001b[A\n","  7%|6         | 417792/6102878 [00:00<00:21, 260171.83B/s]\u001b[A\n"," 14%|#3        | 852992/6102878 [00:00<00:14, 357157.17B/s]\u001b[A\n"," 28%|##8       | 1732608/6102878 [00:01<00:08, 496520.04B/s]\u001b[A\n"," 57%|#####7    | 3502080/6102878 [00:01<00:03, 696025.65B/s]\u001b[A\n","100%|##########| 6102878/6102878 [00:01<00:00, 4274122.36B/s]\n","2020-11-09 02:00:29,056 - INFO - allennlp.common.file_utils - copying /tmp/tmpqnlbqi0f to cache at /root/.allennlp/cache/b11c3f3eeae9f2ccc5f5b665317a06c8f2810e99652cd2b7e078642fb4a66278.a7efc96174a546b9dbb59f6ad1aad365980ceff0f5c677b7529cf146fd42eb49\n","2020-11-09 02:00:29,062 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/b11c3f3eeae9f2ccc5f5b665317a06c8f2810e99652cd2b7e078642fb4a66278.a7efc96174a546b9dbb59f6ad1aad365980ceff0f5c677b7529cf146fd42eb49\n","2020-11-09 02:00:29,063 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmpqnlbqi0f\n","30212it [00:13, 2307.65it/s]\n","2020-11-09 02:00:39,265 - INFO - allennlp.common.params - test_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/rct-20k/test.jsonl\n","2020-11-09 02:00:39,265 - INFO - allennlp.training.util - Reading test data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/rct-20k/test.jsonl\n","0it [00:00, ?it/s]2020-11-09 02:00:39,960 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/rct-20k/test.jsonl not found in cache, downloading to /tmp/tmp2htphkd8\n","\n","  0%|          | 0/6062745 [00:00<?, ?B/s]\u001b[A\n","  0%|          | 17408/6062745 [00:00<00:55, 108229.03B/s]\u001b[A\n","  1%|          | 52224/6062745 [00:00<00:47, 127239.97B/s]\u001b[A\n","  1%|1         | 87040/6062745 [00:00<00:41, 145054.51B/s]\u001b[A\n","  3%|2         | 174080/6062745 [00:00<00:31, 185784.56B/s]\u001b[A\n","  5%|5         | 330752/6062745 [00:00<00:23, 245293.17B/s]\u001b[A\n"," 11%|#1        | 678912/6062745 [00:00<00:16, 334121.21B/s]\u001b[A\n"," 22%|##2       | 1340416/6062745 [00:01<00:10, 461216.14B/s]\u001b[A\n"," 45%|####4     | 2703360/6062745 [00:01<00:05, 643796.26B/s]\u001b[A\n","100%|##########| 6062745/6062745 [00:01<00:00, 4152432.73B/s]\n","2020-11-09 02:00:42,169 - INFO - allennlp.common.file_utils - copying /tmp/tmp2htphkd8 to cache at /root/.allennlp/cache/489da0b06d3f818cf178855e6476c6a2a96d8563b33a696ff6d76ea4c1d65e70.46c349d9ba2a850b5695e1b11596608e17c0c42233f248f8a196aade2e393df1\n","2020-11-09 02:00:42,174 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/489da0b06d3f818cf178855e6476c6a2a96d8563b33a696ff6d76ea4c1d65e70.46c349d9ba2a850b5695e1b11596608e17c0c42233f248f8a196aade2e393df1\n","2020-11-09 02:00:42,174 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmp2htphkd8\n","30135it [00:09, 3019.76it/s]\n","2020-11-09 02:00:49,656 - INFO - allennlp.training.trainer_pieces - From dataset instances, validation, train, test will be considered for vocabulary creation.\n","2020-11-09 02:00:49,656 - INFO - allennlp.common.params - vocabulary.type = None\n","2020-11-09 02:00:49,656 - INFO - allennlp.common.params - vocabulary.extend = False\n","2020-11-09 02:00:49,656 - INFO - allennlp.common.params - vocabulary.directory_path = None\n","2020-11-09 02:00:49,656 - INFO - allennlp.common.params - vocabulary.min_count = None\n","2020-11-09 02:00:49,656 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None\n","2020-11-09 02:00:49,656 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')\n","2020-11-09 02:00:49,656 - INFO - allennlp.common.params - vocabulary.pretrained_files = {}\n","2020-11-09 02:00:49,656 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None\n","2020-11-09 02:00:49,656 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False\n","2020-11-09 02:00:49,656 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None\n","2020-11-09 02:00:49,657 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n","240387it [00:01, 177417.74it/s]\n","2020-11-09 02:00:51,012 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'dropout': '0.1', 'feedforward_layer': {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1}, 'seq2vec_encoder': {'embedding_dim': 768, 'type': 'cls_pooler'}, 'text_field_embedder': {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'type': 'basic_classifier_with_f1'} and extras {'vocab'}\n","2020-11-09 02:00:51,012 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1\n","2020-11-09 02:00:51,012 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.models.basic_classifier_with_f1.BasicClassifierWithF1'> from params {'dropout': '0.1', 'feedforward_layer': {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1}, 'seq2vec_encoder': {'embedding_dim': 768, 'type': 'cls_pooler'}, 'text_field_embedder': {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}} and extras {'vocab'}\n","2020-11-09 02:00:51,013 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}} and extras {'vocab'}\n","2020-11-09 02:00:51,013 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n","2020-11-09 02:00:51,013 - INFO - allennlp.common.params - model.text_field_embedder.embedder_to_indexer_map = None\n","2020-11-09 02:00:51,013 - INFO - allennlp.common.params - model.text_field_embedder.allow_unmatched_keys = False\n","2020-11-09 02:00:51,013 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders = None\n","2020-11-09 02:00:51,013 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras {'vocab'}\n","2020-11-09 02:00:51,013 - INFO - allennlp.common.params - model.text_field_embedder.roberta.type = pretrained_transformer\n","2020-11-09 02:00:51,013 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.pretrained_transformer_embedder.PretrainedTransformerEmbedder'> from params {'model_name': 'roberta-base'} and extras {'vocab'}\n","2020-11-09 02:00:51,014 - INFO - allennlp.common.params - model.text_field_embedder.roberta.model_name = roberta-base\n","2020-11-09 02:00:51,390 - INFO - pytorch_transformers.modeling_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/pytorch_transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n","2020-11-09 02:00:51,390 - INFO - pytorch_transformers.modeling_utils - Model config {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 1,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","2020-11-09 02:00:51,823 - INFO - pytorch_transformers.modeling_utils - loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n","2020-11-09 02:00:56,215 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'embedding_dim': 768, 'type': 'cls_pooler'} and extras {'vocab'}\n","2020-11-09 02:00:56,215 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler\n","2020-11-09 02:00:56,215 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.modules.seq2vec_encoders.cls_pooler.CLSPooler'> from params {'embedding_dim': 768} and extras {'vocab'}\n","2020-11-09 02:00:56,215 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768\n","2020-11-09 02:00:56,216 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1} and extras {'vocab'}\n","2020-11-09 02:00:56,216 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768\n","2020-11-09 02:00:56,216 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1\n","2020-11-09 02:00:56,216 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768\n","2020-11-09 02:00:56,216 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh\n","2020-11-09 02:00:56,217 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0\n","2020-11-09 02:00:56,222 - INFO - allennlp.common.params - model.dropout = 0.1\n","2020-11-09 02:00:56,222 - INFO - allennlp.common.params - model.num_labels = None\n","2020-11-09 02:00:56,222 - INFO - allennlp.common.params - model.label_namespace = labels\n","2020-11-09 02:00:56,223 - INFO - allennlp.nn.initializers - Initializing parameters\n","2020-11-09 02:00:56,224 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n","2020-11-09 02:00:56,225 - INFO - allennlp.nn.initializers -    _classification_layer.bias\n","2020-11-09 02:00:56,225 - INFO - allennlp.nn.initializers -    _classification_layer.weight\n","2020-11-09 02:00:56,225 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias\n","2020-11-09 02:00:56,225 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight\n","2020-11-09 02:00:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias\n","2020-11-09 02:00:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight\n","2020-11-09 02:00:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight\n","2020-11-09 02:00:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight\n","2020-11-09 02:00:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight\n","2020-11-09 02:00:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias\n","2020-11-09 02:00:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight\n","2020-11-09 02:00:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias\n","2020-11-09 02:00:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight\n","2020-11-09 02:00:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias\n","2020-11-09 02:00:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight\n","2020-11-09 02:00:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias\n","2020-11-09 02:00:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight\n","2020-11-09 02:00:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias\n","2020-11-09 02:00:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight\n","2020-11-09 02:00:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias\n","2020-11-09 02:00:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight\n","2020-11-09 02:00:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias\n","2020-11-09 02:00:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight\n","2020-11-09 02:00:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias\n","2020-11-09 02:00:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight\n","2020-11-09 02:00:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias\n","2020-11-09 02:00:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight\n","2020-11-09 02:00:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias\n","2020-11-09 02:00:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight\n","2020-11-09 02:00:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias\n","2020-11-09 02:00:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight\n","2020-11-09 02:00:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias\n","2020-11-09 02:00:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight\n","2020-11-09 02:00:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias\n","2020-11-09 02:00:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight\n","2020-11-09 02:00:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias\n","2020-11-09 02:00:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight\n","2020-11-09 02:00:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias\n","2020-11-09 02:00:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight\n","2020-11-09 02:00:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias\n","2020-11-09 02:00:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight\n","2020-11-09 02:00:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias\n","2020-11-09 02:00:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight\n","2020-11-09 02:00:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias\n","2020-11-09 02:00:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight\n","2020-11-09 02:00:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias\n","2020-11-09 02:00:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight\n","2020-11-09 02:00:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias\n","2020-11-09 02:00:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight\n","2020-11-09 02:00:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias\n","2020-11-09 02:00:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight\n","2020-11-09 02:00:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias\n","2020-11-09 02:00:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight\n","2020-11-09 02:00:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias\n","2020-11-09 02:00:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight\n","2020-11-09 02:00:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias\n","2020-11-09 02:00:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight\n","2020-11-09 02:00:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias\n","2020-11-09 02:00:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight\n","2020-11-09 02:00:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias\n","2020-11-09 02:00:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight\n","2020-11-09 02:00:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias\n","2020-11-09 02:00:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight\n","2020-11-09 02:00:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias\n","2020-11-09 02:00:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight\n","2020-11-09 02:00:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias\n","2020-11-09 02:00:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight\n","2020-11-09 02:00:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias\n","2020-11-09 02:00:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight\n","2020-11-09 02:00:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias\n","2020-11-09 02:00:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight\n","2020-11-09 02:00:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias\n","2020-11-09 02:00:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight\n","2020-11-09 02:00:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias\n","2020-11-09 02:00:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight\n","2020-11-09 02:00:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias\n","2020-11-09 02:00:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight\n","2020-11-09 02:00:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias\n","2020-11-09 02:00:56,231 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight\n","2020-11-09 02:00:56,231 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,231 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,231 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias\n","2020-11-09 02:00:56,231 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight\n","2020-11-09 02:00:56,231 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias\n","2020-11-09 02:00:56,231 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight\n","2020-11-09 02:00:56,231 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias\n","2020-11-09 02:00:56,231 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight\n","2020-11-09 02:00:56,231 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias\n","2020-11-09 02:00:56,231 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight\n","2020-11-09 02:00:56,231 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias\n","2020-11-09 02:00:56,231 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight\n","2020-11-09 02:00:56,231 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias\n","2020-11-09 02:00:56,231 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight\n","2020-11-09 02:00:56,231 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias\n","2020-11-09 02:00:56,231 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight\n","2020-11-09 02:00:56,231 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias\n","2020-11-09 02:00:56,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight\n","2020-11-09 02:00:56,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias\n","2020-11-09 02:00:56,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight\n","2020-11-09 02:00:56,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias\n","2020-11-09 02:00:56,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight\n","2020-11-09 02:00:56,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias\n","2020-11-09 02:00:56,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight\n","2020-11-09 02:00:56,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias\n","2020-11-09 02:00:56,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight\n","2020-11-09 02:00:56,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias\n","2020-11-09 02:00:56,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight\n","2020-11-09 02:00:56,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias\n","2020-11-09 02:00:56,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight\n","2020-11-09 02:00:56,306 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,306 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,306 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias\n","2020-11-09 02:00:56,306 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight\n","2020-11-09 02:00:56,306 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias\n","2020-11-09 02:00:56,306 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight\n","2020-11-09 02:00:56,306 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias\n","2020-11-09 02:00:56,306 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight\n","2020-11-09 02:00:56,306 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias\n","2020-11-09 02:00:56,306 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight\n","2020-11-09 02:00:56,306 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias\n","2020-11-09 02:00:56,306 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight\n","2020-11-09 02:00:56,307 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias\n","2020-11-09 02:00:56,307 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight\n","2020-11-09 02:00:56,307 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias\n","2020-11-09 02:00:56,307 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight\n","2020-11-09 02:00:56,307 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,307 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,307 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias\n","2020-11-09 02:00:56,307 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight\n","2020-11-09 02:00:56,307 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias\n","2020-11-09 02:00:56,307 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight\n","2020-11-09 02:00:56,307 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias\n","2020-11-09 02:00:56,307 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight\n","2020-11-09 02:00:56,308 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias\n","2020-11-09 02:00:56,308 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight\n","2020-11-09 02:00:56,308 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias\n","2020-11-09 02:00:56,308 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight\n","2020-11-09 02:00:56,308 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias\n","2020-11-09 02:00:56,308 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight\n","2020-11-09 02:00:56,308 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias\n","2020-11-09 02:00:56,308 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight\n","2020-11-09 02:00:56,308 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,308 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,308 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias\n","2020-11-09 02:00:56,308 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight\n","2020-11-09 02:00:56,308 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias\n","2020-11-09 02:00:56,309 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight\n","2020-11-09 02:00:56,309 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias\n","2020-11-09 02:00:56,309 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight\n","2020-11-09 02:00:56,309 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias\n","2020-11-09 02:00:56,309 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight\n","2020-11-09 02:00:56,309 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias\n","2020-11-09 02:00:56,309 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight\n","2020-11-09 02:00:56,309 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias\n","2020-11-09 02:00:56,309 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight\n","2020-11-09 02:00:56,309 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias\n","2020-11-09 02:00:56,309 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight\n","2020-11-09 02:00:56,309 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,309 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,310 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias\n","2020-11-09 02:00:56,310 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight\n","2020-11-09 02:00:56,310 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias\n","2020-11-09 02:00:56,310 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight\n","2020-11-09 02:00:56,310 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias\n","2020-11-09 02:00:56,310 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight\n","2020-11-09 02:00:56,310 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias\n","2020-11-09 02:00:56,310 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight\n","2020-11-09 02:00:56,310 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias\n","2020-11-09 02:00:56,310 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight\n","2020-11-09 02:00:56,310 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias\n","2020-11-09 02:00:56,310 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight\n","2020-11-09 02:00:56,310 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias\n","2020-11-09 02:00:56,311 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight\n","2020-11-09 02:00:56,311 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,311 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,311 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias\n","2020-11-09 02:00:56,311 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight\n","2020-11-09 02:00:56,311 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias\n","2020-11-09 02:00:56,311 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight\n","2020-11-09 02:00:56,311 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias\n","2020-11-09 02:00:56,311 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight\n","2020-11-09 02:00:56,311 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias\n","2020-11-09 02:00:56,311 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight\n","2020-11-09 02:00:56,311 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias\n","2020-11-09 02:00:56,311 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight\n","2020-11-09 02:00:56,312 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias\n","2020-11-09 02:00:56,312 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight\n","2020-11-09 02:00:56,312 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias\n","2020-11-09 02:00:56,312 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight\n","2020-11-09 02:00:56,312 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias\n","2020-11-09 02:00:56,312 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight\n","2020-11-09 02:00:56,314 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 8, 'sorting_keys': [['tokens', 'num_tokens']], 'type': 'bucket'} and extras set()\n","2020-11-09 02:00:56,314 - INFO - allennlp.common.params - iterator.type = bucket\n","2020-11-09 02:00:56,314 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 8, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()\n","2020-11-09 02:00:56,314 - INFO - allennlp.common.params - iterator.sorting_keys = [['tokens', 'num_tokens']]\n","2020-11-09 02:00:56,314 - INFO - allennlp.common.params - iterator.padding_noise = 0.1\n","2020-11-09 02:00:56,314 - INFO - allennlp.common.params - iterator.biggest_batch_first = False\n","2020-11-09 02:00:56,314 - INFO - allennlp.common.params - iterator.batch_size = 8\n","2020-11-09 02:00:56,314 - INFO - allennlp.common.params - iterator.instances_per_epoch = None\n","2020-11-09 02:00:56,314 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None\n","2020-11-09 02:00:56,314 - INFO - allennlp.common.params - iterator.cache_instances = False\n","2020-11-09 02:00:56,315 - INFO - allennlp.common.params - iterator.track_epoch = False\n","2020-11-09 02:00:56,315 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None\n","2020-11-09 02:00:56,315 - INFO - allennlp.common.params - iterator.skip_smaller_batches = False\n","2020-11-09 02:00:56,315 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'sorting_keys': [['tokens', 'num_tokens']], 'type': 'bucket'} and extras set()\n","2020-11-09 02:00:56,315 - INFO - allennlp.common.params - validation_iterator.type = bucket\n","2020-11-09 02:00:56,315 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 64, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()\n","2020-11-09 02:00:56,315 - INFO - allennlp.common.params - validation_iterator.sorting_keys = [['tokens', 'num_tokens']]\n","2020-11-09 02:00:56,315 - INFO - allennlp.common.params - validation_iterator.padding_noise = 0.1\n","2020-11-09 02:00:56,315 - INFO - allennlp.common.params - validation_iterator.biggest_batch_first = False\n","2020-11-09 02:00:56,315 - INFO - allennlp.common.params - validation_iterator.batch_size = 64\n","2020-11-09 02:00:56,315 - INFO - allennlp.common.params - validation_iterator.instances_per_epoch = None\n","2020-11-09 02:00:56,315 - INFO - allennlp.common.params - validation_iterator.max_instances_in_memory = None\n","2020-11-09 02:00:56,315 - INFO - allennlp.common.params - validation_iterator.cache_instances = False\n","2020-11-09 02:00:56,316 - INFO - allennlp.common.params - validation_iterator.track_epoch = False\n","2020-11-09 02:00:56,316 - INFO - allennlp.common.params - validation_iterator.maximum_samples_per_batch = None\n","2020-11-09 02:00:56,316 - INFO - allennlp.common.params - validation_iterator.skip_smaller_batches = False\n","2020-11-09 02:00:56,316 - INFO - allennlp.common.params - trainer.no_grad = ()\n","2020-11-09 02:00:56,319 - INFO - allennlp.training.trainer_pieces - Following parameters are Frozen  (without gradient):\n","2020-11-09 02:00:56,319 - INFO - allennlp.training.trainer_pieces - Following parameters are Tunable (with gradient):\n","2020-11-09 02:00:56,319 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight\n","2020-11-09 02:00:56,319 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight\n","2020-11-09 02:00:56,319 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight\n","2020-11-09 02:00:56,319 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight\n","2020-11-09 02:00:56,319 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias\n","2020-11-09 02:00:56,319 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight\n","2020-11-09 02:00:56,319 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias\n","2020-11-09 02:00:56,319 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight\n","2020-11-09 02:00:56,319 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias\n","2020-11-09 02:00:56,319 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight\n","2020-11-09 02:00:56,319 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias\n","2020-11-09 02:00:56,319 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight\n","2020-11-09 02:00:56,319 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias\n","2020-11-09 02:00:56,320 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight\n","2020-11-09 02:00:56,321 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias\n","2020-11-09 02:00:56,322 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight\n","2020-11-09 02:00:56,322 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias\n","2020-11-09 02:00:56,322 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight\n","2020-11-09 02:00:56,322 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias\n","2020-11-09 02:00:56,322 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight\n","2020-11-09 02:00:56,322 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias\n","2020-11-09 02:00:56,322 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight\n","2020-11-09 02:00:56,322 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias\n","2020-11-09 02:00:56,322 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight\n","2020-11-09 02:00:56,322 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias\n","2020-11-09 02:00:56,413 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight\n","2020-11-09 02:00:56,413 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias\n","2020-11-09 02:00:56,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight\n","2020-11-09 02:00:56,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias\n","2020-11-09 02:00:56,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight\n","2020-11-09 02:00:56,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias\n","2020-11-09 02:00:56,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight\n","2020-11-09 02:00:56,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias\n","2020-11-09 02:00:56,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight\n","2020-11-09 02:00:56,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias\n","2020-11-09 02:00:56,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight\n","2020-11-09 02:00:56,414 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias\n","2020-11-09 02:00:56,415 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight\n","2020-11-09 02:00:56,415 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias\n","2020-11-09 02:00:56,415 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight\n","2020-11-09 02:00:56,415 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias\n","2020-11-09 02:00:56,415 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,415 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,415 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight\n","2020-11-09 02:00:56,415 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias\n","2020-11-09 02:00:56,415 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight\n","2020-11-09 02:00:56,415 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias\n","2020-11-09 02:00:56,415 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight\n","2020-11-09 02:00:56,415 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias\n","2020-11-09 02:00:56,415 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight\n","2020-11-09 02:00:56,415 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias\n","2020-11-09 02:00:56,416 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight\n","2020-11-09 02:00:56,416 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias\n","2020-11-09 02:00:56,416 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight\n","2020-11-09 02:00:56,416 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias\n","2020-11-09 02:00:56,416 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight\n","2020-11-09 02:00:56,416 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias\n","2020-11-09 02:00:56,416 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,416 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,416 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight\n","2020-11-09 02:00:56,416 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias\n","2020-11-09 02:00:56,416 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight\n","2020-11-09 02:00:56,416 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias\n","2020-11-09 02:00:56,416 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight\n","2020-11-09 02:00:56,416 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias\n","2020-11-09 02:00:56,417 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight\n","2020-11-09 02:00:56,417 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias\n","2020-11-09 02:00:56,417 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight\n","2020-11-09 02:00:56,417 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias\n","2020-11-09 02:00:56,417 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight\n","2020-11-09 02:00:56,417 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias\n","2020-11-09 02:00:56,417 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight\n","2020-11-09 02:00:56,417 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias\n","2020-11-09 02:00:56,417 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,417 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,417 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight\n","2020-11-09 02:00:56,417 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias\n","2020-11-09 02:00:56,417 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight\n","2020-11-09 02:00:56,417 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias\n","2020-11-09 02:00:56,418 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight\n","2020-11-09 02:00:56,418 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias\n","2020-11-09 02:00:56,418 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight\n","2020-11-09 02:00:56,418 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias\n","2020-11-09 02:00:56,418 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight\n","2020-11-09 02:00:56,418 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias\n","2020-11-09 02:00:56,418 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight\n","2020-11-09 02:00:56,418 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias\n","2020-11-09 02:00:56,418 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight\n","2020-11-09 02:00:56,418 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias\n","2020-11-09 02:00:56,418 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,418 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,418 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight\n","2020-11-09 02:00:56,418 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias\n","2020-11-09 02:00:56,419 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight\n","2020-11-09 02:00:56,419 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias\n","2020-11-09 02:00:56,419 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight\n","2020-11-09 02:00:56,419 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias\n","2020-11-09 02:00:56,419 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight\n","2020-11-09 02:00:56,419 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias\n","2020-11-09 02:00:56,419 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight\n","2020-11-09 02:00:56,419 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias\n","2020-11-09 02:00:56,419 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight\n","2020-11-09 02:00:56,419 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias\n","2020-11-09 02:00:56,419 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight\n","2020-11-09 02:00:56,419 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias\n","2020-11-09 02:00:56,419 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,420 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,420 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight\n","2020-11-09 02:00:56,420 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias\n","2020-11-09 02:00:56,420 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight\n","2020-11-09 02:00:56,420 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias\n","2020-11-09 02:00:56,420 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight\n","2020-11-09 02:00:56,420 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias\n","2020-11-09 02:00:56,420 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight\n","2020-11-09 02:00:56,420 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias\n","2020-11-09 02:00:56,420 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight\n","2020-11-09 02:00:56,420 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias\n","2020-11-09 02:00:56,420 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight\n","2020-11-09 02:00:56,420 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias\n","2020-11-09 02:00:56,420 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight\n","2020-11-09 02:00:56,421 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias\n","2020-11-09 02:00:56,421 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,421 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,421 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight\n","2020-11-09 02:00:56,421 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias\n","2020-11-09 02:00:56,421 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight\n","2020-11-09 02:00:56,421 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias\n","2020-11-09 02:00:56,421 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight\n","2020-11-09 02:00:56,421 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias\n","2020-11-09 02:00:56,421 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight\n","2020-11-09 02:00:56,421 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias\n","2020-11-09 02:00:56,421 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight\n","2020-11-09 02:00:56,421 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias\n","2020-11-09 02:00:56,421 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight\n","2020-11-09 02:00:56,422 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias\n","2020-11-09 02:00:56,422 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight\n","2020-11-09 02:00:56,422 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias\n","2020-11-09 02:00:56,422 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n","2020-11-09 02:00:56,422 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n","2020-11-09 02:00:56,422 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight\n","2020-11-09 02:00:56,422 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias\n","2020-11-09 02:00:56,422 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight\n","2020-11-09 02:00:56,422 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias\n","2020-11-09 02:00:56,422 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight\n","2020-11-09 02:00:56,422 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias\n","2020-11-09 02:00:56,422 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight\n","2020-11-09 02:00:56,422 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias\n","2020-11-09 02:00:56,422 - INFO - allennlp.training.trainer_pieces - _feedforward_layer._linear_layers.0.weight\n","2020-11-09 02:00:56,423 - INFO - allennlp.training.trainer_pieces - _feedforward_layer._linear_layers.0.bias\n","2020-11-09 02:00:56,423 - INFO - allennlp.training.trainer_pieces - _classification_layer.weight\n","2020-11-09 02:00:56,423 - INFO - allennlp.training.trainer_pieces - _classification_layer.bias\n","2020-11-09 02:00:56,423 - INFO - allennlp.common.params - trainer.patience = 3\n","2020-11-09 02:00:56,423 - INFO - allennlp.common.params - trainer.validation_metric = +f1\n","2020-11-09 02:00:56,423 - INFO - allennlp.common.params - trainer.shuffle = True\n","2020-11-09 02:00:56,423 - INFO - allennlp.common.params - trainer.num_epochs = 10\n","2020-11-09 02:00:56,423 - INFO - allennlp.common.params - trainer.cuda_device = 0\n","2020-11-09 02:00:56,423 - INFO - allennlp.common.params - trainer.grad_norm = None\n","2020-11-09 02:00:56,423 - INFO - allennlp.common.params - trainer.grad_clipping = None\n","2020-11-09 02:00:56,423 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None\n","2020-11-09 02:00:56,423 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n","2020-11-09 02:00:56,424 - INFO - allennlp.common.params - trainer.gradient_accumulation_batch_size = 8\n","2020-11-09 02:01:01,167 - INFO - allennlp.common.params - trainer.optimizer.type = bert_adam\n","2020-11-09 02:01:01,167 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n","2020-11-09 02:01:01,167 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n","2020-11-09 02:01:01,167 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups.0.1.weight_decay = 0\n","2020-11-09 02:01:01,168 - INFO - allennlp.training.optimizers - Done constructing parameter groups.\n","2020-11-09 02:01:01,168 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias', '_feedforward_layer._linear_layers.0.bias', '_classification_layer.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias'], {'weight_decay': 0}\n","2020-11-09 02:01:01,243 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight', '_classification_layer.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight', '_feedforward_layer._linear_layers.0.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight'], {}\n","2020-11-09 02:01:01,244 - WARNING - allennlp.training.optimizers - When constructing parameter groups,  layer_norm.weight not match any parameter name\n","2020-11-09 02:01:01,244 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125240069\n","2020-11-09 02:01:01,246 - INFO - allennlp.common.params - trainer.optimizer.infer_type_and_cast = True\n","2020-11-09 02:01:01,246 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n","2020-11-09 02:01:01,246 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n","2020-11-09 02:01:01,246 - INFO - allennlp.common.params - trainer.optimizer.b1 = 0.9\n","2020-11-09 02:01:01,246 - INFO - allennlp.common.params - trainer.optimizer.b2 = 0.98\n","2020-11-09 02:01:01,246 - INFO - allennlp.common.params - trainer.optimizer.e = 1e-06\n","2020-11-09 02:01:01,246 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05\n","2020-11-09 02:01:01,246 - INFO - allennlp.common.params - trainer.optimizer.max_grad_norm = 1\n","2020-11-09 02:01:01,246 - INFO - allennlp.common.params - trainer.optimizer.schedule = warmup_linear\n","2020-11-09 02:01:01,247 - INFO - allennlp.common.params - trainer.optimizer.t_total = -1\n","2020-11-09 02:01:01,247 - INFO - allennlp.common.params - trainer.optimizer.warmup = 0.06\n","2020-11-09 02:01:01,247 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1\n","2020-11-09 02:01:01,247 - WARNING - pytorch_pretrained_bert.optimization - t_total value of -1 results in schedule not being applied\n","2020-11-09 02:01:01,249 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 0\n","2020-11-09 02:01:01,249 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None\n","2020-11-09 02:01:01,249 - INFO - allennlp.common.params - trainer.model_save_interval = None\n","2020-11-09 02:01:01,249 - INFO - allennlp.common.params - trainer.summary_interval = 100\n","2020-11-09 02:01:01,250 - INFO - allennlp.common.params - trainer.histogram_interval = None\n","2020-11-09 02:01:01,250 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True\n","2020-11-09 02:01:01,250 - INFO - allennlp.common.params - trainer.should_log_learning_rate = False\n","2020-11-09 02:01:01,250 - INFO - allennlp.common.params - trainer.log_batch_size_period = None\n","2020-11-09 02:01:01,252 - INFO - allennlp.training.trainer - Beginning training.\n","2020-11-09 02:01:01,253 - INFO - allennlp.training.trainer - Epoch 0/9\n","2020-11-09 02:01:01,253 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 6279.692\n","2020-11-09 02:01:01,383 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1769\n","2020-11-09 02:01:01,387 - INFO - allennlp.training.trainer - Training\n","  0%|          | 0/22505 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","f1: 0.7743, accuracy: 0.8395, loss: 0.4648 ||: 100%|##########| 22505/22505 [56:25<00:00,  6.65it/s]\n","2020-11-09 02:57:27,048 - INFO - allennlp.training.trainer - Validating\n","f1: 0.7932, accuracy: 0.8521, loss: 0.4780 ||: 100%|##########| 473/473 [00:26<00:00, 17.86it/s]\n","2020-11-09 02:57:53,537 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 02:57:53,537 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  1769.000  |       N/A\n","2020-11-09 02:57:53,538 - INFO - allennlp.training.tensorboard_writer - loss            |     0.465  |     0.478\n","2020-11-09 02:57:53,539 - INFO - allennlp.training.tensorboard_writer - f1              |     0.774  |     0.793\n","2020-11-09 02:57:53,540 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.839  |     0.852\n","2020-11-09 02:57:53,540 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  6279.692  |       N/A\n","2020-11-09 02:57:58,689 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/rct20k_nas_01/best.th'.\n","2020-11-09 02:58:00,561 - INFO - allennlp.training.trainer - Epoch duration: 0:56:59.308768\n","2020-11-09 02:58:00,564 - INFO - allennlp.training.trainer - Estimated training time remaining: 8:32:53\n","2020-11-09 02:58:00,564 - INFO - allennlp.training.trainer - Epoch 1/9\n","2020-11-09 02:58:00,564 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 6545.056\n","2020-11-09 02:58:00,704 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 15267\n","2020-11-09 02:58:00,708 - INFO - allennlp.training.trainer - Training\n","f1: 0.7911, accuracy: 0.8543, loss: 0.4349 ||: 100%|##########| 22505/22505 [56:38<00:00,  6.62it/s]\n","2020-11-09 03:54:39,681 - INFO - allennlp.training.trainer - Validating\n","f1: 0.8046, accuracy: 0.8632, loss: 0.4073 ||: 100%|##########| 473/473 [00:25<00:00, 18.70it/s]\n","2020-11-09 03:55:04,984 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 03:55:04,985 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  15267.000  |       N/A\n","2020-11-09 03:55:04,985 - INFO - allennlp.training.tensorboard_writer - loss            |     0.435  |     0.407\n","2020-11-09 03:55:04,987 - INFO - allennlp.training.tensorboard_writer - f1              |     0.791  |     0.805\n","2020-11-09 03:55:04,987 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.854  |     0.863\n","2020-11-09 03:55:04,987 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  6545.056  |       N/A\n","2020-11-09 03:55:10,120 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/rct20k_nas_01/best.th'.\n","2020-11-09 03:55:12,155 - INFO - allennlp.training.trainer - Epoch duration: 0:57:11.590853\n","2020-11-09 03:55:12,155 - INFO - allennlp.training.trainer - Estimated training time remaining: 7:36:43\n","2020-11-09 03:55:12,155 - INFO - allennlp.training.trainer - Epoch 2/9\n","2020-11-09 03:55:12,155 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 6553.66\n","2020-11-09 03:55:12,290 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 15267\n","2020-11-09 03:55:12,294 - INFO - allennlp.training.trainer - Training\n","f1: 0.8006, accuracy: 0.8626, loss: 0.4174 ||: 100%|##########| 22505/22505 [56:59<00:00,  6.58it/s]\n","2020-11-09 04:52:11,429 - INFO - allennlp.training.trainer - Validating\n","f1: 0.8078, accuracy: 0.8656, loss: 0.4458 ||: 100%|##########| 473/473 [00:25<00:00, 18.81it/s]\n","2020-11-09 04:52:36,572 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 04:52:36,573 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  15267.000  |       N/A\n","2020-11-09 04:52:36,573 - INFO - allennlp.training.tensorboard_writer - loss            |     0.417  |     0.446\n","2020-11-09 04:52:36,574 - INFO - allennlp.training.tensorboard_writer - f1              |     0.801  |     0.808\n","2020-11-09 04:52:36,574 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.863  |     0.866\n","2020-11-09 04:52:36,574 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  6553.660  |       N/A\n","2020-11-09 04:52:41,801 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/rct20k_nas_01/best.th'.\n","2020-11-09 04:52:43,800 - INFO - allennlp.training.trainer - Epoch duration: 0:57:31.645171\n","2020-11-09 04:52:43,800 - INFO - allennlp.training.trainer - Estimated training time remaining: 6:40:39\n","2020-11-09 04:52:43,801 - INFO - allennlp.training.trainer - Epoch 3/9\n","2020-11-09 04:52:43,801 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 6553.676\n","2020-11-09 04:52:43,932 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 15751\n","2020-11-09 04:52:43,936 - INFO - allennlp.training.trainer - Training\n","f1: 0.8067, accuracy: 0.8691, loss: 0.3964 ||: 100%|##########| 22505/22505 [55:57<00:00,  6.70it/s]\n","2020-11-09 05:48:41,245 - INFO - allennlp.training.trainer - Validating\n","f1: 0.8074, accuracy: 0.8656, loss: 0.4374 ||: 100%|##########| 473/473 [00:25<00:00, 18.80it/s]\n","2020-11-09 05:49:06,406 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 05:49:06,406 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  15751.000  |       N/A\n","2020-11-09 05:49:06,407 - INFO - allennlp.training.tensorboard_writer - loss            |     0.396  |     0.437\n","2020-11-09 05:49:06,407 - INFO - allennlp.training.tensorboard_writer - f1              |     0.807  |     0.807\n","2020-11-09 05:49:06,407 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.869  |     0.866\n","2020-11-09 05:49:06,408 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  6553.676  |       N/A\n","2020-11-09 05:49:11,688 - INFO - allennlp.training.trainer - Epoch duration: 0:56:27.887645\n","2020-11-09 05:49:11,689 - INFO - allennlp.training.trainer - Estimated training time remaining: 5:42:15\n","2020-11-09 05:49:11,689 - INFO - allennlp.training.trainer - Epoch 4/9\n","2020-11-09 05:49:11,689 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 6553.676\n","2020-11-09 05:49:11,823 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 15751\n","2020-11-09 05:49:11,826 - INFO - allennlp.training.trainer - Training\n","f1: 0.8146, accuracy: 0.8755, loss: 0.3857 ||: 100%|##########| 22505/22505 [55:16<00:00,  6.79it/s]\n","2020-11-09 06:44:27,976 - INFO - allennlp.training.trainer - Validating\n","f1: 0.8028, accuracy: 0.8575, loss: 0.5352 ||: 100%|##########| 473/473 [00:28<00:00, 16.43it/s]\n","2020-11-09 06:44:56,774 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 06:44:56,774 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  15751.000  |       N/A\n","2020-11-09 06:44:56,775 - INFO - allennlp.training.tensorboard_writer - loss            |     0.386  |     0.535\n","2020-11-09 06:44:56,775 - INFO - allennlp.training.tensorboard_writer - f1              |     0.815  |     0.803\n","2020-11-09 06:44:56,776 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.875  |     0.858\n","2020-11-09 06:44:56,777 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  6553.676  |       N/A\n","2020-11-09 06:45:01,879 - INFO - allennlp.training.trainer - Epoch duration: 0:55:50.190284\n","2020-11-09 06:45:01,879 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:44:00\n","2020-11-09 06:45:01,879 - INFO - allennlp.training.trainer - Epoch 5/9\n","2020-11-09 06:45:01,879 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 6553.696\n","2020-11-09 06:45:02,015 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 4773\n","2020-11-09 06:45:02,020 - INFO - allennlp.training.trainer - Training\n","f1: 0.8207, accuracy: 0.8805, loss: 0.3760 ||: 100%|##########| 22505/22505 [54:46<00:00,  6.85it/s]\n","2020-11-09 07:39:48,346 - INFO - allennlp.training.trainer - Validating\n","f1: 0.8001, accuracy: 0.8576, loss: 0.4652 ||: 100%|##########| 473/473 [00:24<00:00, 18.92it/s]\n","2020-11-09 07:40:13,345 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.\n","2020-11-09 07:40:13,346 - INFO - allennlp.training.checkpointer - loading best weights\n","2020-11-09 07:40:13,677 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.\n","2020-11-09 07:40:13,678 - INFO - allennlp.training.util - Iterating over dataset\n","f1: 0.80, accuracy: 0.86, loss: 0.47 ||: 100%|##########| 471/471 [00:25<00:00, 18.26it/s]\n","2020-11-09 07:40:39,473 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/rct20k_nas_01/model.tar.gz\n","2020-11-09 07:41:05,001 - INFO - allennlp.common.util - Metrics: {\n","  \"best_epoch\": 2,\n","  \"peak_cpu_memory_MB\": 6553.696,\n","  \"peak_gpu_0_memory_MB\": 15751,\n","  \"training_duration\": \"4:43:55.524889\",\n","  \"training_start_epoch\": 0,\n","  \"training_epochs\": 4,\n","  \"epoch\": 4,\n","  \"training_f1\": 0.8145888090133667,\n","  \"training_accuracy\": 0.8754610086647412,\n","  \"training_loss\": 0.38572845008135326,\n","  \"training_cpu_memory_MB\": 6553.676,\n","  \"training_gpu_0_memory_MB\": 15751,\n","  \"validation_f1\": 0.8028497099876404,\n","  \"validation_accuracy\": 0.8575400503111347,\n","  \"validation_loss\": 0.5351843070920584,\n","  \"best_validation_f1\": 0.8078266024589539,\n","  \"best_validation_accuracy\": 0.865616311399444,\n","  \"best_validation_loss\": 0.44583957696660376,\n","  \"test_f1\": 0.8028999090194702,\n","  \"test_accuracy\": 0.8595652895304463,\n","  \"test_loss\": 0.4676875979708796\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mHE1f20eqLhH","executionInfo":{"status":"ok","timestamp":1604908005719,"user_tz":300,"elapsed":21838733,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"a42d8c95-e72e-4bcb-94e2-d9ea0ed53c90","colab":{"base_uri":"https://localhost:8080/"}},"source":["!python -m scripts.train \\\n","        --config training_config/classifier.jsonnet \\\n","        --serialization_dir model_logs/citation_intent_nas_01 \\\n","        --hyperparameters ROBERTA_CLASSIFIER_MINI \\\n","        --dataset citation_intent \\\n","        --model roberta-base \\\n","        --device 0 \\\n","        --perf +f1 \\\n","        --evaluate_on_test"],"execution_count":18,"outputs":[{"output_type":"stream","text":["2020-11-09 07:41:14,113 - INFO - pytorch_pretrained_bert.modeling - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-09 07:41:14,567 - INFO - pytorch_transformers.modeling_bert - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-09 07:41:14,570 - INFO - pytorch_transformers.modeling_xlnet - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-09 07:41:15,065 - INFO - allennlp.common.params - random_seed = 1157\n","2020-11-09 07:41:15,065 - INFO - allennlp.common.params - numpy_seed = 1157\n","2020-11-09 07:41:15,065 - INFO - allennlp.common.params - pytorch_seed = 1157\n","2020-11-09 07:41:15,073 - INFO - allennlp.common.checks - Pytorch version: 1.7.0+cu101\n","2020-11-09 07:41:15,074 - INFO - allennlp.common.params - evaluate_on_test = True\n","2020-11-09 07:41:15,075 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}, 'type': 'text_classification_json_with_sampling'} and extras set()\n","2020-11-09 07:41:15,075 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling\n","2020-11-09 07:41:15,075 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.data.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}} and extras set()\n","2020-11-09 07:41:15,075 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 07:41:15,075 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.type = pretrained_transformer\n","2020-11-09 07:41:15,075 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base'} and extras set()\n","2020-11-09 07:41:15,075 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.model_name = roberta-base\n","2020-11-09 07:41:15,076 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.do_lowercase = False\n","2020-11-09 07:41:15,076 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.namespace = tags\n","2020-11-09 07:41:15,076 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.token_min_padding_length = 0\n","2020-11-09 07:41:15,815 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 07:41:15,815 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 07:41:15,894 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 1\n","2020-11-09 07:41:15,895 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 07:41:15,895 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer\n","2020-11-09 07:41:15,895 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>']} and extras set()\n","2020-11-09 07:41:15,895 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base\n","2020-11-09 07:41:15,895 - INFO - allennlp.common.params - dataset_reader.tokenizer.do_lowercase = False\n","2020-11-09 07:41:15,895 - INFO - allennlp.common.params - dataset_reader.tokenizer.start_tokens = ['<s>']\n","2020-11-09 07:41:15,895 - INFO - allennlp.common.params - dataset_reader.tokenizer.end_tokens = ['</s>']\n","2020-11-09 07:41:16,700 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 07:41:16,700 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 07:41:16,772 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512\n","2020-11-09 07:41:16,772 - INFO - allennlp.common.params - dataset_reader.sample = None\n","2020-11-09 07:41:16,772 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False\n","2020-11-09 07:41:16,772 - INFO - allennlp.common.params - dataset_reader.lazy = False\n","2020-11-09 07:41:16,772 - INFO - allennlp.training.util - Using a separate dataset reader to load validation and test data.\n","2020-11-09 07:41:16,772 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}, 'type': 'text_classification_json_with_sampling'} and extras set()\n","2020-11-09 07:41:16,772 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling\n","2020-11-09 07:41:16,772 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.data.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}} and extras set()\n","2020-11-09 07:41:16,772 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 07:41:16,773 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.type = pretrained_transformer\n","2020-11-09 07:41:16,773 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base'} and extras set()\n","2020-11-09 07:41:16,773 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.model_name = roberta-base\n","2020-11-09 07:41:16,773 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.do_lowercase = False\n","2020-11-09 07:41:16,773 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.namespace = tags\n","2020-11-09 07:41:16,773 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.token_min_padding_length = 0\n","2020-11-09 07:41:17,511 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 07:41:17,511 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 07:41:17,585 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 1\n","2020-11-09 07:41:17,585 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 07:41:17,585 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer\n","2020-11-09 07:41:17,585 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>']} and extras set()\n","2020-11-09 07:41:17,586 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base\n","2020-11-09 07:41:17,586 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.do_lowercase = False\n","2020-11-09 07:41:17,586 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.start_tokens = ['<s>']\n","2020-11-09 07:41:17,586 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.end_tokens = ['</s>']\n","2020-11-09 07:41:18,333 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 07:41:18,333 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 07:41:18,404 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512\n","2020-11-09 07:41:18,404 - INFO - allennlp.common.params - validation_dataset_reader.sample = None\n","2020-11-09 07:41:18,404 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False\n","2020-11-09 07:41:18,405 - INFO - allennlp.common.params - validation_dataset_reader.lazy = False\n","2020-11-09 07:41:18,405 - INFO - allennlp.common.params - train_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/citation_intent/train.jsonl\n","2020-11-09 07:41:18,405 - INFO - allennlp.training.util - Reading training data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/citation_intent/train.jsonl\n","0it [00:00, ?it/s]2020-11-09 07:41:19,091 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/citation_intent/train.jsonl not found in cache, downloading to /tmp/tmpwjue7inh\n","\n","  0%|          | 0/465895 [00:00<?, ?B/s]\u001b[A\n","  0%|          | 1024/465895 [00:00<01:13, 6361.76B/s]\u001b[A\n"," 11%|#1        | 52224/465895 [00:00<00:45, 9010.63B/s]\u001b[A\n"," 19%|#8        | 87040/465895 [00:00<00:29, 12645.57B/s]\u001b[A\n"," 45%|####4     | 208896/465895 [00:00<00:14, 17935.78B/s]\u001b[A\n","100%|##########| 465895/465895 [00:00<00:00, 575829.90B/s]\n","2020-11-09 07:41:20,645 - INFO - allennlp.common.file_utils - copying /tmp/tmpwjue7inh to cache at /root/.allennlp/cache/e63c8ea977152f5441f122048babaae85c0cfec5b476939d47c48007b693a46d.7ea13b1f554882ff49054868a00c2f567c01d9e088e553eae187bf27f5c033cf\n","2020-11-09 07:41:20,646 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/e63c8ea977152f5441f122048babaae85c0cfec5b476939d47c48007b693a46d.7ea13b1f554882ff49054868a00c2f567c01d9e088e553eae187bf27f5c033cf\n","2020-11-09 07:41:20,646 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmpwjue7inh\n","1688it [00:03, 546.80it/s]\n","2020-11-09 07:41:21,492 - INFO - allennlp.common.params - validation_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/citation_intent/dev.jsonl\n","2020-11-09 07:41:21,493 - INFO - allennlp.training.util - Reading validation data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/citation_intent/dev.jsonl\n","0it [00:00, ?it/s]2020-11-09 07:41:22,164 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/citation_intent/dev.jsonl not found in cache, downloading to /tmp/tmp0f69x_jk\n","\n","  0%|          | 0/30138 [00:00<?, ?B/s]\u001b[A\n","100%|##########| 30138/30138 [00:00<00:00, 186540.33B/s]\n","2020-11-09 07:41:23,088 - INFO - allennlp.common.file_utils - copying /tmp/tmp0f69x_jk to cache at /root/.allennlp/cache/569819492be704f7055bba5bd57667102ae010298fa7017f6f1f5827eddd1951.eb12b0ed0574347d6dd1adcfa52d200c30780569bea1ae08ccdda0711abd3bf6\n","2020-11-09 07:41:23,089 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/569819492be704f7055bba5bd57667102ae010298fa7017f6f1f5827eddd1951.eb12b0ed0574347d6dd1adcfa52d200c30780569bea1ae08ccdda0711abd3bf6\n","2020-11-09 07:41:23,089 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmp0f69x_jk\n","114it [00:01, 67.70it/s]\n","2020-11-09 07:41:23,177 - INFO - allennlp.common.params - test_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/citation_intent/test.jsonl\n","2020-11-09 07:41:23,177 - INFO - allennlp.training.util - Reading test data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/citation_intent/test.jsonl\n","0it [00:00, ?it/s]2020-11-09 07:41:23,852 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/citation_intent/test.jsonl not found in cache, downloading to /tmp/tmptl33ky3j\n","\n","  0%|          | 0/38637 [00:00<?, ?B/s]\u001b[A\n","100%|##########| 38637/38637 [00:00<00:00, 236385.59B/s]\n","2020-11-09 07:41:24,718 - INFO - allennlp.common.file_utils - copying /tmp/tmptl33ky3j to cache at /root/.allennlp/cache/e40b8ad548dc5d5fc1f7e5173ea148954ca4b64794f7c0d7716b6dc541ccc63e.7a59da5c45951a1f2465d419a131bdb5578f02ae00fa3593cad3168caccf2390\n","2020-11-09 07:41:24,718 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/e40b8ad548dc5d5fc1f7e5173ea148954ca4b64794f7c0d7716b6dc541ccc63e.7a59da5c45951a1f2465d419a131bdb5578f02ae00fa3593cad3168caccf2390\n","2020-11-09 07:41:24,719 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmptl33ky3j\n","139it [00:01, 85.92it/s]\n","2020-11-09 07:41:24,810 - INFO - allennlp.training.trainer_pieces - From dataset instances, validation, train, test will be considered for vocabulary creation.\n","2020-11-09 07:41:24,810 - INFO - allennlp.common.params - vocabulary.type = None\n","2020-11-09 07:41:24,810 - INFO - allennlp.common.params - vocabulary.extend = False\n","2020-11-09 07:41:24,810 - INFO - allennlp.common.params - vocabulary.directory_path = None\n","2020-11-09 07:41:24,810 - INFO - allennlp.common.params - vocabulary.min_count = None\n","2020-11-09 07:41:24,810 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None\n","2020-11-09 07:41:24,810 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')\n","2020-11-09 07:41:24,810 - INFO - allennlp.common.params - vocabulary.pretrained_files = {}\n","2020-11-09 07:41:24,810 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None\n","2020-11-09 07:41:24,810 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False\n","2020-11-09 07:41:24,810 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None\n","2020-11-09 07:41:24,810 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n","1941it [00:00, 137997.19it/s]\n","2020-11-09 07:41:24,825 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'dropout': '0.1', 'feedforward_layer': {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1}, 'seq2vec_encoder': {'embedding_dim': 768, 'type': 'cls_pooler'}, 'text_field_embedder': {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'type': 'basic_classifier_with_f1'} and extras {'vocab'}\n","2020-11-09 07:41:24,825 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1\n","2020-11-09 07:41:24,825 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.models.basic_classifier_with_f1.BasicClassifierWithF1'> from params {'dropout': '0.1', 'feedforward_layer': {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1}, 'seq2vec_encoder': {'embedding_dim': 768, 'type': 'cls_pooler'}, 'text_field_embedder': {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}} and extras {'vocab'}\n","2020-11-09 07:41:24,826 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}} and extras {'vocab'}\n","2020-11-09 07:41:24,826 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n","2020-11-09 07:41:24,826 - INFO - allennlp.common.params - model.text_field_embedder.embedder_to_indexer_map = None\n","2020-11-09 07:41:24,826 - INFO - allennlp.common.params - model.text_field_embedder.allow_unmatched_keys = False\n","2020-11-09 07:41:24,826 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders = None\n","2020-11-09 07:41:24,826 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras {'vocab'}\n","2020-11-09 07:41:24,826 - INFO - allennlp.common.params - model.text_field_embedder.roberta.type = pretrained_transformer\n","2020-11-09 07:41:24,826 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.pretrained_transformer_embedder.PretrainedTransformerEmbedder'> from params {'model_name': 'roberta-base'} and extras {'vocab'}\n","2020-11-09 07:41:24,826 - INFO - allennlp.common.params - model.text_field_embedder.roberta.model_name = roberta-base\n","2020-11-09 07:41:25,193 - INFO - pytorch_transformers.modeling_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/pytorch_transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n","2020-11-09 07:41:25,194 - INFO - pytorch_transformers.modeling_utils - Model config {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 1,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","2020-11-09 07:41:25,570 - INFO - pytorch_transformers.modeling_utils - loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n","2020-11-09 07:41:29,932 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'embedding_dim': 768, 'type': 'cls_pooler'} and extras {'vocab'}\n","2020-11-09 07:41:29,932 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler\n","2020-11-09 07:41:29,932 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.modules.seq2vec_encoders.cls_pooler.CLSPooler'> from params {'embedding_dim': 768} and extras {'vocab'}\n","2020-11-09 07:41:29,933 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768\n","2020-11-09 07:41:29,933 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1} and extras {'vocab'}\n","2020-11-09 07:41:29,933 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768\n","2020-11-09 07:41:29,933 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1\n","2020-11-09 07:41:29,933 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768\n","2020-11-09 07:41:29,933 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh\n","2020-11-09 07:41:29,934 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0\n","2020-11-09 07:41:29,939 - INFO - allennlp.common.params - model.dropout = 0.1\n","2020-11-09 07:41:29,939 - INFO - allennlp.common.params - model.num_labels = None\n","2020-11-09 07:41:29,939 - INFO - allennlp.common.params - model.label_namespace = labels\n","2020-11-09 07:41:29,940 - INFO - allennlp.nn.initializers - Initializing parameters\n","2020-11-09 07:41:29,941 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n","2020-11-09 07:41:29,941 - INFO - allennlp.nn.initializers -    _classification_layer.bias\n","2020-11-09 07:41:29,942 - INFO - allennlp.nn.initializers -    _classification_layer.weight\n","2020-11-09 07:41:29,942 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias\n","2020-11-09 07:41:29,942 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight\n","2020-11-09 07:41:29,942 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias\n","2020-11-09 07:41:29,942 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight\n","2020-11-09 07:41:29,942 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight\n","2020-11-09 07:41:29,942 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight\n","2020-11-09 07:41:29,942 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight\n","2020-11-09 07:41:29,942 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n","2020-11-09 07:41:29,942 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n","2020-11-09 07:41:29,942 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias\n","2020-11-09 07:41:29,942 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight\n","2020-11-09 07:41:29,942 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias\n","2020-11-09 07:41:29,942 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight\n","2020-11-09 07:41:29,942 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias\n","2020-11-09 07:41:29,943 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight\n","2020-11-09 07:41:29,943 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias\n","2020-11-09 07:41:29,943 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight\n","2020-11-09 07:41:29,943 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias\n","2020-11-09 07:41:29,943 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight\n","2020-11-09 07:41:29,943 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias\n","2020-11-09 07:41:29,943 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight\n","2020-11-09 07:41:29,943 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias\n","2020-11-09 07:41:29,943 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight\n","2020-11-09 07:41:29,943 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n","2020-11-09 07:41:29,943 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n","2020-11-09 07:41:29,943 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias\n","2020-11-09 07:41:29,943 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight\n","2020-11-09 07:41:29,943 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias\n","2020-11-09 07:41:29,943 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight\n","2020-11-09 07:41:29,943 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias\n","2020-11-09 07:41:29,943 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight\n","2020-11-09 07:41:29,944 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias\n","2020-11-09 07:41:29,944 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight\n","2020-11-09 07:41:29,944 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias\n","2020-11-09 07:41:29,944 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight\n","2020-11-09 07:41:29,944 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias\n","2020-11-09 07:41:29,944 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight\n","2020-11-09 07:41:29,944 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias\n","2020-11-09 07:41:29,944 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight\n","2020-11-09 07:41:29,944 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n","2020-11-09 07:41:29,944 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n","2020-11-09 07:41:29,944 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias\n","2020-11-09 07:41:29,944 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight\n","2020-11-09 07:41:29,944 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias\n","2020-11-09 07:41:29,944 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight\n","2020-11-09 07:41:29,944 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias\n","2020-11-09 07:41:29,944 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight\n","2020-11-09 07:41:29,945 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias\n","2020-11-09 07:41:29,945 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight\n","2020-11-09 07:41:29,945 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias\n","2020-11-09 07:41:29,945 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight\n","2020-11-09 07:41:29,945 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias\n","2020-11-09 07:41:29,945 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight\n","2020-11-09 07:41:29,945 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias\n","2020-11-09 07:41:29,945 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight\n","2020-11-09 07:41:29,945 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n","2020-11-09 07:41:29,945 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n","2020-11-09 07:41:29,945 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias\n","2020-11-09 07:41:29,945 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight\n","2020-11-09 07:41:29,945 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias\n","2020-11-09 07:41:29,945 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight\n","2020-11-09 07:41:29,945 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias\n","2020-11-09 07:41:29,945 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight\n","2020-11-09 07:41:29,946 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias\n","2020-11-09 07:41:29,946 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight\n","2020-11-09 07:41:29,946 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias\n","2020-11-09 07:41:29,946 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight\n","2020-11-09 07:41:29,946 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias\n","2020-11-09 07:41:29,946 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight\n","2020-11-09 07:41:29,946 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias\n","2020-11-09 07:41:29,946 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight\n","2020-11-09 07:41:29,946 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n","2020-11-09 07:41:29,946 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n","2020-11-09 07:41:29,946 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias\n","2020-11-09 07:41:29,946 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight\n","2020-11-09 07:41:29,946 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias\n","2020-11-09 07:41:29,946 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight\n","2020-11-09 07:41:29,946 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias\n","2020-11-09 07:41:29,946 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight\n","2020-11-09 07:41:29,947 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias\n","2020-11-09 07:41:29,947 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight\n","2020-11-09 07:41:29,947 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias\n","2020-11-09 07:41:29,947 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight\n","2020-11-09 07:41:29,947 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias\n","2020-11-09 07:41:29,947 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight\n","2020-11-09 07:41:29,947 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias\n","2020-11-09 07:41:29,947 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight\n","2020-11-09 07:41:29,947 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n","2020-11-09 07:41:29,947 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n","2020-11-09 07:41:29,947 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias\n","2020-11-09 07:41:29,947 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight\n","2020-11-09 07:41:29,947 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias\n","2020-11-09 07:41:29,947 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight\n","2020-11-09 07:41:29,947 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias\n","2020-11-09 07:41:29,947 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight\n","2020-11-09 07:41:29,947 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias\n","2020-11-09 07:41:29,948 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight\n","2020-11-09 07:41:29,948 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias\n","2020-11-09 07:41:29,948 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight\n","2020-11-09 07:41:29,948 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias\n","2020-11-09 07:41:29,948 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight\n","2020-11-09 07:41:29,948 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias\n","2020-11-09 07:41:29,948 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight\n","2020-11-09 07:41:29,948 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n","2020-11-09 07:41:29,955 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n","2020-11-09 07:41:29,955 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias\n","2020-11-09 07:41:29,955 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight\n","2020-11-09 07:41:29,955 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias\n","2020-11-09 07:41:29,955 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight\n","2020-11-09 07:41:29,955 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias\n","2020-11-09 07:41:29,955 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight\n","2020-11-09 07:41:29,955 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias\n","2020-11-09 07:41:29,955 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight\n","2020-11-09 07:41:29,956 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias\n","2020-11-09 07:41:29,956 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight\n","2020-11-09 07:41:29,956 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias\n","2020-11-09 07:41:29,956 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight\n","2020-11-09 07:41:29,956 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias\n","2020-11-09 07:41:29,956 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight\n","2020-11-09 07:41:29,956 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n","2020-11-09 07:41:29,956 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n","2020-11-09 07:41:29,956 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias\n","2020-11-09 07:41:29,956 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight\n","2020-11-09 07:41:29,956 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias\n","2020-11-09 07:41:29,956 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight\n","2020-11-09 07:41:29,956 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias\n","2020-11-09 07:41:29,956 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight\n","2020-11-09 07:41:29,957 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias\n","2020-11-09 07:41:29,957 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight\n","2020-11-09 07:41:29,957 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias\n","2020-11-09 07:41:29,957 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight\n","2020-11-09 07:41:29,957 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias\n","2020-11-09 07:41:29,957 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight\n","2020-11-09 07:41:29,957 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias\n","2020-11-09 07:41:29,957 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight\n","2020-11-09 07:41:29,957 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n","2020-11-09 07:41:29,957 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n","2020-11-09 07:41:29,957 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias\n","2020-11-09 07:41:29,957 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight\n","2020-11-09 07:41:29,957 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias\n","2020-11-09 07:41:29,957 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight\n","2020-11-09 07:41:29,958 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias\n","2020-11-09 07:41:29,958 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight\n","2020-11-09 07:41:29,958 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias\n","2020-11-09 07:41:29,958 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight\n","2020-11-09 07:41:29,958 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias\n","2020-11-09 07:41:29,958 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight\n","2020-11-09 07:41:29,958 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias\n","2020-11-09 07:41:29,958 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight\n","2020-11-09 07:41:29,958 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias\n","2020-11-09 07:41:29,958 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight\n","2020-11-09 07:41:29,958 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n","2020-11-09 07:41:29,958 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n","2020-11-09 07:41:29,958 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias\n","2020-11-09 07:41:29,958 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight\n","2020-11-09 07:41:29,959 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias\n","2020-11-09 07:41:29,959 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight\n","2020-11-09 07:41:29,959 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias\n","2020-11-09 07:41:29,959 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight\n","2020-11-09 07:41:29,959 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias\n","2020-11-09 07:41:29,959 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight\n","2020-11-09 07:41:29,959 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias\n","2020-11-09 07:41:29,959 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight\n","2020-11-09 07:41:29,959 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias\n","2020-11-09 07:41:29,959 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight\n","2020-11-09 07:41:29,959 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias\n","2020-11-09 07:41:29,959 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight\n","2020-11-09 07:41:29,959 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n","2020-11-09 07:41:29,959 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n","2020-11-09 07:41:29,959 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias\n","2020-11-09 07:41:29,960 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight\n","2020-11-09 07:41:29,960 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias\n","2020-11-09 07:41:29,960 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight\n","2020-11-09 07:41:29,960 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias\n","2020-11-09 07:41:29,960 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight\n","2020-11-09 07:41:29,960 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias\n","2020-11-09 07:41:29,960 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight\n","2020-11-09 07:41:29,960 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias\n","2020-11-09 07:41:29,960 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight\n","2020-11-09 07:41:29,960 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias\n","2020-11-09 07:41:29,960 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight\n","2020-11-09 07:41:29,960 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias\n","2020-11-09 07:41:29,960 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight\n","2020-11-09 07:41:29,960 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n","2020-11-09 07:41:29,961 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n","2020-11-09 07:41:29,961 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias\n","2020-11-09 07:41:29,961 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight\n","2020-11-09 07:41:29,961 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias\n","2020-11-09 07:41:29,961 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight\n","2020-11-09 07:41:29,961 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias\n","2020-11-09 07:41:29,961 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight\n","2020-11-09 07:41:29,961 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias\n","2020-11-09 07:41:29,961 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight\n","2020-11-09 07:41:29,961 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias\n","2020-11-09 07:41:29,961 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight\n","2020-11-09 07:41:29,961 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias\n","2020-11-09 07:41:29,961 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight\n","2020-11-09 07:41:29,961 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias\n","2020-11-09 07:41:29,961 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight\n","2020-11-09 07:41:29,962 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias\n","2020-11-09 07:41:29,962 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight\n","2020-11-09 07:41:29,963 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 8, 'sorting_keys': [['tokens', 'num_tokens']], 'type': 'bucket'} and extras set()\n","2020-11-09 07:41:29,963 - INFO - allennlp.common.params - iterator.type = bucket\n","2020-11-09 07:41:29,963 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 8, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()\n","2020-11-09 07:41:29,963 - INFO - allennlp.common.params - iterator.sorting_keys = [['tokens', 'num_tokens']]\n","2020-11-09 07:41:29,964 - INFO - allennlp.common.params - iterator.padding_noise = 0.1\n","2020-11-09 07:41:29,964 - INFO - allennlp.common.params - iterator.biggest_batch_first = False\n","2020-11-09 07:41:29,964 - INFO - allennlp.common.params - iterator.batch_size = 8\n","2020-11-09 07:41:29,964 - INFO - allennlp.common.params - iterator.instances_per_epoch = None\n","2020-11-09 07:41:29,964 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None\n","2020-11-09 07:41:29,964 - INFO - allennlp.common.params - iterator.cache_instances = False\n","2020-11-09 07:41:29,964 - INFO - allennlp.common.params - iterator.track_epoch = False\n","2020-11-09 07:41:29,964 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None\n","2020-11-09 07:41:29,964 - INFO - allennlp.common.params - iterator.skip_smaller_batches = False\n","2020-11-09 07:41:29,964 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'sorting_keys': [['tokens', 'num_tokens']], 'type': 'bucket'} and extras set()\n","2020-11-09 07:41:29,965 - INFO - allennlp.common.params - validation_iterator.type = bucket\n","2020-11-09 07:41:29,965 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 64, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()\n","2020-11-09 07:41:29,965 - INFO - allennlp.common.params - validation_iterator.sorting_keys = [['tokens', 'num_tokens']]\n","2020-11-09 07:41:29,965 - INFO - allennlp.common.params - validation_iterator.padding_noise = 0.1\n","2020-11-09 07:41:29,965 - INFO - allennlp.common.params - validation_iterator.biggest_batch_first = False\n","2020-11-09 07:41:29,965 - INFO - allennlp.common.params - validation_iterator.batch_size = 64\n","2020-11-09 07:41:29,965 - INFO - allennlp.common.params - validation_iterator.instances_per_epoch = None\n","2020-11-09 07:41:29,965 - INFO - allennlp.common.params - validation_iterator.max_instances_in_memory = None\n","2020-11-09 07:41:29,965 - INFO - allennlp.common.params - validation_iterator.cache_instances = False\n","2020-11-09 07:41:29,966 - INFO - allennlp.common.params - validation_iterator.track_epoch = False\n","2020-11-09 07:41:29,966 - INFO - allennlp.common.params - validation_iterator.maximum_samples_per_batch = None\n","2020-11-09 07:41:29,966 - INFO - allennlp.common.params - validation_iterator.skip_smaller_batches = False\n","2020-11-09 07:41:29,966 - INFO - allennlp.common.params - trainer.no_grad = ()\n","2020-11-09 07:41:29,969 - INFO - allennlp.training.trainer_pieces - Following parameters are Frozen  (without gradient):\n","2020-11-09 07:41:29,969 - INFO - allennlp.training.trainer_pieces - Following parameters are Tunable (with gradient):\n","2020-11-09 07:41:29,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight\n","2020-11-09 07:41:29,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight\n","2020-11-09 07:41:29,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight\n","2020-11-09 07:41:29,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight\n","2020-11-09 07:41:29,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias\n","2020-11-09 07:41:29,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight\n","2020-11-09 07:41:29,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias\n","2020-11-09 07:41:29,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight\n","2020-11-09 07:41:29,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias\n","2020-11-09 07:41:29,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight\n","2020-11-09 07:41:29,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias\n","2020-11-09 07:41:29,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight\n","2020-11-09 07:41:29,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias\n","2020-11-09 07:41:29,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n","2020-11-09 07:41:29,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n","2020-11-09 07:41:29,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight\n","2020-11-09 07:41:29,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias\n","2020-11-09 07:41:29,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight\n","2020-11-09 07:41:29,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias\n","2020-11-09 07:41:29,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight\n","2020-11-09 07:41:29,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias\n","2020-11-09 07:41:29,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight\n","2020-11-09 07:41:29,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias\n","2020-11-09 07:41:29,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight\n","2020-11-09 07:41:29,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias\n","2020-11-09 07:41:29,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight\n","2020-11-09 07:41:29,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias\n","2020-11-09 07:41:29,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight\n","2020-11-09 07:41:29,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias\n","2020-11-09 07:41:29,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n","2020-11-09 07:41:29,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n","2020-11-09 07:41:29,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight\n","2020-11-09 07:41:29,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias\n","2020-11-09 07:41:29,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight\n","2020-11-09 07:41:29,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias\n","2020-11-09 07:41:29,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight\n","2020-11-09 07:41:29,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias\n","2020-11-09 07:41:29,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight\n","2020-11-09 07:41:29,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias\n","2020-11-09 07:41:29,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight\n","2020-11-09 07:41:29,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias\n","2020-11-09 07:41:29,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight\n","2020-11-09 07:41:29,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias\n","2020-11-09 07:41:29,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight\n","2020-11-09 07:41:29,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias\n","2020-11-09 07:41:29,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n","2020-11-09 07:41:29,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n","2020-11-09 07:41:29,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight\n","2020-11-09 07:41:29,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias\n","2020-11-09 07:41:29,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight\n","2020-11-09 07:41:29,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias\n","2020-11-09 07:41:29,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight\n","2020-11-09 07:41:29,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias\n","2020-11-09 07:41:29,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight\n","2020-11-09 07:41:29,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias\n","2020-11-09 07:41:29,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight\n","2020-11-09 07:41:29,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias\n","2020-11-09 07:41:29,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight\n","2020-11-09 07:41:29,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias\n","2020-11-09 07:41:29,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight\n","2020-11-09 07:41:29,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias\n","2020-11-09 07:41:29,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n","2020-11-09 07:41:29,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n","2020-11-09 07:41:29,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight\n","2020-11-09 07:41:29,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias\n","2020-11-09 07:41:29,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight\n","2020-11-09 07:41:29,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias\n","2020-11-09 07:41:29,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight\n","2020-11-09 07:41:29,973 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias\n","2020-11-09 07:41:29,973 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight\n","2020-11-09 07:41:29,973 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias\n","2020-11-09 07:41:29,973 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight\n","2020-11-09 07:41:29,973 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias\n","2020-11-09 07:41:29,973 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight\n","2020-11-09 07:41:29,973 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias\n","2020-11-09 07:41:30,063 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight\n","2020-11-09 07:41:30,063 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias\n","2020-11-09 07:41:30,063 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n","2020-11-09 07:41:30,063 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n","2020-11-09 07:41:30,063 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight\n","2020-11-09 07:41:30,063 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias\n","2020-11-09 07:41:30,063 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight\n","2020-11-09 07:41:30,063 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias\n","2020-11-09 07:41:30,063 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight\n","2020-11-09 07:41:30,063 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias\n","2020-11-09 07:41:30,063 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight\n","2020-11-09 07:41:30,064 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias\n","2020-11-09 07:41:30,064 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight\n","2020-11-09 07:41:30,064 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias\n","2020-11-09 07:41:30,064 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight\n","2020-11-09 07:41:30,064 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias\n","2020-11-09 07:41:30,064 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight\n","2020-11-09 07:41:30,064 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias\n","2020-11-09 07:41:30,064 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n","2020-11-09 07:41:30,064 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n","2020-11-09 07:41:30,064 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight\n","2020-11-09 07:41:30,064 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias\n","2020-11-09 07:41:30,064 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight\n","2020-11-09 07:41:30,064 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias\n","2020-11-09 07:41:30,064 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight\n","2020-11-09 07:41:30,064 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias\n","2020-11-09 07:41:30,065 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight\n","2020-11-09 07:41:30,065 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias\n","2020-11-09 07:41:30,065 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight\n","2020-11-09 07:41:30,065 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias\n","2020-11-09 07:41:30,065 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight\n","2020-11-09 07:41:30,065 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias\n","2020-11-09 07:41:30,065 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight\n","2020-11-09 07:41:30,065 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias\n","2020-11-09 07:41:30,065 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n","2020-11-09 07:41:30,065 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n","2020-11-09 07:41:30,065 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight\n","2020-11-09 07:41:30,065 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias\n","2020-11-09 07:41:30,065 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight\n","2020-11-09 07:41:30,065 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias\n","2020-11-09 07:41:30,065 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight\n","2020-11-09 07:41:30,066 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias\n","2020-11-09 07:41:30,066 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight\n","2020-11-09 07:41:30,066 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias\n","2020-11-09 07:41:30,066 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight\n","2020-11-09 07:41:30,066 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias\n","2020-11-09 07:41:30,066 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight\n","2020-11-09 07:41:30,066 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias\n","2020-11-09 07:41:30,066 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight\n","2020-11-09 07:41:30,066 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias\n","2020-11-09 07:41:30,066 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n","2020-11-09 07:41:30,066 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n","2020-11-09 07:41:30,066 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight\n","2020-11-09 07:41:30,066 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias\n","2020-11-09 07:41:30,067 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight\n","2020-11-09 07:41:30,067 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias\n","2020-11-09 07:41:30,067 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight\n","2020-11-09 07:41:30,067 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias\n","2020-11-09 07:41:30,067 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight\n","2020-11-09 07:41:30,067 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias\n","2020-11-09 07:41:30,067 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight\n","2020-11-09 07:41:30,067 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias\n","2020-11-09 07:41:30,067 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight\n","2020-11-09 07:41:30,067 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias\n","2020-11-09 07:41:30,067 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight\n","2020-11-09 07:41:30,067 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias\n","2020-11-09 07:41:30,067 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n","2020-11-09 07:41:30,068 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n","2020-11-09 07:41:30,068 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight\n","2020-11-09 07:41:30,068 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias\n","2020-11-09 07:41:30,068 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight\n","2020-11-09 07:41:30,068 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias\n","2020-11-09 07:41:30,068 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight\n","2020-11-09 07:41:30,068 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias\n","2020-11-09 07:41:30,068 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight\n","2020-11-09 07:41:30,068 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias\n","2020-11-09 07:41:30,068 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight\n","2020-11-09 07:41:30,068 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias\n","2020-11-09 07:41:30,068 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight\n","2020-11-09 07:41:30,068 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias\n","2020-11-09 07:41:30,068 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight\n","2020-11-09 07:41:30,069 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias\n","2020-11-09 07:41:30,069 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n","2020-11-09 07:41:30,069 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n","2020-11-09 07:41:30,069 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight\n","2020-11-09 07:41:30,069 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias\n","2020-11-09 07:41:30,069 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight\n","2020-11-09 07:41:30,069 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias\n","2020-11-09 07:41:30,069 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight\n","2020-11-09 07:41:30,069 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias\n","2020-11-09 07:41:30,069 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight\n","2020-11-09 07:41:30,069 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias\n","2020-11-09 07:41:30,069 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight\n","2020-11-09 07:41:30,069 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias\n","2020-11-09 07:41:30,070 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight\n","2020-11-09 07:41:30,070 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias\n","2020-11-09 07:41:30,070 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight\n","2020-11-09 07:41:30,070 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias\n","2020-11-09 07:41:30,070 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n","2020-11-09 07:41:30,070 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n","2020-11-09 07:41:30,070 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight\n","2020-11-09 07:41:30,070 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias\n","2020-11-09 07:41:30,070 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight\n","2020-11-09 07:41:30,070 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias\n","2020-11-09 07:41:30,070 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight\n","2020-11-09 07:41:30,070 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias\n","2020-11-09 07:41:30,070 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight\n","2020-11-09 07:41:30,070 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias\n","2020-11-09 07:41:30,071 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight\n","2020-11-09 07:41:30,071 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias\n","2020-11-09 07:41:30,071 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight\n","2020-11-09 07:41:30,071 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias\n","2020-11-09 07:41:30,071 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight\n","2020-11-09 07:41:30,071 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias\n","2020-11-09 07:41:30,071 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n","2020-11-09 07:41:30,071 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n","2020-11-09 07:41:30,071 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight\n","2020-11-09 07:41:30,071 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias\n","2020-11-09 07:41:30,071 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight\n","2020-11-09 07:41:30,071 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias\n","2020-11-09 07:41:30,071 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight\n","2020-11-09 07:41:30,071 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias\n","2020-11-09 07:41:30,071 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight\n","2020-11-09 07:41:30,072 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias\n","2020-11-09 07:41:30,072 - INFO - allennlp.training.trainer_pieces - _feedforward_layer._linear_layers.0.weight\n","2020-11-09 07:41:30,072 - INFO - allennlp.training.trainer_pieces - _feedforward_layer._linear_layers.0.bias\n","2020-11-09 07:41:30,072 - INFO - allennlp.training.trainer_pieces - _classification_layer.weight\n","2020-11-09 07:41:30,072 - INFO - allennlp.training.trainer_pieces - _classification_layer.bias\n","2020-11-09 07:41:30,072 - INFO - allennlp.common.params - trainer.patience = 3\n","2020-11-09 07:41:30,072 - INFO - allennlp.common.params - trainer.validation_metric = +f1\n","2020-11-09 07:41:30,072 - INFO - allennlp.common.params - trainer.shuffle = True\n","2020-11-09 07:41:30,072 - INFO - allennlp.common.params - trainer.num_epochs = 10\n","2020-11-09 07:41:30,072 - INFO - allennlp.common.params - trainer.cuda_device = 0\n","2020-11-09 07:41:30,072 - INFO - allennlp.common.params - trainer.grad_norm = None\n","2020-11-09 07:41:30,072 - INFO - allennlp.common.params - trainer.grad_clipping = None\n","2020-11-09 07:41:30,073 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None\n","2020-11-09 07:41:30,073 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n","2020-11-09 07:41:30,073 - INFO - allennlp.common.params - trainer.gradient_accumulation_batch_size = 8\n","2020-11-09 07:41:34,814 - INFO - allennlp.common.params - trainer.optimizer.type = bert_adam\n","2020-11-09 07:41:34,814 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n","2020-11-09 07:41:34,814 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n","2020-11-09 07:41:34,814 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups.0.1.weight_decay = 0\n","2020-11-09 07:41:34,815 - INFO - allennlp.training.optimizers - Done constructing parameter groups.\n","2020-11-09 07:41:34,815 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_classification_layer.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias', '_feedforward_layer._linear_layers.0.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias'], {'weight_decay': 0}\n","2020-11-09 07:41:34,892 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight', '_feedforward_layer._linear_layers.0.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight', '_classification_layer.weight'], {}\n","2020-11-09 07:41:34,893 - WARNING - allennlp.training.optimizers - When constructing parameter groups,  layer_norm.weight not match any parameter name\n","2020-11-09 07:41:34,893 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125240838\n","2020-11-09 07:41:34,894 - INFO - allennlp.common.params - trainer.optimizer.infer_type_and_cast = True\n","2020-11-09 07:41:34,894 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n","2020-11-09 07:41:34,894 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n","2020-11-09 07:41:34,894 - INFO - allennlp.common.params - trainer.optimizer.b1 = 0.9\n","2020-11-09 07:41:34,895 - INFO - allennlp.common.params - trainer.optimizer.b2 = 0.98\n","2020-11-09 07:41:34,895 - INFO - allennlp.common.params - trainer.optimizer.e = 1e-06\n","2020-11-09 07:41:34,895 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05\n","2020-11-09 07:41:34,895 - INFO - allennlp.common.params - trainer.optimizer.max_grad_norm = 1\n","2020-11-09 07:41:34,895 - INFO - allennlp.common.params - trainer.optimizer.schedule = warmup_linear\n","2020-11-09 07:41:34,895 - INFO - allennlp.common.params - trainer.optimizer.t_total = -1\n","2020-11-09 07:41:34,895 - INFO - allennlp.common.params - trainer.optimizer.warmup = 0.06\n","2020-11-09 07:41:34,895 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1\n","2020-11-09 07:41:34,895 - WARNING - pytorch_pretrained_bert.optimization - t_total value of -1 results in schedule not being applied\n","2020-11-09 07:41:34,896 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 0\n","2020-11-09 07:41:34,896 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None\n","2020-11-09 07:41:34,896 - INFO - allennlp.common.params - trainer.model_save_interval = None\n","2020-11-09 07:41:34,896 - INFO - allennlp.common.params - trainer.summary_interval = 100\n","2020-11-09 07:41:34,897 - INFO - allennlp.common.params - trainer.histogram_interval = None\n","2020-11-09 07:41:34,897 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True\n","2020-11-09 07:41:34,897 - INFO - allennlp.common.params - trainer.should_log_learning_rate = False\n","2020-11-09 07:41:34,897 - INFO - allennlp.common.params - trainer.log_batch_size_period = None\n","2020-11-09 07:41:34,899 - INFO - allennlp.training.trainer - Beginning training.\n","2020-11-09 07:41:34,899 - INFO - allennlp.training.trainer - Epoch 0/9\n","2020-11-09 07:41:34,899 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4852.66\n","2020-11-09 07:41:35,005 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1769\n","2020-11-09 07:41:35,008 - INFO - allennlp.training.trainer - Training\n","  0%|          | 0/211 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","f1: 0.1972, accuracy: 0.5521, loss: 1.2716 ||: 100%|##########| 211/211 [00:33<00:00,  6.30it/s]\n","2020-11-09 07:42:08,510 - INFO - allennlp.training.trainer - Validating\n","f1: 0.2440, accuracy: 0.6491, loss: 0.9657 ||: 100%|##########| 2/2 [00:00<00:00,  9.42it/s]\n","2020-11-09 07:42:08,725 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 07:42:08,726 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.552  |     0.649\n","2020-11-09 07:42:08,726 - INFO - allennlp.training.tensorboard_writer - loss            |     1.272  |     0.966\n","2020-11-09 07:42:08,727 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4852.660  |       N/A\n","2020-11-09 07:42:08,727 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  1769.000  |       N/A\n","2020-11-09 07:42:08,728 - INFO - allennlp.training.tensorboard_writer - f1              |     0.197  |     0.244\n","2020-11-09 07:42:15,540 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/citation_intent_nas_01/best.th'.\n","2020-11-09 07:42:16,666 - INFO - allennlp.training.trainer - Epoch duration: 0:00:41.766959\n","2020-11-09 07:42:16,667 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:06:15\n","2020-11-09 07:42:16,668 - INFO - allennlp.training.trainer - Epoch 1/9\n","2020-11-09 07:42:16,668 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4864.9\n","2020-11-09 07:42:16,784 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 7127\n","2020-11-09 07:42:16,787 - INFO - allennlp.training.trainer - Training\n","f1: 0.3848, accuracy: 0.6914, loss: 0.9287 ||: 100%|##########| 211/211 [00:33<00:00,  6.36it/s]\n","2020-11-09 07:42:49,986 - INFO - allennlp.training.trainer - Validating\n","f1: 0.5381, accuracy: 0.7632, loss: 0.7808 ||: 100%|##########| 2/2 [00:00<00:00,  9.38it/s]\n","2020-11-09 07:42:50,203 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 07:42:50,203 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.691  |     0.763\n","2020-11-09 07:42:50,204 - INFO - allennlp.training.tensorboard_writer - loss            |     0.929  |     0.781\n","2020-11-09 07:42:50,205 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4864.900  |       N/A\n","2020-11-09 07:42:50,205 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  7127.000  |       N/A\n","2020-11-09 07:42:50,205 - INFO - allennlp.training.tensorboard_writer - f1              |     0.385  |     0.538\n","2020-11-09 07:42:57,084 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/citation_intent_nas_01/best.th'.\n","2020-11-09 07:42:58,504 - INFO - allennlp.training.trainer - Epoch duration: 0:00:41.836451\n","2020-11-09 07:42:58,504 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:05:34\n","2020-11-09 07:42:58,504 - INFO - allennlp.training.trainer - Epoch 2/9\n","2020-11-09 07:42:58,504 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4864.984\n","2020-11-09 07:42:58,608 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 7127\n","2020-11-09 07:42:58,611 - INFO - allennlp.training.trainer - Training\n","f1: 0.6390, accuracy: 0.7921, loss: 0.6392 ||: 100%|##########| 211/211 [00:32<00:00,  6.41it/s]\n","2020-11-09 07:43:31,527 - INFO - allennlp.training.trainer - Validating\n","f1: 0.5943, accuracy: 0.7632, loss: 0.7796 ||: 100%|##########| 2/2 [00:00<00:00,  9.70it/s]\n","2020-11-09 07:43:31,736 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 07:43:31,736 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.792  |     0.763\n","2020-11-09 07:43:31,737 - INFO - allennlp.training.tensorboard_writer - loss            |     0.639  |     0.780\n","2020-11-09 07:43:31,737 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4864.984  |       N/A\n","2020-11-09 07:43:31,737 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  7127.000  |       N/A\n","2020-11-09 07:43:31,739 - INFO - allennlp.training.tensorboard_writer - f1              |     0.639  |     0.594\n","2020-11-09 07:43:39,534 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/citation_intent_nas_01/best.th'.\n","2020-11-09 07:43:40,769 - INFO - allennlp.training.trainer - Epoch duration: 0:00:42.264100\n","2020-11-09 07:43:40,769 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:04:53\n","2020-11-09 07:43:40,769 - INFO - allennlp.training.trainer - Epoch 3/9\n","2020-11-09 07:43:40,769 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4864.992\n","2020-11-09 07:43:40,876 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 7127\n","2020-11-09 07:43:40,880 - INFO - allennlp.training.trainer - Training\n","f1: 0.7850, accuracy: 0.8697, loss: 0.4271 ||: 100%|##########| 211/211 [00:32<00:00,  6.41it/s]\n","2020-11-09 07:44:13,819 - INFO - allennlp.training.trainer - Validating\n","f1: 0.6854, accuracy: 0.7982, loss: 0.6210 ||: 100%|##########| 2/2 [00:00<00:00,  9.84it/s]\n","2020-11-09 07:44:14,025 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 07:44:14,025 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.870  |     0.798\n","2020-11-09 07:44:14,026 - INFO - allennlp.training.tensorboard_writer - loss            |     0.427  |     0.621\n","2020-11-09 07:44:14,027 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4864.992  |       N/A\n","2020-11-09 07:44:14,027 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  7127.000  |       N/A\n","2020-11-09 07:44:14,027 - INFO - allennlp.training.tensorboard_writer - f1              |     0.785  |     0.685\n","2020-11-09 07:44:21,142 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/citation_intent_nas_01/best.th'.\n","2020-11-09 07:44:22,180 - INFO - allennlp.training.trainer - Epoch duration: 0:00:41.411040\n","2020-11-09 07:44:22,180 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:04:10\n","2020-11-09 07:44:22,180 - INFO - allennlp.training.trainer - Epoch 4/9\n","2020-11-09 07:44:22,181 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4864.992\n","2020-11-09 07:44:22,289 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 7127\n","2020-11-09 07:44:22,292 - INFO - allennlp.training.trainer - Training\n","f1: 0.8547, accuracy: 0.9028, loss: 0.3071 ||: 100%|##########| 211/211 [00:32<00:00,  6.41it/s]\n","2020-11-09 07:44:55,204 - INFO - allennlp.training.trainer - Validating\n","f1: 0.6263, accuracy: 0.7281, loss: 0.9353 ||: 100%|##########| 2/2 [00:00<00:00,  9.81it/s]\n","2020-11-09 07:44:55,410 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 07:44:55,410 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.903  |     0.728\n","2020-11-09 07:44:55,411 - INFO - allennlp.training.tensorboard_writer - loss            |     0.307  |     0.935\n","2020-11-09 07:44:55,412 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4864.992  |       N/A\n","2020-11-09 07:44:55,412 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  7127.000  |       N/A\n","2020-11-09 07:44:55,412 - INFO - allennlp.training.tensorboard_writer - f1              |     0.855  |     0.626\n","2020-11-09 07:45:02,127 - INFO - allennlp.training.trainer - Epoch duration: 0:00:39.946955\n","2020-11-09 07:45:02,128 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:03:27\n","2020-11-09 07:45:02,128 - INFO - allennlp.training.trainer - Epoch 5/9\n","2020-11-09 07:45:02,128 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4864.992\n","2020-11-09 07:45:02,226 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 7127\n","2020-11-09 07:45:02,229 - INFO - allennlp.training.trainer - Training\n","f1: 0.8882, accuracy: 0.9259, loss: 0.2458 ||: 100%|##########| 211/211 [00:32<00:00,  6.45it/s]\n","2020-11-09 07:45:34,964 - INFO - allennlp.training.trainer - Validating\n","f1: 0.6791, accuracy: 0.7895, loss: 0.7729 ||: 100%|##########| 2/2 [00:00<00:00,  9.73it/s]\n","2020-11-09 07:45:35,172 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 07:45:35,173 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.926  |     0.789\n","2020-11-09 07:45:35,173 - INFO - allennlp.training.tensorboard_writer - loss            |     0.246  |     0.773\n","2020-11-09 07:45:35,173 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4864.992  |       N/A\n","2020-11-09 07:45:35,173 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  7127.000  |       N/A\n","2020-11-09 07:45:35,175 - INFO - allennlp.training.tensorboard_writer - f1              |     0.888  |     0.679\n","2020-11-09 07:45:41,955 - INFO - allennlp.training.trainer - Epoch duration: 0:00:39.827416\n","2020-11-09 07:45:41,956 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:02:44\n","2020-11-09 07:45:41,956 - INFO - allennlp.training.trainer - Epoch 6/9\n","2020-11-09 07:45:41,956 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4865.004\n","2020-11-09 07:45:42,060 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 7127\n","2020-11-09 07:45:42,063 - INFO - allennlp.training.trainer - Training\n","f1: 0.9131, accuracy: 0.9455, loss: 0.1725 ||: 100%|##########| 211/211 [00:32<00:00,  6.45it/s]\n","2020-11-09 07:46:14,754 - INFO - allennlp.training.trainer - Validating\n","f1: 0.6176, accuracy: 0.7719, loss: 1.0572 ||: 100%|##########| 2/2 [00:00<00:00,  9.84it/s]\n","2020-11-09 07:46:14,959 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.\n","2020-11-09 07:46:14,961 - INFO - allennlp.training.checkpointer - loading best weights\n","2020-11-09 07:46:15,440 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.\n","2020-11-09 07:46:15,441 - INFO - allennlp.training.util - Iterating over dataset\n","f1: 0.60, accuracy: 0.76, loss: 0.91 ||: 100%|##########| 3/3 [00:00<00:00, 13.59it/s]\n","2020-11-09 07:46:15,664 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/citation_intent_nas_01/model.tar.gz\n","2020-11-09 07:46:43,833 - INFO - allennlp.common.util - Metrics: {\n","  \"best_epoch\": 3,\n","  \"peak_cpu_memory_MB\": 4865.004,\n","  \"peak_gpu_0_memory_MB\": 7127,\n","  \"training_duration\": \"0:04:00.276124\",\n","  \"training_start_epoch\": 0,\n","  \"training_epochs\": 5,\n","  \"epoch\": 5,\n","  \"training_f1\": 0.888166089852651,\n","  \"training_accuracy\": 0.9259478672985783,\n","  \"training_loss\": 0.24584376246346187,\n","  \"training_cpu_memory_MB\": 4864.992,\n","  \"training_gpu_0_memory_MB\": 7127,\n","  \"validation_f1\": 0.6790629674990972,\n","  \"validation_accuracy\": 0.7894736842105263,\n","  \"validation_loss\": 0.7729426622390747,\n","  \"best_validation_f1\": 0.685377503434817,\n","  \"best_validation_accuracy\": 0.7982456140350878,\n","  \"best_validation_loss\": 0.620998352766037,\n","  \"test_f1\": 0.5985564241806666,\n","  \"test_accuracy\": 0.7553956834532374,\n","  \"test_loss\": 0.9101839661598206\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F9Ix2XLbqM6P","executionInfo":{"status":"ok","timestamp":1604908731817,"user_tz":300,"elapsed":22564830,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"1d9fb000-bfa1-4ace-c41d-67152d637046","colab":{"base_uri":"https://localhost:8080/"}},"source":["!python -m scripts.train \\\n","        --config training_config/classifier.jsonnet \\\n","        --serialization_dir model_logs/sciie_nas_01 \\\n","        --hyperparameters ROBERTA_CLASSIFIER_MINI \\\n","        --dataset sciie \\\n","        --model roberta-base \\\n","        --device 0 \\\n","        --perf +f1 \\\n","        --evaluate_on_test"],"execution_count":19,"outputs":[{"output_type":"stream","text":["2020-11-09 07:46:47,516 - INFO - pytorch_pretrained_bert.modeling - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-09 07:46:47,962 - INFO - pytorch_transformers.modeling_bert - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-09 07:46:47,965 - INFO - pytorch_transformers.modeling_xlnet - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-09 07:46:48,455 - INFO - allennlp.common.params - random_seed = 530437\n","2020-11-09 07:46:48,455 - INFO - allennlp.common.params - numpy_seed = 530437\n","2020-11-09 07:46:48,455 - INFO - allennlp.common.params - pytorch_seed = 530437\n","2020-11-09 07:46:48,462 - INFO - allennlp.common.checks - Pytorch version: 1.7.0+cu101\n","2020-11-09 07:46:48,464 - INFO - allennlp.common.params - evaluate_on_test = True\n","2020-11-09 07:46:48,464 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}, 'type': 'text_classification_json_with_sampling'} and extras set()\n","2020-11-09 07:46:48,464 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling\n","2020-11-09 07:46:48,465 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.data.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}} and extras set()\n","2020-11-09 07:46:48,465 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 07:46:48,465 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.type = pretrained_transformer\n","2020-11-09 07:46:48,465 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base'} and extras set()\n","2020-11-09 07:46:48,465 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.model_name = roberta-base\n","2020-11-09 07:46:48,465 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.do_lowercase = False\n","2020-11-09 07:46:48,465 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.namespace = tags\n","2020-11-09 07:46:48,465 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.token_min_padding_length = 0\n","2020-11-09 07:46:49,228 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 07:46:49,228 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 07:46:49,304 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 1\n","2020-11-09 07:46:49,304 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 07:46:49,304 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer\n","2020-11-09 07:46:49,304 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>']} and extras set()\n","2020-11-09 07:46:49,304 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base\n","2020-11-09 07:46:49,304 - INFO - allennlp.common.params - dataset_reader.tokenizer.do_lowercase = False\n","2020-11-09 07:46:49,305 - INFO - allennlp.common.params - dataset_reader.tokenizer.start_tokens = ['<s>']\n","2020-11-09 07:46:49,305 - INFO - allennlp.common.params - dataset_reader.tokenizer.end_tokens = ['</s>']\n","2020-11-09 07:46:50,072 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 07:46:50,072 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 07:46:50,145 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512\n","2020-11-09 07:46:50,145 - INFO - allennlp.common.params - dataset_reader.sample = None\n","2020-11-09 07:46:50,145 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False\n","2020-11-09 07:46:50,145 - INFO - allennlp.common.params - dataset_reader.lazy = False\n","2020-11-09 07:46:50,145 - INFO - allennlp.training.util - Using a separate dataset reader to load validation and test data.\n","2020-11-09 07:46:50,145 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}, 'type': 'text_classification_json_with_sampling'} and extras set()\n","2020-11-09 07:46:50,145 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling\n","2020-11-09 07:46:50,145 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.data.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}} and extras set()\n","2020-11-09 07:46:50,145 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 07:46:50,146 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.type = pretrained_transformer\n","2020-11-09 07:46:50,146 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base'} and extras set()\n","2020-11-09 07:46:50,146 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.model_name = roberta-base\n","2020-11-09 07:46:50,146 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.do_lowercase = False\n","2020-11-09 07:46:50,146 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.namespace = tags\n","2020-11-09 07:46:50,146 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.token_min_padding_length = 0\n","2020-11-09 07:46:50,896 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 07:46:50,896 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 07:46:50,971 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 1\n","2020-11-09 07:46:50,972 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 07:46:50,972 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer\n","2020-11-09 07:46:50,972 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>']} and extras set()\n","2020-11-09 07:46:50,972 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base\n","2020-11-09 07:46:50,972 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.do_lowercase = False\n","2020-11-09 07:46:50,972 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.start_tokens = ['<s>']\n","2020-11-09 07:46:50,972 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.end_tokens = ['</s>']\n","2020-11-09 07:46:51,707 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 07:46:51,707 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 07:46:51,778 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512\n","2020-11-09 07:46:51,778 - INFO - allennlp.common.params - validation_dataset_reader.sample = None\n","2020-11-09 07:46:51,779 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False\n","2020-11-09 07:46:51,779 - INFO - allennlp.common.params - validation_dataset_reader.lazy = False\n","2020-11-09 07:46:51,779 - INFO - allennlp.common.params - train_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/sciie/train.jsonl\n","2020-11-09 07:46:51,779 - INFO - allennlp.training.util - Reading training data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/sciie/train.jsonl\n","0it [00:00, ?it/s]2020-11-09 07:46:52,467 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/sciie/train.jsonl not found in cache, downloading to /tmp/tmpod0t8140\n","\n","  0%|          | 0/823836 [00:00<?, ?B/s]\u001b[A\n","  2%|2         | 17408/823836 [00:00<00:07, 108142.79B/s]\u001b[A\n","  6%|6         | 52224/823836 [00:00<00:06, 127106.38B/s]\u001b[A\n"," 13%|#2        | 104448/823836 [00:00<00:04, 155387.97B/s]\u001b[A\n"," 27%|##7       | 226304/823836 [00:00<00:02, 203938.86B/s]\u001b[A\n","100%|##########| 823836/823836 [00:00<00:00, 1013086.33B/s]\n","2020-11-09 07:46:54,016 - INFO - allennlp.common.file_utils - copying /tmp/tmpod0t8140 to cache at /root/.allennlp/cache/2261d610aac60b0fe2485e4f35b1e9bdbbd244f1ba915d1f130ca432d2521ecd.7b22669b59efacc47553e42401bf3731da72e1686da445c91b6523acfaaa8a88\n","2020-11-09 07:46:54,030 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/2261d610aac60b0fe2485e4f35b1e9bdbbd244f1ba915d1f130ca432d2521ecd.7b22669b59efacc47553e42401bf3731da72e1686da445c91b6523acfaaa8a88\n","2020-11-09 07:46:54,031 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmpod0t8140\n","3219it [00:03, 926.85it/s]\n","2020-11-09 07:46:55,252 - INFO - allennlp.common.params - validation_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/sciie/dev.jsonl\n","2020-11-09 07:46:55,253 - INFO - allennlp.training.util - Reading validation data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/sciie/dev.jsonl\n","0it [00:00, ?it/s]2020-11-09 07:46:55,942 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/sciie/dev.jsonl not found in cache, downloading to /tmp/tmpwbqjw5ju\n","\n","  0%|          | 0/118354 [00:00<?, ?B/s]\u001b[A\n","  1%|          | 1024/118354 [00:00<00:18, 6381.17B/s]\u001b[A\n"," 29%|##9       | 34816/118354 [00:00<00:09, 8998.38B/s]\u001b[A\n","100%|##########| 118354/118354 [00:00<00:00, 244542.71B/s]\n","2020-11-09 07:46:57,153 - INFO - allennlp.common.file_utils - copying /tmp/tmpwbqjw5ju to cache at /root/.allennlp/cache/cbeae1ceaffcab656f77b9c61bcc283886009c63f569b07dcafd15c07ca34e49.ed40b3b0d90bd7348490ba4e074e35b20a0faea43ed7aae7660e8acd2e41ef2b\n","2020-11-09 07:46:57,154 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/cbeae1ceaffcab656f77b9c61bcc283886009c63f569b07dcafd15c07ca34e49.ed40b3b0d90bd7348490ba4e074e35b20a0faea43ed7aae7660e8acd2e41ef2b\n","2020-11-09 07:46:57,154 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmpwbqjw5ju\n","455it [00:02, 220.14it/s]\n","2020-11-09 07:46:57,320 - INFO - allennlp.common.params - test_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/sciie/test.jsonl\n","2020-11-09 07:46:57,320 - INFO - allennlp.training.util - Reading test data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/sciie/test.jsonl\n","0it [00:00, ?it/s]2020-11-09 07:46:57,995 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/sciie/test.jsonl not found in cache, downloading to /tmp/tmptkmbsstl\n","\n","  0%|          | 0/249465 [00:00<?, ?B/s]\u001b[A\n","  7%|6         | 17408/249465 [00:00<00:02, 108636.60B/s]\u001b[A\n"," 21%|##        | 52224/249465 [00:00<00:01, 127649.64B/s]\u001b[A\n"," 42%|####1     | 104448/249465 [00:00<00:00, 156032.24B/s]\u001b[A\n","100%|##########| 249465/249465 [00:00<00:00, 387025.82B/s]\n","2020-11-09 07:46:59,370 - INFO - allennlp.common.file_utils - copying /tmp/tmptkmbsstl to cache at /root/.allennlp/cache/a0b3392225f54f389b6053d01a12643c9d3e3e2028a72b697b6fa5377ea5e98c.1c547a696f41a7e08a8a13da1d06fedff772189c1ca4edaa34771d63f2a6e7b1\n","2020-11-09 07:46:59,371 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/a0b3392225f54f389b6053d01a12643c9d3e3e2028a72b697b6fa5377ea5e98c.1c547a696f41a7e08a8a13da1d06fedff772189c1ca4edaa34771d63f2a6e7b1\n","2020-11-09 07:46:59,371 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmptkmbsstl\n","974it [00:02, 394.41it/s]\n","2020-11-09 07:46:59,807 - INFO - allennlp.training.trainer_pieces - From dataset instances, test, train, validation will be considered for vocabulary creation.\n","2020-11-09 07:46:59,808 - INFO - allennlp.common.params - vocabulary.type = None\n","2020-11-09 07:46:59,808 - INFO - allennlp.common.params - vocabulary.extend = False\n","2020-11-09 07:46:59,808 - INFO - allennlp.common.params - vocabulary.directory_path = None\n","2020-11-09 07:46:59,808 - INFO - allennlp.common.params - vocabulary.min_count = None\n","2020-11-09 07:46:59,808 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None\n","2020-11-09 07:46:59,808 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')\n","2020-11-09 07:46:59,808 - INFO - allennlp.common.params - vocabulary.pretrained_files = {}\n","2020-11-09 07:46:59,808 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None\n","2020-11-09 07:46:59,808 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False\n","2020-11-09 07:46:59,808 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None\n","2020-11-09 07:46:59,808 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n","4648it [00:00, 166639.24it/s]\n","2020-11-09 07:46:59,836 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'dropout': '0.1', 'feedforward_layer': {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1}, 'seq2vec_encoder': {'embedding_dim': 768, 'type': 'cls_pooler'}, 'text_field_embedder': {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'type': 'basic_classifier_with_f1'} and extras {'vocab'}\n","2020-11-09 07:46:59,837 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1\n","2020-11-09 07:46:59,837 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.models.basic_classifier_with_f1.BasicClassifierWithF1'> from params {'dropout': '0.1', 'feedforward_layer': {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1}, 'seq2vec_encoder': {'embedding_dim': 768, 'type': 'cls_pooler'}, 'text_field_embedder': {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}} and extras {'vocab'}\n","2020-11-09 07:46:59,837 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}} and extras {'vocab'}\n","2020-11-09 07:46:59,837 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n","2020-11-09 07:46:59,837 - INFO - allennlp.common.params - model.text_field_embedder.embedder_to_indexer_map = None\n","2020-11-09 07:46:59,837 - INFO - allennlp.common.params - model.text_field_embedder.allow_unmatched_keys = False\n","2020-11-09 07:46:59,837 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders = None\n","2020-11-09 07:46:59,837 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras {'vocab'}\n","2020-11-09 07:46:59,837 - INFO - allennlp.common.params - model.text_field_embedder.roberta.type = pretrained_transformer\n","2020-11-09 07:46:59,837 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.pretrained_transformer_embedder.PretrainedTransformerEmbedder'> from params {'model_name': 'roberta-base'} and extras {'vocab'}\n","2020-11-09 07:46:59,838 - INFO - allennlp.common.params - model.text_field_embedder.roberta.model_name = roberta-base\n","2020-11-09 07:47:00,224 - INFO - pytorch_transformers.modeling_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/pytorch_transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n","2020-11-09 07:47:00,224 - INFO - pytorch_transformers.modeling_utils - Model config {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 1,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","2020-11-09 07:47:00,645 - INFO - pytorch_transformers.modeling_utils - loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n","2020-11-09 07:47:04,857 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'embedding_dim': 768, 'type': 'cls_pooler'} and extras {'vocab'}\n","2020-11-09 07:47:04,857 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler\n","2020-11-09 07:47:04,857 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.modules.seq2vec_encoders.cls_pooler.CLSPooler'> from params {'embedding_dim': 768} and extras {'vocab'}\n","2020-11-09 07:47:04,857 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768\n","2020-11-09 07:47:04,857 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1} and extras {'vocab'}\n","2020-11-09 07:47:04,857 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768\n","2020-11-09 07:47:04,857 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1\n","2020-11-09 07:47:04,858 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768\n","2020-11-09 07:47:04,858 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh\n","2020-11-09 07:47:04,858 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0\n","2020-11-09 07:47:04,863 - INFO - allennlp.common.params - model.dropout = 0.1\n","2020-11-09 07:47:04,863 - INFO - allennlp.common.params - model.num_labels = None\n","2020-11-09 07:47:04,863 - INFO - allennlp.common.params - model.label_namespace = labels\n","2020-11-09 07:47:04,864 - INFO - allennlp.nn.initializers - Initializing parameters\n","2020-11-09 07:47:04,865 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n","2020-11-09 07:47:04,865 - INFO - allennlp.nn.initializers -    _classification_layer.bias\n","2020-11-09 07:47:04,865 - INFO - allennlp.nn.initializers -    _classification_layer.weight\n","2020-11-09 07:47:04,865 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias\n","2020-11-09 07:47:04,865 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight\n","2020-11-09 07:47:04,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias\n","2020-11-09 07:47:04,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight\n","2020-11-09 07:47:04,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight\n","2020-11-09 07:47:04,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight\n","2020-11-09 07:47:04,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight\n","2020-11-09 07:47:04,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n","2020-11-09 07:47:04,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n","2020-11-09 07:47:04,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias\n","2020-11-09 07:47:04,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight\n","2020-11-09 07:47:04,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias\n","2020-11-09 07:47:04,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight\n","2020-11-09 07:47:04,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias\n","2020-11-09 07:47:04,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight\n","2020-11-09 07:47:04,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias\n","2020-11-09 07:47:04,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight\n","2020-11-09 07:47:04,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias\n","2020-11-09 07:47:04,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight\n","2020-11-09 07:47:04,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias\n","2020-11-09 07:47:04,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight\n","2020-11-09 07:47:04,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias\n","2020-11-09 07:47:04,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight\n","2020-11-09 07:47:04,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n","2020-11-09 07:47:04,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n","2020-11-09 07:47:04,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias\n","2020-11-09 07:47:04,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight\n","2020-11-09 07:47:04,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight\n","2020-11-09 07:47:04,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight\n","2020-11-09 07:47:04,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight\n","2020-11-09 07:47:04,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n","2020-11-09 07:47:04,910 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n","2020-11-09 07:47:04,910 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias\n","2020-11-09 07:47:04,910 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight\n","2020-11-09 07:47:04,911 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias\n","2020-11-09 07:47:04,911 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight\n","2020-11-09 07:47:04,911 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias\n","2020-11-09 07:47:04,911 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight\n","2020-11-09 07:47:04,911 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias\n","2020-11-09 07:47:04,911 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight\n","2020-11-09 07:47:04,911 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias\n","2020-11-09 07:47:04,911 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight\n","2020-11-09 07:47:04,911 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias\n","2020-11-09 07:47:04,911 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight\n","2020-11-09 07:47:04,911 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias\n","2020-11-09 07:47:04,911 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight\n","2020-11-09 07:47:04,911 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n","2020-11-09 07:47:04,911 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n","2020-11-09 07:47:04,911 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias\n","2020-11-09 07:47:04,912 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight\n","2020-11-09 07:47:04,912 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias\n","2020-11-09 07:47:04,912 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight\n","2020-11-09 07:47:04,912 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias\n","2020-11-09 07:47:04,912 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight\n","2020-11-09 07:47:04,912 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias\n","2020-11-09 07:47:04,912 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight\n","2020-11-09 07:47:04,912 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias\n","2020-11-09 07:47:04,912 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight\n","2020-11-09 07:47:04,912 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias\n","2020-11-09 07:47:04,912 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight\n","2020-11-09 07:47:04,912 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias\n","2020-11-09 07:47:04,912 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight\n","2020-11-09 07:47:04,912 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n","2020-11-09 07:47:04,913 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n","2020-11-09 07:47:04,913 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias\n","2020-11-09 07:47:04,913 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight\n","2020-11-09 07:47:04,913 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias\n","2020-11-09 07:47:04,913 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight\n","2020-11-09 07:47:04,913 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias\n","2020-11-09 07:47:04,913 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight\n","2020-11-09 07:47:04,913 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias\n","2020-11-09 07:47:04,913 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight\n","2020-11-09 07:47:04,913 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias\n","2020-11-09 07:47:04,913 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight\n","2020-11-09 07:47:04,914 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias\n","2020-11-09 07:47:04,914 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight\n","2020-11-09 07:47:04,914 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias\n","2020-11-09 07:47:04,914 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight\n","2020-11-09 07:47:04,914 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n","2020-11-09 07:47:04,914 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n","2020-11-09 07:47:04,914 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias\n","2020-11-09 07:47:04,914 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight\n","2020-11-09 07:47:04,914 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias\n","2020-11-09 07:47:04,914 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight\n","2020-11-09 07:47:04,914 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias\n","2020-11-09 07:47:04,914 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight\n","2020-11-09 07:47:04,914 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias\n","2020-11-09 07:47:04,914 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight\n","2020-11-09 07:47:04,915 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias\n","2020-11-09 07:47:04,915 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight\n","2020-11-09 07:47:04,915 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias\n","2020-11-09 07:47:04,915 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight\n","2020-11-09 07:47:04,915 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias\n","2020-11-09 07:47:04,915 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight\n","2020-11-09 07:47:04,915 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n","2020-11-09 07:47:04,915 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n","2020-11-09 07:47:04,915 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias\n","2020-11-09 07:47:04,915 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight\n","2020-11-09 07:47:04,915 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias\n","2020-11-09 07:47:04,915 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight\n","2020-11-09 07:47:04,915 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias\n","2020-11-09 07:47:04,915 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight\n","2020-11-09 07:47:04,916 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias\n","2020-11-09 07:47:04,916 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight\n","2020-11-09 07:47:04,916 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias\n","2020-11-09 07:47:04,916 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight\n","2020-11-09 07:47:04,916 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias\n","2020-11-09 07:47:04,916 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight\n","2020-11-09 07:47:04,916 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias\n","2020-11-09 07:47:04,916 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight\n","2020-11-09 07:47:04,916 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n","2020-11-09 07:47:04,916 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n","2020-11-09 07:47:04,916 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias\n","2020-11-09 07:47:04,916 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight\n","2020-11-09 07:47:04,916 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias\n","2020-11-09 07:47:04,917 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight\n","2020-11-09 07:47:04,917 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias\n","2020-11-09 07:47:04,917 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight\n","2020-11-09 07:47:04,917 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias\n","2020-11-09 07:47:04,917 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight\n","2020-11-09 07:47:04,917 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias\n","2020-11-09 07:47:04,917 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight\n","2020-11-09 07:47:04,917 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias\n","2020-11-09 07:47:04,917 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight\n","2020-11-09 07:47:04,917 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias\n","2020-11-09 07:47:04,917 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight\n","2020-11-09 07:47:04,917 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias\n","2020-11-09 07:47:04,917 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight\n","2020-11-09 07:47:04,919 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 8, 'sorting_keys': [['tokens', 'num_tokens']], 'type': 'bucket'} and extras set()\n","2020-11-09 07:47:04,919 - INFO - allennlp.common.params - iterator.type = bucket\n","2020-11-09 07:47:04,919 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 8, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()\n","2020-11-09 07:47:04,920 - INFO - allennlp.common.params - iterator.sorting_keys = [['tokens', 'num_tokens']]\n","2020-11-09 07:47:04,920 - INFO - allennlp.common.params - iterator.padding_noise = 0.1\n","2020-11-09 07:47:04,920 - INFO - allennlp.common.params - iterator.biggest_batch_first = False\n","2020-11-09 07:47:04,920 - INFO - allennlp.common.params - iterator.batch_size = 8\n","2020-11-09 07:47:04,920 - INFO - allennlp.common.params - iterator.instances_per_epoch = None\n","2020-11-09 07:47:04,920 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None\n","2020-11-09 07:47:04,920 - INFO - allennlp.common.params - iterator.cache_instances = False\n","2020-11-09 07:47:04,920 - INFO - allennlp.common.params - iterator.track_epoch = False\n","2020-11-09 07:47:04,920 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None\n","2020-11-09 07:47:04,920 - INFO - allennlp.common.params - iterator.skip_smaller_batches = False\n","2020-11-09 07:47:04,920 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'sorting_keys': [['tokens', 'num_tokens']], 'type': 'bucket'} and extras set()\n","2020-11-09 07:47:04,920 - INFO - allennlp.common.params - validation_iterator.type = bucket\n","2020-11-09 07:47:04,920 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 64, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()\n","2020-11-09 07:47:04,920 - INFO - allennlp.common.params - validation_iterator.sorting_keys = [['tokens', 'num_tokens']]\n","2020-11-09 07:47:04,921 - INFO - allennlp.common.params - validation_iterator.padding_noise = 0.1\n","2020-11-09 07:47:04,921 - INFO - allennlp.common.params - validation_iterator.biggest_batch_first = False\n","2020-11-09 07:47:04,921 - INFO - allennlp.common.params - validation_iterator.batch_size = 64\n","2020-11-09 07:47:04,921 - INFO - allennlp.common.params - validation_iterator.instances_per_epoch = None\n","2020-11-09 07:47:04,921 - INFO - allennlp.common.params - validation_iterator.max_instances_in_memory = None\n","2020-11-09 07:47:04,921 - INFO - allennlp.common.params - validation_iterator.cache_instances = False\n","2020-11-09 07:47:04,921 - INFO - allennlp.common.params - validation_iterator.track_epoch = False\n","2020-11-09 07:47:04,921 - INFO - allennlp.common.params - validation_iterator.maximum_samples_per_batch = None\n","2020-11-09 07:47:04,921 - INFO - allennlp.common.params - validation_iterator.skip_smaller_batches = False\n","2020-11-09 07:47:04,921 - INFO - allennlp.common.params - trainer.no_grad = ()\n","2020-11-09 07:47:04,924 - INFO - allennlp.training.trainer_pieces - Following parameters are Frozen  (without gradient):\n","2020-11-09 07:47:04,924 - INFO - allennlp.training.trainer_pieces - Following parameters are Tunable (with gradient):\n","2020-11-09 07:47:04,924 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight\n","2020-11-09 07:47:04,924 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight\n","2020-11-09 07:47:04,924 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight\n","2020-11-09 07:47:04,924 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight\n","2020-11-09 07:47:04,924 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias\n","2020-11-09 07:47:04,924 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight\n","2020-11-09 07:47:04,924 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias\n","2020-11-09 07:47:04,924 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight\n","2020-11-09 07:47:04,924 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias\n","2020-11-09 07:47:04,924 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight\n","2020-11-09 07:47:04,924 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias\n","2020-11-09 07:47:04,924 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight\n","2020-11-09 07:47:04,924 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias\n","2020-11-09 07:47:04,924 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n","2020-11-09 07:47:04,924 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n","2020-11-09 07:47:04,924 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight\n","2020-11-09 07:47:04,924 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight\n","2020-11-09 07:47:04,925 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias\n","2020-11-09 07:47:04,926 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight\n","2020-11-09 07:47:04,926 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias\n","2020-11-09 07:47:04,926 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight\n","2020-11-09 07:47:04,926 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias\n","2020-11-09 07:47:04,926 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n","2020-11-09 07:47:04,926 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n","2020-11-09 07:47:04,926 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight\n","2020-11-09 07:47:04,926 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias\n","2020-11-09 07:47:04,926 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight\n","2020-11-09 07:47:04,926 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias\n","2020-11-09 07:47:04,926 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight\n","2020-11-09 07:47:04,926 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias\n","2020-11-09 07:47:04,926 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight\n","2020-11-09 07:47:04,926 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias\n","2020-11-09 07:47:04,926 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight\n","2020-11-09 07:47:04,926 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias\n","2020-11-09 07:47:04,926 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight\n","2020-11-09 07:47:04,926 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias\n","2020-11-09 07:47:04,926 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight\n","2020-11-09 07:47:04,926 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias\n","2020-11-09 07:47:04,926 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n","2020-11-09 07:47:04,926 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n","2020-11-09 07:47:04,926 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight\n","2020-11-09 07:47:04,927 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias\n","2020-11-09 07:47:04,927 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight\n","2020-11-09 07:47:04,927 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias\n","2020-11-09 07:47:04,927 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight\n","2020-11-09 07:47:04,927 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias\n","2020-11-09 07:47:04,927 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight\n","2020-11-09 07:47:04,927 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias\n","2020-11-09 07:47:04,927 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight\n","2020-11-09 07:47:04,927 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias\n","2020-11-09 07:47:04,927 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight\n","2020-11-09 07:47:04,927 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias\n","2020-11-09 07:47:05,018 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight\n","2020-11-09 07:47:05,018 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias\n","2020-11-09 07:47:05,019 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n","2020-11-09 07:47:05,019 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n","2020-11-09 07:47:05,019 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight\n","2020-11-09 07:47:05,019 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias\n","2020-11-09 07:47:05,019 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight\n","2020-11-09 07:47:05,019 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias\n","2020-11-09 07:47:05,019 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight\n","2020-11-09 07:47:05,019 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias\n","2020-11-09 07:47:05,019 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight\n","2020-11-09 07:47:05,019 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias\n","2020-11-09 07:47:05,019 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight\n","2020-11-09 07:47:05,019 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias\n","2020-11-09 07:47:05,019 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight\n","2020-11-09 07:47:05,019 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias\n","2020-11-09 07:47:05,019 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight\n","2020-11-09 07:47:05,019 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias\n","2020-11-09 07:47:05,020 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n","2020-11-09 07:47:05,020 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n","2020-11-09 07:47:05,020 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight\n","2020-11-09 07:47:05,020 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias\n","2020-11-09 07:47:05,020 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight\n","2020-11-09 07:47:05,020 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias\n","2020-11-09 07:47:05,020 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight\n","2020-11-09 07:47:05,020 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias\n","2020-11-09 07:47:05,020 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight\n","2020-11-09 07:47:05,020 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias\n","2020-11-09 07:47:05,020 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight\n","2020-11-09 07:47:05,020 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias\n","2020-11-09 07:47:05,020 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight\n","2020-11-09 07:47:05,020 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias\n","2020-11-09 07:47:05,020 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight\n","2020-11-09 07:47:05,020 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias\n","2020-11-09 07:47:05,021 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n","2020-11-09 07:47:05,021 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n","2020-11-09 07:47:05,021 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight\n","2020-11-09 07:47:05,021 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias\n","2020-11-09 07:47:05,021 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight\n","2020-11-09 07:47:05,021 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias\n","2020-11-09 07:47:05,021 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight\n","2020-11-09 07:47:05,021 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias\n","2020-11-09 07:47:05,021 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight\n","2020-11-09 07:47:05,021 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias\n","2020-11-09 07:47:05,021 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight\n","2020-11-09 07:47:05,021 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias\n","2020-11-09 07:47:05,021 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight\n","2020-11-09 07:47:05,021 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias\n","2020-11-09 07:47:05,021 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight\n","2020-11-09 07:47:05,021 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias\n","2020-11-09 07:47:05,021 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n","2020-11-09 07:47:05,022 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n","2020-11-09 07:47:05,022 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight\n","2020-11-09 07:47:05,022 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias\n","2020-11-09 07:47:05,022 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight\n","2020-11-09 07:47:05,022 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias\n","2020-11-09 07:47:05,022 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight\n","2020-11-09 07:47:05,022 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias\n","2020-11-09 07:47:05,022 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight\n","2020-11-09 07:47:05,022 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias\n","2020-11-09 07:47:05,022 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight\n","2020-11-09 07:47:05,022 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias\n","2020-11-09 07:47:05,022 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight\n","2020-11-09 07:47:05,022 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias\n","2020-11-09 07:47:05,022 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight\n","2020-11-09 07:47:05,022 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias\n","2020-11-09 07:47:05,022 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n","2020-11-09 07:47:05,023 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n","2020-11-09 07:47:05,023 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight\n","2020-11-09 07:47:05,023 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias\n","2020-11-09 07:47:05,023 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight\n","2020-11-09 07:47:05,023 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias\n","2020-11-09 07:47:05,023 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight\n","2020-11-09 07:47:05,023 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias\n","2020-11-09 07:47:05,023 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight\n","2020-11-09 07:47:05,023 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias\n","2020-11-09 07:47:05,023 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight\n","2020-11-09 07:47:05,023 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias\n","2020-11-09 07:47:05,023 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight\n","2020-11-09 07:47:05,023 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias\n","2020-11-09 07:47:05,023 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight\n","2020-11-09 07:47:05,024 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias\n","2020-11-09 07:47:05,024 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n","2020-11-09 07:47:05,024 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n","2020-11-09 07:47:05,024 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight\n","2020-11-09 07:47:05,024 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias\n","2020-11-09 07:47:05,024 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight\n","2020-11-09 07:47:05,024 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias\n","2020-11-09 07:47:05,024 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight\n","2020-11-09 07:47:05,024 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias\n","2020-11-09 07:47:05,024 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight\n","2020-11-09 07:47:05,024 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias\n","2020-11-09 07:47:05,024 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight\n","2020-11-09 07:47:05,024 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias\n","2020-11-09 07:47:05,024 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight\n","2020-11-09 07:47:05,024 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias\n","2020-11-09 07:47:05,025 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight\n","2020-11-09 07:47:05,025 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias\n","2020-11-09 07:47:05,025 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n","2020-11-09 07:47:05,025 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n","2020-11-09 07:47:05,025 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight\n","2020-11-09 07:47:05,025 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias\n","2020-11-09 07:47:05,025 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight\n","2020-11-09 07:47:05,025 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias\n","2020-11-09 07:47:05,025 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight\n","2020-11-09 07:47:05,025 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias\n","2020-11-09 07:47:05,025 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight\n","2020-11-09 07:47:05,025 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias\n","2020-11-09 07:47:05,025 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight\n","2020-11-09 07:47:05,025 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias\n","2020-11-09 07:47:05,025 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight\n","2020-11-09 07:47:05,025 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias\n","2020-11-09 07:47:05,025 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight\n","2020-11-09 07:47:05,026 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias\n","2020-11-09 07:47:05,026 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n","2020-11-09 07:47:05,026 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n","2020-11-09 07:47:05,026 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight\n","2020-11-09 07:47:05,026 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias\n","2020-11-09 07:47:05,026 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight\n","2020-11-09 07:47:05,026 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias\n","2020-11-09 07:47:05,026 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight\n","2020-11-09 07:47:05,026 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias\n","2020-11-09 07:47:05,026 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight\n","2020-11-09 07:47:05,026 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias\n","2020-11-09 07:47:05,026 - INFO - allennlp.training.trainer_pieces - _feedforward_layer._linear_layers.0.weight\n","2020-11-09 07:47:05,026 - INFO - allennlp.training.trainer_pieces - _feedforward_layer._linear_layers.0.bias\n","2020-11-09 07:47:05,026 - INFO - allennlp.training.trainer_pieces - _classification_layer.weight\n","2020-11-09 07:47:05,026 - INFO - allennlp.training.trainer_pieces - _classification_layer.bias\n","2020-11-09 07:47:05,027 - INFO - allennlp.common.params - trainer.patience = 3\n","2020-11-09 07:47:05,027 - INFO - allennlp.common.params - trainer.validation_metric = +f1\n","2020-11-09 07:47:05,027 - INFO - allennlp.common.params - trainer.shuffle = True\n","2020-11-09 07:47:05,027 - INFO - allennlp.common.params - trainer.num_epochs = 10\n","2020-11-09 07:47:05,027 - INFO - allennlp.common.params - trainer.cuda_device = 0\n","2020-11-09 07:47:05,027 - INFO - allennlp.common.params - trainer.grad_norm = None\n","2020-11-09 07:47:05,027 - INFO - allennlp.common.params - trainer.grad_clipping = None\n","2020-11-09 07:47:05,027 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None\n","2020-11-09 07:47:05,027 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n","2020-11-09 07:47:05,027 - INFO - allennlp.common.params - trainer.gradient_accumulation_batch_size = 8\n","2020-11-09 07:47:09,625 - INFO - allennlp.common.params - trainer.optimizer.type = bert_adam\n","2020-11-09 07:47:09,625 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n","2020-11-09 07:47:09,625 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n","2020-11-09 07:47:09,625 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups.0.1.weight_decay = 0\n","2020-11-09 07:47:09,626 - INFO - allennlp.training.optimizers - Done constructing parameter groups.\n","2020-11-09 07:47:09,626 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_feedforward_layer._linear_layers.0.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_classification_layer.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias'], {'weight_decay': 0}\n","2020-11-09 07:47:09,646 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight', '_feedforward_layer._linear_layers.0.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight', '_classification_layer.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight'], {}\n","2020-11-09 07:47:09,646 - WARNING - allennlp.training.optimizers - When constructing parameter groups,  layer_norm.weight not match any parameter name\n","2020-11-09 07:47:09,647 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125241607\n","2020-11-09 07:47:09,648 - INFO - allennlp.common.params - trainer.optimizer.infer_type_and_cast = True\n","2020-11-09 07:47:09,648 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n","2020-11-09 07:47:09,648 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n","2020-11-09 07:47:09,648 - INFO - allennlp.common.params - trainer.optimizer.b1 = 0.9\n","2020-11-09 07:47:09,648 - INFO - allennlp.common.params - trainer.optimizer.b2 = 0.98\n","2020-11-09 07:47:09,648 - INFO - allennlp.common.params - trainer.optimizer.e = 1e-06\n","2020-11-09 07:47:09,648 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05\n","2020-11-09 07:47:09,648 - INFO - allennlp.common.params - trainer.optimizer.max_grad_norm = 1\n","2020-11-09 07:47:09,648 - INFO - allennlp.common.params - trainer.optimizer.schedule = warmup_linear\n","2020-11-09 07:47:09,648 - INFO - allennlp.common.params - trainer.optimizer.t_total = -1\n","2020-11-09 07:47:09,648 - INFO - allennlp.common.params - trainer.optimizer.warmup = 0.06\n","2020-11-09 07:47:09,648 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1\n","2020-11-09 07:47:09,648 - WARNING - pytorch_pretrained_bert.optimization - t_total value of -1 results in schedule not being applied\n","2020-11-09 07:47:09,650 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 0\n","2020-11-09 07:47:09,650 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None\n","2020-11-09 07:47:09,650 - INFO - allennlp.common.params - trainer.model_save_interval = None\n","2020-11-09 07:47:09,650 - INFO - allennlp.common.params - trainer.summary_interval = 100\n","2020-11-09 07:47:09,650 - INFO - allennlp.common.params - trainer.histogram_interval = None\n","2020-11-09 07:47:09,650 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True\n","2020-11-09 07:47:09,650 - INFO - allennlp.common.params - trainer.should_log_learning_rate = False\n","2020-11-09 07:47:09,650 - INFO - allennlp.common.params - trainer.log_batch_size_period = None\n","2020-11-09 07:47:09,652 - INFO - allennlp.training.trainer - Beginning training.\n","2020-11-09 07:47:09,653 - INFO - allennlp.training.trainer - Epoch 0/9\n","2020-11-09 07:47:09,653 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4873.276\n","2020-11-09 07:47:09,759 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1769\n","2020-11-09 07:47:09,762 - INFO - allennlp.training.trainer - Training\n","  0%|          | 0/403 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","f1: 0.3282, accuracy: 0.6191, loss: 1.2038 ||: 100%|##########| 403/403 [01:00<00:00,  6.67it/s]\n","2020-11-09 07:48:10,197 - INFO - allennlp.training.trainer - Validating\n","f1: 0.5410, accuracy: 0.7495, loss: 0.7652 ||: 100%|##########| 8/8 [00:00<00:00, 15.87it/s]\n","2020-11-09 07:48:10,704 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 07:48:10,705 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4873.276  |       N/A\n","2020-11-09 07:48:10,705 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  1769.000  |       N/A\n","2020-11-09 07:48:10,706 - INFO - allennlp.training.tensorboard_writer - f1              |     0.328  |     0.541\n","2020-11-09 07:48:10,707 - INFO - allennlp.training.tensorboard_writer - loss            |     1.204  |     0.765\n","2020-11-09 07:48:10,708 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.619  |     0.749\n","2020-11-09 07:48:15,927 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/sciie_nas_01/best.th'.\n","2020-11-09 07:48:17,609 - INFO - allennlp.training.trainer - Epoch duration: 0:01:07.956110\n","2020-11-09 07:48:17,610 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:10:11\n","2020-11-09 07:48:17,610 - INFO - allennlp.training.trainer - Epoch 1/9\n","2020-11-09 07:48:17,610 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4886.872\n","2020-11-09 07:48:17,717 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 4539\n","2020-11-09 07:48:17,721 - INFO - allennlp.training.trainer - Training\n","f1: 0.7131, accuracy: 0.8357, loss: 0.5335 ||: 100%|##########| 403/403 [01:00<00:00,  6.67it/s]\n","2020-11-09 07:49:18,173 - INFO - allennlp.training.trainer - Validating\n","f1: 0.7953, accuracy: 0.8549, loss: 0.5292 ||: 100%|##########| 8/8 [00:00<00:00, 16.69it/s]\n","2020-11-09 07:49:18,655 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 07:49:18,655 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4886.872  |       N/A\n","2020-11-09 07:49:18,656 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  4539.000  |       N/A\n","2020-11-09 07:49:18,656 - INFO - allennlp.training.tensorboard_writer - f1              |     0.713  |     0.795\n","2020-11-09 07:49:18,657 - INFO - allennlp.training.tensorboard_writer - loss            |     0.534  |     0.529\n","2020-11-09 07:49:18,657 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.836  |     0.855\n","2020-11-09 07:49:23,697 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/sciie_nas_01/best.th'.\n","2020-11-09 07:49:25,681 - INFO - allennlp.training.trainer - Epoch duration: 0:01:08.070911\n","2020-11-09 07:49:25,682 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:09:04\n","2020-11-09 07:49:25,682 - INFO - allennlp.training.trainer - Epoch 2/9\n","2020-11-09 07:49:25,682 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4887.004\n","2020-11-09 07:49:25,787 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 4539\n","2020-11-09 07:49:25,790 - INFO - allennlp.training.trainer - Training\n","f1: 0.8406, accuracy: 0.8997, loss: 0.3231 ||: 100%|##########| 403/403 [01:00<00:00,  6.63it/s]\n","2020-11-09 07:50:26,611 - INFO - allennlp.training.trainer - Validating\n","f1: 0.8314, accuracy: 0.8813, loss: 0.4139 ||: 100%|##########| 8/8 [00:00<00:00, 16.75it/s]\n","2020-11-09 07:50:27,091 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 07:50:27,091 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4887.004  |       N/A\n","2020-11-09 07:50:27,092 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  4539.000  |       N/A\n","2020-11-09 07:50:27,092 - INFO - allennlp.training.tensorboard_writer - f1              |     0.841  |     0.831\n","2020-11-09 07:50:27,093 - INFO - allennlp.training.tensorboard_writer - loss            |     0.323  |     0.414\n","2020-11-09 07:50:27,094 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.900  |     0.881\n","2020-11-09 07:50:32,750 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/sciie_nas_01/best.th'.\n","2020-11-09 07:50:34,212 - INFO - allennlp.training.trainer - Epoch duration: 0:01:08.530718\n","2020-11-09 07:50:34,213 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:07:57\n","2020-11-09 07:50:34,213 - INFO - allennlp.training.trainer - Epoch 3/9\n","2020-11-09 07:50:34,213 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4887.012\n","2020-11-09 07:50:34,318 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 4539\n","2020-11-09 07:50:34,321 - INFO - allennlp.training.trainer - Training\n","f1: 0.9002, accuracy: 0.9372, loss: 0.2134 ||: 100%|##########| 403/403 [01:00<00:00,  6.70it/s]\n","2020-11-09 07:51:34,504 - INFO - allennlp.training.trainer - Validating\n","f1: 0.8412, accuracy: 0.8791, loss: 0.5019 ||: 100%|##########| 8/8 [00:00<00:00, 16.81it/s]\n","2020-11-09 07:51:34,983 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 07:51:34,983 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4887.012  |       N/A\n","2020-11-09 07:51:34,984 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  4539.000  |       N/A\n","2020-11-09 07:51:34,985 - INFO - allennlp.training.tensorboard_writer - f1              |     0.900  |     0.841\n","2020-11-09 07:51:34,985 - INFO - allennlp.training.tensorboard_writer - loss            |     0.213  |     0.502\n","2020-11-09 07:51:34,986 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.937  |     0.879\n","2020-11-09 07:51:40,513 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/sciie_nas_01/best.th'.\n","2020-11-09 07:51:42,179 - INFO - allennlp.training.trainer - Epoch duration: 0:01:07.966163\n","2020-11-09 07:51:42,179 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:06:48\n","2020-11-09 07:51:42,179 - INFO - allennlp.training.trainer - Epoch 4/9\n","2020-11-09 07:51:42,179 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4887.012\n","2020-11-09 07:51:42,284 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 4539\n","2020-11-09 07:51:42,287 - INFO - allennlp.training.trainer - Training\n","f1: 0.9465, accuracy: 0.9646, loss: 0.1299 ||: 100%|##########| 403/403 [01:00<00:00,  6.67it/s]\n","2020-11-09 07:52:42,692 - INFO - allennlp.training.trainer - Validating\n","f1: 0.8500, accuracy: 0.8857, loss: 0.5893 ||: 100%|##########| 8/8 [00:00<00:00, 16.68it/s]\n","2020-11-09 07:52:43,174 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 07:52:43,174 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4887.012  |       N/A\n","2020-11-09 07:52:43,175 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  4539.000  |       N/A\n","2020-11-09 07:52:43,175 - INFO - allennlp.training.tensorboard_writer - f1              |     0.947  |     0.850\n","2020-11-09 07:52:43,175 - INFO - allennlp.training.tensorboard_writer - loss            |     0.130  |     0.589\n","2020-11-09 07:52:43,176 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.965  |     0.886\n","2020-11-09 07:52:48,436 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/sciie_nas_01/best.th'.\n","2020-11-09 07:52:50,376 - INFO - allennlp.training.trainer - Epoch duration: 0:01:08.196392\n","2020-11-09 07:52:50,376 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:05:40\n","2020-11-09 07:52:50,376 - INFO - allennlp.training.trainer - Epoch 5/9\n","2020-11-09 07:52:50,376 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4887.012\n","2020-11-09 07:52:50,483 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 4539\n","2020-11-09 07:52:50,486 - INFO - allennlp.training.trainer - Training\n","f1: 0.9566, accuracy: 0.9720, loss: 0.1014 ||: 100%|##########| 403/403 [01:00<00:00,  6.62it/s]\n","2020-11-09 07:53:51,323 - INFO - allennlp.training.trainer - Validating\n","f1: 0.8482, accuracy: 0.8857, loss: 0.5071 ||: 100%|##########| 8/8 [00:00<00:00, 16.75it/s]\n","2020-11-09 07:53:51,804 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 07:53:51,804 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4887.012  |       N/A\n","2020-11-09 07:53:51,805 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  4539.000  |       N/A\n","2020-11-09 07:53:51,806 - INFO - allennlp.training.tensorboard_writer - f1              |     0.957  |     0.848\n","2020-11-09 07:53:51,806 - INFO - allennlp.training.tensorboard_writer - loss            |     0.101  |     0.507\n","2020-11-09 07:53:51,808 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.972  |     0.886\n","2020-11-09 07:53:56,920 - INFO - allennlp.training.trainer - Epoch duration: 0:01:06.543420\n","2020-11-09 07:53:56,920 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:04:31\n","2020-11-09 07:53:56,920 - INFO - allennlp.training.trainer - Epoch 6/9\n","2020-11-09 07:53:56,920 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4887.012\n","2020-11-09 07:53:57,028 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 4539\n","2020-11-09 07:53:57,031 - INFO - allennlp.training.trainer - Training\n","f1: 0.9664, accuracy: 0.9770, loss: 0.0776 ||: 100%|##########| 403/403 [01:00<00:00,  6.63it/s]\n","2020-11-09 07:54:57,846 - INFO - allennlp.training.trainer - Validating\n","f1: 0.8618, accuracy: 0.8901, loss: 0.5394 ||: 100%|##########| 8/8 [00:00<00:00, 16.71it/s]\n","2020-11-09 07:54:58,328 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 07:54:58,328 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4887.012  |       N/A\n","2020-11-09 07:54:58,329 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  4539.000  |       N/A\n","2020-11-09 07:54:58,329 - INFO - allennlp.training.tensorboard_writer - f1              |     0.966  |     0.862\n","2020-11-09 07:54:58,330 - INFO - allennlp.training.tensorboard_writer - loss            |     0.078  |     0.539\n","2020-11-09 07:54:58,331 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.977  |     0.890\n","2020-11-09 07:55:03,520 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/sciie_nas_01/best.th'.\n","2020-11-09 07:55:05,501 - INFO - allennlp.training.trainer - Epoch duration: 0:01:08.581127\n","2020-11-09 07:55:05,502 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:03:23\n","2020-11-09 07:55:05,502 - INFO - allennlp.training.trainer - Epoch 7/9\n","2020-11-09 07:55:05,502 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4887.012\n","2020-11-09 07:55:05,606 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 4539\n","2020-11-09 07:55:05,610 - INFO - allennlp.training.trainer - Training\n","f1: 0.9853, accuracy: 0.9901, loss: 0.0461 ||: 100%|##########| 403/403 [01:00<00:00,  6.66it/s]\n","2020-11-09 07:56:06,110 - INFO - allennlp.training.trainer - Validating\n","f1: 0.8441, accuracy: 0.8857, loss: 0.7489 ||: 100%|##########| 8/8 [00:00<00:00, 16.96it/s]\n","2020-11-09 07:56:06,584 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 07:56:06,585 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4887.012  |       N/A\n","2020-11-09 07:56:06,585 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  4539.000  |       N/A\n","2020-11-09 07:56:06,585 - INFO - allennlp.training.tensorboard_writer - f1              |     0.985  |     0.844\n","2020-11-09 07:56:06,587 - INFO - allennlp.training.tensorboard_writer - loss            |     0.046  |     0.749\n","2020-11-09 07:56:06,587 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.990  |     0.886\n","2020-11-09 07:56:12,109 - INFO - allennlp.training.trainer - Epoch duration: 0:01:06.607420\n","2020-11-09 07:56:12,110 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:02:15\n","2020-11-09 07:56:12,110 - INFO - allennlp.training.trainer - Epoch 8/9\n","2020-11-09 07:56:12,110 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4887.012\n","2020-11-09 07:56:12,217 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 4539\n","2020-11-09 07:56:12,221 - INFO - allennlp.training.trainer - Training\n","f1: 0.9742, accuracy: 0.9832, loss: 0.0629 ||: 100%|##########| 403/403 [01:00<00:00,  6.68it/s]\n","2020-11-09 07:57:12,592 - INFO - allennlp.training.trainer - Validating\n","f1: 0.8442, accuracy: 0.8857, loss: 0.5744 ||: 100%|##########| 8/8 [00:00<00:00, 16.85it/s]\n","2020-11-09 07:57:13,070 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 07:57:13,070 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4887.012  |       N/A\n","2020-11-09 07:57:13,070 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  4539.000  |       N/A\n","2020-11-09 07:57:13,071 - INFO - allennlp.training.tensorboard_writer - f1              |     0.974  |     0.844\n","2020-11-09 07:57:13,071 - INFO - allennlp.training.tensorboard_writer - loss            |     0.063  |     0.574\n","2020-11-09 07:57:13,072 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.983  |     0.886\n","2020-11-09 07:57:18,487 - INFO - allennlp.training.trainer - Epoch duration: 0:01:06.377302\n","2020-11-09 07:57:18,487 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:01:07\n","2020-11-09 07:57:18,487 - INFO - allennlp.training.trainer - Epoch 9/9\n","2020-11-09 07:57:18,487 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4887.012\n","2020-11-09 07:57:18,594 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 4539\n","2020-11-09 07:57:18,597 - INFO - allennlp.training.trainer - Training\n","f1: 0.9870, accuracy: 0.9901, loss: 0.0321 ||: 100%|##########| 403/403 [01:01<00:00,  6.58it/s]\n","2020-11-09 07:58:19,834 - INFO - allennlp.training.trainer - Validating\n","f1: 0.8292, accuracy: 0.8725, loss: 0.8158 ||: 100%|##########| 8/8 [00:00<00:00, 16.86it/s]\n","2020-11-09 07:58:20,311 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.\n","2020-11-09 07:58:20,312 - INFO - allennlp.training.checkpointer - loading best weights\n","2020-11-09 07:58:20,640 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.\n","2020-11-09 07:58:20,641 - INFO - allennlp.training.util - Iterating over dataset\n","f1: 0.81, accuracy: 0.87, loss: 0.61 ||: 100%|##########| 16/16 [00:01<00:00, 15.85it/s]\n","2020-11-09 07:58:21,652 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/sciie_nas_01/model.tar.gz\n","2020-11-09 07:58:49,750 - INFO - allennlp.common.util - Metrics: {\n","  \"best_epoch\": 6,\n","  \"peak_cpu_memory_MB\": 4887.012,\n","  \"peak_gpu_0_memory_MB\": 4539,\n","  \"training_duration\": \"0:10:03.419818\",\n","  \"training_start_epoch\": 0,\n","  \"training_epochs\": 8,\n","  \"epoch\": 8,\n","  \"training_f1\": 0.9741739460400173,\n","  \"training_accuracy\": 0.983224603914259,\n","  \"training_loss\": 0.06286272399287626,\n","  \"training_cpu_memory_MB\": 4887.012,\n","  \"training_gpu_0_memory_MB\": 4539,\n","  \"validation_f1\": 0.8441841517175946,\n","  \"validation_accuracy\": 0.8857142857142857,\n","  \"validation_loss\": 0.5744476616382599,\n","  \"best_validation_f1\": 0.8618384429386684,\n","  \"best_validation_accuracy\": 0.8901098901098901,\n","  \"best_validation_loss\": 0.5394229255616665,\n","  \"test_f1\": 0.8128701874188015,\n","  \"test_accuracy\": 0.8696098562628337,\n","  \"test_loss\": 0.6090700719505548\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XqqHfdWAqfmf","executionInfo":{"status":"ok","timestamp":1604930223799,"user_tz":300,"elapsed":44056809,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"de482e70-753f-4466-b0d2-b8f0c1d90c11","colab":{"base_uri":"https://localhost:8080/"}},"source":["!python -m scripts.train \\\n","        --config training_config/classifier.jsonnet \\\n","        --serialization_dir model_logs/ag_nas_01 \\\n","        --hyperparameters ROBERTA_CLASSIFIER_MINI \\\n","        --dataset ag \\\n","        --model roberta-base \\\n","        --device 0 \\\n","        --perf +f1 \\\n","        --evaluate_on_test"],"execution_count":20,"outputs":[{"output_type":"stream","text":["2020-11-09 07:58:53,648 - INFO - pytorch_pretrained_bert.modeling - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-09 07:58:54,116 - INFO - pytorch_transformers.modeling_bert - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-09 07:58:54,120 - INFO - pytorch_transformers.modeling_xlnet - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-09 07:58:54,599 - INFO - allennlp.common.params - random_seed = 845289\n","2020-11-09 07:58:54,599 - INFO - allennlp.common.params - numpy_seed = 845289\n","2020-11-09 07:58:54,599 - INFO - allennlp.common.params - pytorch_seed = 845289\n","2020-11-09 07:58:54,611 - INFO - allennlp.common.checks - Pytorch version: 1.7.0+cu101\n","2020-11-09 07:58:54,613 - INFO - allennlp.common.params - evaluate_on_test = True\n","2020-11-09 07:58:54,613 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}, 'type': 'text_classification_json_with_sampling'} and extras set()\n","2020-11-09 07:58:54,613 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling\n","2020-11-09 07:58:54,614 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.data.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}} and extras set()\n","2020-11-09 07:58:54,614 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 07:58:54,614 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.type = pretrained_transformer\n","2020-11-09 07:58:54,614 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base'} and extras set()\n","2020-11-09 07:58:54,614 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.model_name = roberta-base\n","2020-11-09 07:58:54,614 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.do_lowercase = False\n","2020-11-09 07:58:54,614 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.namespace = tags\n","2020-11-09 07:58:54,614 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.token_min_padding_length = 0\n","2020-11-09 07:58:55,358 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 07:58:55,358 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 07:58:55,436 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 1\n","2020-11-09 07:58:55,437 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 07:58:55,437 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer\n","2020-11-09 07:58:55,437 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>']} and extras set()\n","2020-11-09 07:58:55,437 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base\n","2020-11-09 07:58:55,437 - INFO - allennlp.common.params - dataset_reader.tokenizer.do_lowercase = False\n","2020-11-09 07:58:55,437 - INFO - allennlp.common.params - dataset_reader.tokenizer.start_tokens = ['<s>']\n","2020-11-09 07:58:55,437 - INFO - allennlp.common.params - dataset_reader.tokenizer.end_tokens = ['</s>']\n","2020-11-09 07:58:56,169 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 07:58:56,169 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 07:58:56,249 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512\n","2020-11-09 07:58:56,250 - INFO - allennlp.common.params - dataset_reader.sample = None\n","2020-11-09 07:58:56,250 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False\n","2020-11-09 07:58:56,250 - INFO - allennlp.common.params - dataset_reader.lazy = False\n","2020-11-09 07:58:56,250 - INFO - allennlp.training.util - Using a separate dataset reader to load validation and test data.\n","2020-11-09 07:58:56,250 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}, 'type': 'text_classification_json_with_sampling'} and extras set()\n","2020-11-09 07:58:56,250 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling\n","2020-11-09 07:58:56,250 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.data.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}} and extras set()\n","2020-11-09 07:58:56,251 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 07:58:56,251 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.type = pretrained_transformer\n","2020-11-09 07:58:56,251 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base'} and extras set()\n","2020-11-09 07:58:56,251 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.model_name = roberta-base\n","2020-11-09 07:58:56,251 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.do_lowercase = False\n","2020-11-09 07:58:56,251 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.namespace = tags\n","2020-11-09 07:58:56,251 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.token_min_padding_length = 0\n","2020-11-09 07:58:57,001 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 07:58:57,001 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 07:58:57,076 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 1\n","2020-11-09 07:58:57,077 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 07:58:57,077 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer\n","2020-11-09 07:58:57,077 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>']} and extras set()\n","2020-11-09 07:58:57,077 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base\n","2020-11-09 07:58:57,077 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.do_lowercase = False\n","2020-11-09 07:58:57,077 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.start_tokens = ['<s>']\n","2020-11-09 07:58:57,077 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.end_tokens = ['</s>']\n","2020-11-09 07:58:57,807 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 07:58:57,807 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 07:58:57,881 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512\n","2020-11-09 07:58:57,881 - INFO - allennlp.common.params - validation_dataset_reader.sample = None\n","2020-11-09 07:58:57,881 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False\n","2020-11-09 07:58:57,881 - INFO - allennlp.common.params - validation_dataset_reader.lazy = False\n","2020-11-09 07:58:57,881 - INFO - allennlp.common.params - train_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/ag/train.jsonl\n","2020-11-09 07:58:57,881 - INFO - allennlp.training.util - Reading training data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/ag/train.jsonl\n","0it [00:00, ?it/s]2020-11-09 07:58:58,586 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/ag/train.jsonl not found in cache, downloading to /tmp/tmpt8xohmkk\n","\n","  0%|          | 0/32899364 [00:00<?, ?B/s]\u001b[A\n","  0%|          | 17408/32899364 [00:00<04:58, 110227.62B/s]\u001b[A\n","  0%|          | 52224/32899364 [00:00<04:13, 129542.33B/s]\u001b[A\n","  0%|          | 104448/32899364 [00:00<03:27, 158304.52B/s]\u001b[A\n","  1%|          | 260096/32899364 [00:00<02:34, 211482.45B/s]\u001b[A\n","  2%|1         | 539648/32899364 [00:00<01:52, 287316.95B/s]\u001b[A\n","  3%|3         | 1096704/32899364 [00:00<01:20, 396509.52B/s]\u001b[A\n","  7%|6         | 2231296/32899364 [00:01<00:55, 553254.35B/s]\u001b[A\n"," 14%|#3        | 4492288/32899364 [00:01<00:36, 777400.57B/s]\u001b[A\n"," 21%|##        | 6786048/32899364 [00:01<00:24, 1085481.34B/s]\u001b[A\n"," 27%|##7       | 8965120/32899364 [00:01<00:15, 1499758.00B/s]\u001b[A\n"," 34%|###4      | 11226112/32899364 [00:01<00:10, 2049876.74B/s]\u001b[A\n"," 41%|####      | 13454336/32899364 [00:01<00:07, 2755583.13B/s]\u001b[A\n"," 48%|####7     | 15715328/32899364 [00:02<00:04, 3634819.81B/s]\u001b[A\n"," 54%|#####4    | 17894400/32899364 [00:02<00:03, 4662465.61B/s]\u001b[A\n"," 61%|######1   | 20139008/32899364 [00:02<00:02, 5834555.32B/s]\u001b[A\n"," 68%|######7   | 22285312/32899364 [00:02<00:01, 7032348.43B/s]\u001b[A\n"," 75%|#######4  | 24513536/32899364 [00:02<00:01, 8268906.15B/s]\u001b[A\n"," 81%|########1 | 26708992/32899364 [00:02<00:00, 9398317.88B/s]\u001b[A\n"," 88%|########7 | 28937216/32899364 [00:03<00:00, 10430103.68B/s]\u001b[A\n","100%|##########| 32899364/32899364 [00:03<00:00, 10283876.11B/s]\n","2020-11-09 07:59:02,521 - INFO - allennlp.common.file_utils - copying /tmp/tmpt8xohmkk to cache at /root/.allennlp/cache/721cad1b1efd89e04222742dacb6731f3c1ac1ba6a251162477f56e982d32234.32c4cf6b305c0890550c34a5a45d709983011ba012c413d7a2e00a3945bcc02f\n","2020-11-09 07:59:02,553 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/721cad1b1efd89e04222742dacb6731f3c1ac1ba6a251162477f56e982d32234.32c4cf6b305c0890550c34a5a45d709983011ba012c413d7a2e00a3945bcc02f\n","2020-11-09 07:59:02,554 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmpt8xohmkk\n","115000it [00:42, 2687.55it/s]\n","2020-11-09 07:59:40,672 - INFO - allennlp.common.params - validation_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/ag/dev.jsonl\n","2020-11-09 07:59:40,672 - INFO - allennlp.training.util - Reading validation data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/ag/dev.jsonl\n","0it [00:00, ?it/s]2020-11-09 07:59:41,381 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/ag/dev.jsonl not found in cache, downloading to /tmp/tmp15q8rg3g\n","\n","  0%|          | 0/1431278 [00:00<?, ?B/s]\u001b[A\n","  1%|1         | 16384/1431278 [00:00<00:13, 102404.52B/s]\u001b[A\n","  4%|3         | 51200/1431278 [00:00<00:11, 121667.68B/s]\u001b[A\n","  8%|8         | 120832/1431278 [00:00<00:08, 155149.89B/s]\u001b[A\n"," 18%|#8        | 260096/1431278 [00:00<00:05, 205839.97B/s]\u001b[A\n"," 38%|###7      | 538624/1431278 [00:00<00:03, 279834.79B/s]\u001b[A\n","100%|##########| 1431278/1431278 [00:00<00:00, 1480411.46B/s]\n","2020-11-09 07:59:43,066 - INFO - allennlp.common.file_utils - copying /tmp/tmp15q8rg3g to cache at /root/.allennlp/cache/c23ab1f99d079dfddfc5ab71c7544f6fe871990f2c1aaa0a52e4b97bcf39903d.736e97026ef76f199d0dcabacfb3d2f6b7754736a9ab57f8494d4a695f470f27\n","2020-11-09 07:59:43,068 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/c23ab1f99d079dfddfc5ab71c7544f6fe871990f2c1aaa0a52e4b97bcf39903d.736e97026ef76f199d0dcabacfb3d2f6b7754736a9ab57f8494d4a695f470f27\n","2020-11-09 07:59:43,068 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmp15q8rg3g\n","5000it [00:04, 1127.92it/s]\n","2020-11-09 07:59:45,105 - INFO - allennlp.common.params - test_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/ag/test.jsonl\n","2020-11-09 07:59:45,106 - INFO - allennlp.training.util - Reading test data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/ag/test.jsonl\n","0it [00:00, ?it/s]2020-11-09 07:59:45,802 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/ag/test.jsonl not found in cache, downloading to /tmp/tmp034bt215\n","\n","  0%|          | 0/2002793 [00:00<?, ?B/s]\u001b[A\n","  1%|          | 17408/2002793 [00:00<00:18, 109806.23B/s]\u001b[A\n","  3%|2         | 52224/2002793 [00:00<00:15, 129064.50B/s]\u001b[A\n","  5%|5         | 104448/2002793 [00:00<00:12, 157761.03B/s]\u001b[A\n"," 10%|#         | 208896/2002793 [00:00<00:08, 204312.67B/s]\u001b[A\n"," 23%|##3       | 470016/2002793 [00:00<00:05, 277066.63B/s]\u001b[A\n"," 48%|####7     | 957440/2002793 [00:00<00:02, 381011.65B/s]\u001b[A\n","100%|##########| 2002793/2002793 [00:01<00:00, 1794803.83B/s]\n","2020-11-09 07:59:47,624 - INFO - allennlp.common.file_utils - copying /tmp/tmp034bt215 to cache at /root/.allennlp/cache/ac9c9754adaa1a761b584e8a143de1ed17863ea3d59e969c182bd3106806193d.7bbc2ff499f971e735e72eb9e790b0ed1a75245472e52e51cc4856a6b35b8d34\n","2020-11-09 07:59:47,626 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/ac9c9754adaa1a761b584e8a143de1ed17863ea3d59e969c182bd3106806193d.7bbc2ff499f971e735e72eb9e790b0ed1a75245472e52e51cc4856a6b35b8d34\n","2020-11-09 07:59:47,626 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmp034bt215\n","7600it [00:04, 1559.17it/s]\n","2020-11-09 07:59:50,202 - INFO - allennlp.training.trainer_pieces - From dataset instances, validation, test, train will be considered for vocabulary creation.\n","2020-11-09 07:59:50,202 - INFO - allennlp.common.params - vocabulary.type = None\n","2020-11-09 07:59:50,202 - INFO - allennlp.common.params - vocabulary.extend = False\n","2020-11-09 07:59:50,202 - INFO - allennlp.common.params - vocabulary.directory_path = None\n","2020-11-09 07:59:50,202 - INFO - allennlp.common.params - vocabulary.min_count = None\n","2020-11-09 07:59:50,202 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None\n","2020-11-09 07:59:50,202 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')\n","2020-11-09 07:59:50,202 - INFO - allennlp.common.params - vocabulary.pretrained_files = {}\n","2020-11-09 07:59:50,202 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None\n","2020-11-09 07:59:50,202 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False\n","2020-11-09 07:59:50,203 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None\n","2020-11-09 07:59:50,203 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n","127600it [00:00, 159559.12it/s]\n","2020-11-09 07:59:51,003 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'dropout': '0.1', 'feedforward_layer': {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1}, 'seq2vec_encoder': {'embedding_dim': 768, 'type': 'cls_pooler'}, 'text_field_embedder': {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'type': 'basic_classifier_with_f1'} and extras {'vocab'}\n","2020-11-09 07:59:51,003 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1\n","2020-11-09 07:59:51,003 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.models.basic_classifier_with_f1.BasicClassifierWithF1'> from params {'dropout': '0.1', 'feedforward_layer': {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1}, 'seq2vec_encoder': {'embedding_dim': 768, 'type': 'cls_pooler'}, 'text_field_embedder': {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}} and extras {'vocab'}\n","2020-11-09 07:59:51,004 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}} and extras {'vocab'}\n","2020-11-09 07:59:51,004 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n","2020-11-09 07:59:51,004 - INFO - allennlp.common.params - model.text_field_embedder.embedder_to_indexer_map = None\n","2020-11-09 07:59:51,004 - INFO - allennlp.common.params - model.text_field_embedder.allow_unmatched_keys = False\n","2020-11-09 07:59:51,004 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders = None\n","2020-11-09 07:59:51,004 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras {'vocab'}\n","2020-11-09 07:59:51,004 - INFO - allennlp.common.params - model.text_field_embedder.roberta.type = pretrained_transformer\n","2020-11-09 07:59:51,004 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.pretrained_transformer_embedder.PretrainedTransformerEmbedder'> from params {'model_name': 'roberta-base'} and extras {'vocab'}\n","2020-11-09 07:59:51,004 - INFO - allennlp.common.params - model.text_field_embedder.roberta.model_name = roberta-base\n","2020-11-09 07:59:51,379 - INFO - pytorch_transformers.modeling_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/pytorch_transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n","2020-11-09 07:59:51,379 - INFO - pytorch_transformers.modeling_utils - Model config {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 1,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","2020-11-09 07:59:51,750 - INFO - pytorch_transformers.modeling_utils - loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n","2020-11-09 07:59:56,153 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'embedding_dim': 768, 'type': 'cls_pooler'} and extras {'vocab'}\n","2020-11-09 07:59:56,153 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler\n","2020-11-09 07:59:56,153 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.modules.seq2vec_encoders.cls_pooler.CLSPooler'> from params {'embedding_dim': 768} and extras {'vocab'}\n","2020-11-09 07:59:56,154 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768\n","2020-11-09 07:59:56,154 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1} and extras {'vocab'}\n","2020-11-09 07:59:56,154 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768\n","2020-11-09 07:59:56,154 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1\n","2020-11-09 07:59:56,154 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768\n","2020-11-09 07:59:56,155 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh\n","2020-11-09 07:59:56,155 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0\n","2020-11-09 07:59:56,160 - INFO - allennlp.common.params - model.dropout = 0.1\n","2020-11-09 07:59:56,160 - INFO - allennlp.common.params - model.num_labels = None\n","2020-11-09 07:59:56,160 - INFO - allennlp.common.params - model.label_namespace = labels\n","2020-11-09 07:59:56,161 - INFO - allennlp.nn.initializers - Initializing parameters\n","2020-11-09 07:59:56,162 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n","2020-11-09 07:59:56,163 - INFO - allennlp.nn.initializers -    _classification_layer.bias\n","2020-11-09 07:59:56,163 - INFO - allennlp.nn.initializers -    _classification_layer.weight\n","2020-11-09 07:59:56,163 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias\n","2020-11-09 07:59:56,163 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight\n","2020-11-09 07:59:56,163 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias\n","2020-11-09 07:59:56,163 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight\n","2020-11-09 07:59:56,163 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight\n","2020-11-09 07:59:56,163 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight\n","2020-11-09 07:59:56,163 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight\n","2020-11-09 07:59:56,163 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,163 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,163 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias\n","2020-11-09 07:59:56,163 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight\n","2020-11-09 07:59:56,163 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias\n","2020-11-09 07:59:56,163 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight\n","2020-11-09 07:59:56,163 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias\n","2020-11-09 07:59:56,163 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight\n","2020-11-09 07:59:56,163 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias\n","2020-11-09 07:59:56,163 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight\n","2020-11-09 07:59:56,163 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias\n","2020-11-09 07:59:56,163 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight\n","2020-11-09 07:59:56,163 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias\n","2020-11-09 07:59:56,164 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight\n","2020-11-09 07:59:56,165 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias\n","2020-11-09 07:59:56,165 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight\n","2020-11-09 07:59:56,165 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias\n","2020-11-09 07:59:56,165 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight\n","2020-11-09 07:59:56,165 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias\n","2020-11-09 07:59:56,165 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight\n","2020-11-09 07:59:56,165 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias\n","2020-11-09 07:59:56,165 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight\n","2020-11-09 07:59:56,165 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias\n","2020-11-09 07:59:56,165 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight\n","2020-11-09 07:59:56,165 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,165 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,165 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias\n","2020-11-09 07:59:56,165 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight\n","2020-11-09 07:59:56,165 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias\n","2020-11-09 07:59:56,165 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight\n","2020-11-09 07:59:56,165 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias\n","2020-11-09 07:59:56,165 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight\n","2020-11-09 07:59:56,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias\n","2020-11-09 07:59:56,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight\n","2020-11-09 07:59:56,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias\n","2020-11-09 07:59:56,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight\n","2020-11-09 07:59:56,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias\n","2020-11-09 07:59:56,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight\n","2020-11-09 07:59:56,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias\n","2020-11-09 07:59:56,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight\n","2020-11-09 07:59:56,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias\n","2020-11-09 07:59:56,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight\n","2020-11-09 07:59:56,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias\n","2020-11-09 07:59:56,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight\n","2020-11-09 07:59:56,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias\n","2020-11-09 07:59:56,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight\n","2020-11-09 07:59:56,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias\n","2020-11-09 07:59:56,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight\n","2020-11-09 07:59:56,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias\n","2020-11-09 07:59:56,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight\n","2020-11-09 07:59:56,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias\n","2020-11-09 07:59:56,166 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight\n","2020-11-09 07:59:56,167 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias\n","2020-11-09 07:59:56,167 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight\n","2020-11-09 07:59:56,167 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,167 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,167 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias\n","2020-11-09 07:59:56,167 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight\n","2020-11-09 07:59:56,167 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias\n","2020-11-09 07:59:56,167 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight\n","2020-11-09 07:59:56,167 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias\n","2020-11-09 07:59:56,167 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight\n","2020-11-09 07:59:56,167 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias\n","2020-11-09 07:59:56,167 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight\n","2020-11-09 07:59:56,167 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias\n","2020-11-09 07:59:56,167 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight\n","2020-11-09 07:59:56,167 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias\n","2020-11-09 07:59:56,167 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight\n","2020-11-09 07:59:56,167 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias\n","2020-11-09 07:59:56,167 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight\n","2020-11-09 07:59:56,167 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,222 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,223 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias\n","2020-11-09 07:59:56,223 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight\n","2020-11-09 07:59:56,223 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias\n","2020-11-09 07:59:56,223 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight\n","2020-11-09 07:59:56,223 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias\n","2020-11-09 07:59:56,223 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight\n","2020-11-09 07:59:56,223 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias\n","2020-11-09 07:59:56,223 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight\n","2020-11-09 07:59:56,223 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias\n","2020-11-09 07:59:56,223 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight\n","2020-11-09 07:59:56,223 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias\n","2020-11-09 07:59:56,223 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight\n","2020-11-09 07:59:56,224 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias\n","2020-11-09 07:59:56,224 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight\n","2020-11-09 07:59:56,224 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,224 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,224 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias\n","2020-11-09 07:59:56,224 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight\n","2020-11-09 07:59:56,224 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias\n","2020-11-09 07:59:56,224 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight\n","2020-11-09 07:59:56,224 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias\n","2020-11-09 07:59:56,224 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight\n","2020-11-09 07:59:56,224 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias\n","2020-11-09 07:59:56,224 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight\n","2020-11-09 07:59:56,224 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias\n","2020-11-09 07:59:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight\n","2020-11-09 07:59:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias\n","2020-11-09 07:59:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight\n","2020-11-09 07:59:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias\n","2020-11-09 07:59:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight\n","2020-11-09 07:59:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias\n","2020-11-09 07:59:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight\n","2020-11-09 07:59:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias\n","2020-11-09 07:59:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight\n","2020-11-09 07:59:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias\n","2020-11-09 07:59:56,225 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight\n","2020-11-09 07:59:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias\n","2020-11-09 07:59:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight\n","2020-11-09 07:59:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias\n","2020-11-09 07:59:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight\n","2020-11-09 07:59:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias\n","2020-11-09 07:59:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight\n","2020-11-09 07:59:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias\n","2020-11-09 07:59:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight\n","2020-11-09 07:59:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias\n","2020-11-09 07:59:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight\n","2020-11-09 07:59:56,226 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias\n","2020-11-09 07:59:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight\n","2020-11-09 07:59:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias\n","2020-11-09 07:59:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight\n","2020-11-09 07:59:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias\n","2020-11-09 07:59:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight\n","2020-11-09 07:59:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias\n","2020-11-09 07:59:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight\n","2020-11-09 07:59:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias\n","2020-11-09 07:59:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight\n","2020-11-09 07:59:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias\n","2020-11-09 07:59:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight\n","2020-11-09 07:59:56,227 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias\n","2020-11-09 07:59:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight\n","2020-11-09 07:59:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias\n","2020-11-09 07:59:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight\n","2020-11-09 07:59:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias\n","2020-11-09 07:59:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight\n","2020-11-09 07:59:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias\n","2020-11-09 07:59:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight\n","2020-11-09 07:59:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias\n","2020-11-09 07:59:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight\n","2020-11-09 07:59:56,228 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias\n","2020-11-09 07:59:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight\n","2020-11-09 07:59:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias\n","2020-11-09 07:59:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight\n","2020-11-09 07:59:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias\n","2020-11-09 07:59:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight\n","2020-11-09 07:59:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias\n","2020-11-09 07:59:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight\n","2020-11-09 07:59:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias\n","2020-11-09 07:59:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight\n","2020-11-09 07:59:56,229 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias\n","2020-11-09 07:59:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight\n","2020-11-09 07:59:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias\n","2020-11-09 07:59:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight\n","2020-11-09 07:59:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias\n","2020-11-09 07:59:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight\n","2020-11-09 07:59:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias\n","2020-11-09 07:59:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight\n","2020-11-09 07:59:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias\n","2020-11-09 07:59:56,230 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight\n","2020-11-09 07:59:56,232 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 8, 'sorting_keys': [['tokens', 'num_tokens']], 'type': 'bucket'} and extras set()\n","2020-11-09 07:59:56,232 - INFO - allennlp.common.params - iterator.type = bucket\n","2020-11-09 07:59:56,232 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 8, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()\n","2020-11-09 07:59:56,232 - INFO - allennlp.common.params - iterator.sorting_keys = [['tokens', 'num_tokens']]\n","2020-11-09 07:59:56,232 - INFO - allennlp.common.params - iterator.padding_noise = 0.1\n","2020-11-09 07:59:56,232 - INFO - allennlp.common.params - iterator.biggest_batch_first = False\n","2020-11-09 07:59:56,232 - INFO - allennlp.common.params - iterator.batch_size = 8\n","2020-11-09 07:59:56,232 - INFO - allennlp.common.params - iterator.instances_per_epoch = None\n","2020-11-09 07:59:56,232 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None\n","2020-11-09 07:59:56,233 - INFO - allennlp.common.params - iterator.cache_instances = False\n","2020-11-09 07:59:56,233 - INFO - allennlp.common.params - iterator.track_epoch = False\n","2020-11-09 07:59:56,233 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None\n","2020-11-09 07:59:56,233 - INFO - allennlp.common.params - iterator.skip_smaller_batches = False\n","2020-11-09 07:59:56,233 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'sorting_keys': [['tokens', 'num_tokens']], 'type': 'bucket'} and extras set()\n","2020-11-09 07:59:56,233 - INFO - allennlp.common.params - validation_iterator.type = bucket\n","2020-11-09 07:59:56,233 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 64, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()\n","2020-11-09 07:59:56,233 - INFO - allennlp.common.params - validation_iterator.sorting_keys = [['tokens', 'num_tokens']]\n","2020-11-09 07:59:56,233 - INFO - allennlp.common.params - validation_iterator.padding_noise = 0.1\n","2020-11-09 07:59:56,233 - INFO - allennlp.common.params - validation_iterator.biggest_batch_first = False\n","2020-11-09 07:59:56,233 - INFO - allennlp.common.params - validation_iterator.batch_size = 64\n","2020-11-09 07:59:56,233 - INFO - allennlp.common.params - validation_iterator.instances_per_epoch = None\n","2020-11-09 07:59:56,233 - INFO - allennlp.common.params - validation_iterator.max_instances_in_memory = None\n","2020-11-09 07:59:56,233 - INFO - allennlp.common.params - validation_iterator.cache_instances = False\n","2020-11-09 07:59:56,234 - INFO - allennlp.common.params - validation_iterator.track_epoch = False\n","2020-11-09 07:59:56,234 - INFO - allennlp.common.params - validation_iterator.maximum_samples_per_batch = None\n","2020-11-09 07:59:56,234 - INFO - allennlp.common.params - validation_iterator.skip_smaller_batches = False\n","2020-11-09 07:59:56,234 - INFO - allennlp.common.params - trainer.no_grad = ()\n","2020-11-09 07:59:56,236 - INFO - allennlp.training.trainer_pieces - Following parameters are Frozen  (without gradient):\n","2020-11-09 07:59:56,236 - INFO - allennlp.training.trainer_pieces - Following parameters are Tunable (with gradient):\n","2020-11-09 07:59:56,237 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight\n","2020-11-09 07:59:56,237 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight\n","2020-11-09 07:59:56,237 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight\n","2020-11-09 07:59:56,237 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight\n","2020-11-09 07:59:56,237 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias\n","2020-11-09 07:59:56,237 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight\n","2020-11-09 07:59:56,237 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias\n","2020-11-09 07:59:56,237 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight\n","2020-11-09 07:59:56,237 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias\n","2020-11-09 07:59:56,237 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight\n","2020-11-09 07:59:56,237 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias\n","2020-11-09 07:59:56,237 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight\n","2020-11-09 07:59:56,237 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias\n","2020-11-09 07:59:56,237 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,237 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,237 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight\n","2020-11-09 07:59:56,237 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias\n","2020-11-09 07:59:56,237 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight\n","2020-11-09 07:59:56,237 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias\n","2020-11-09 07:59:56,237 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight\n","2020-11-09 07:59:56,237 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias\n","2020-11-09 07:59:56,237 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight\n","2020-11-09 07:59:56,237 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias\n","2020-11-09 07:59:56,238 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight\n","2020-11-09 07:59:56,239 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias\n","2020-11-09 07:59:56,332 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight\n","2020-11-09 07:59:56,332 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias\n","2020-11-09 07:59:56,332 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,332 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,332 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight\n","2020-11-09 07:59:56,332 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias\n","2020-11-09 07:59:56,332 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight\n","2020-11-09 07:59:56,332 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias\n","2020-11-09 07:59:56,332 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight\n","2020-11-09 07:59:56,332 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias\n","2020-11-09 07:59:56,332 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight\n","2020-11-09 07:59:56,332 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias\n","2020-11-09 07:59:56,333 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight\n","2020-11-09 07:59:56,333 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias\n","2020-11-09 07:59:56,333 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight\n","2020-11-09 07:59:56,333 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias\n","2020-11-09 07:59:56,333 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight\n","2020-11-09 07:59:56,333 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias\n","2020-11-09 07:59:56,333 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,333 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,333 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight\n","2020-11-09 07:59:56,333 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias\n","2020-11-09 07:59:56,333 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight\n","2020-11-09 07:59:56,333 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias\n","2020-11-09 07:59:56,333 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight\n","2020-11-09 07:59:56,334 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias\n","2020-11-09 07:59:56,334 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight\n","2020-11-09 07:59:56,334 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias\n","2020-11-09 07:59:56,334 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight\n","2020-11-09 07:59:56,334 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias\n","2020-11-09 07:59:56,334 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight\n","2020-11-09 07:59:56,334 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias\n","2020-11-09 07:59:56,334 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight\n","2020-11-09 07:59:56,334 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias\n","2020-11-09 07:59:56,334 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,334 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,334 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight\n","2020-11-09 07:59:56,334 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias\n","2020-11-09 07:59:56,334 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight\n","2020-11-09 07:59:56,335 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias\n","2020-11-09 07:59:56,335 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight\n","2020-11-09 07:59:56,335 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias\n","2020-11-09 07:59:56,335 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight\n","2020-11-09 07:59:56,335 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias\n","2020-11-09 07:59:56,335 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight\n","2020-11-09 07:59:56,335 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias\n","2020-11-09 07:59:56,335 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight\n","2020-11-09 07:59:56,335 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias\n","2020-11-09 07:59:56,335 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight\n","2020-11-09 07:59:56,335 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias\n","2020-11-09 07:59:56,335 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,335 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,335 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight\n","2020-11-09 07:59:56,336 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias\n","2020-11-09 07:59:56,336 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight\n","2020-11-09 07:59:56,336 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias\n","2020-11-09 07:59:56,336 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight\n","2020-11-09 07:59:56,336 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias\n","2020-11-09 07:59:56,336 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight\n","2020-11-09 07:59:56,336 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias\n","2020-11-09 07:59:56,336 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight\n","2020-11-09 07:59:56,336 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias\n","2020-11-09 07:59:56,336 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight\n","2020-11-09 07:59:56,336 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias\n","2020-11-09 07:59:56,336 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight\n","2020-11-09 07:59:56,337 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias\n","2020-11-09 07:59:56,337 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,337 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,337 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight\n","2020-11-09 07:59:56,337 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias\n","2020-11-09 07:59:56,337 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight\n","2020-11-09 07:59:56,337 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias\n","2020-11-09 07:59:56,337 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight\n","2020-11-09 07:59:56,337 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias\n","2020-11-09 07:59:56,337 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight\n","2020-11-09 07:59:56,337 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias\n","2020-11-09 07:59:56,337 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight\n","2020-11-09 07:59:56,337 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias\n","2020-11-09 07:59:56,338 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight\n","2020-11-09 07:59:56,338 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias\n","2020-11-09 07:59:56,338 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight\n","2020-11-09 07:59:56,338 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias\n","2020-11-09 07:59:56,338 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,338 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,338 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight\n","2020-11-09 07:59:56,338 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias\n","2020-11-09 07:59:56,338 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight\n","2020-11-09 07:59:56,338 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias\n","2020-11-09 07:59:56,338 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight\n","2020-11-09 07:59:56,338 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias\n","2020-11-09 07:59:56,338 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight\n","2020-11-09 07:59:56,339 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias\n","2020-11-09 07:59:56,339 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight\n","2020-11-09 07:59:56,339 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias\n","2020-11-09 07:59:56,339 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight\n","2020-11-09 07:59:56,339 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias\n","2020-11-09 07:59:56,339 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight\n","2020-11-09 07:59:56,339 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias\n","2020-11-09 07:59:56,339 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,339 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,339 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight\n","2020-11-09 07:59:56,339 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias\n","2020-11-09 07:59:56,339 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight\n","2020-11-09 07:59:56,339 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias\n","2020-11-09 07:59:56,340 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight\n","2020-11-09 07:59:56,340 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias\n","2020-11-09 07:59:56,340 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight\n","2020-11-09 07:59:56,340 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias\n","2020-11-09 07:59:56,340 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight\n","2020-11-09 07:59:56,340 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias\n","2020-11-09 07:59:56,340 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight\n","2020-11-09 07:59:56,340 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias\n","2020-11-09 07:59:56,340 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight\n","2020-11-09 07:59:56,340 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias\n","2020-11-09 07:59:56,340 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n","2020-11-09 07:59:56,340 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n","2020-11-09 07:59:56,340 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight\n","2020-11-09 07:59:56,341 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias\n","2020-11-09 07:59:56,341 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight\n","2020-11-09 07:59:56,341 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias\n","2020-11-09 07:59:56,341 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight\n","2020-11-09 07:59:56,341 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias\n","2020-11-09 07:59:56,341 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight\n","2020-11-09 07:59:56,341 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias\n","2020-11-09 07:59:56,341 - INFO - allennlp.training.trainer_pieces - _feedforward_layer._linear_layers.0.weight\n","2020-11-09 07:59:56,341 - INFO - allennlp.training.trainer_pieces - _feedforward_layer._linear_layers.0.bias\n","2020-11-09 07:59:56,341 - INFO - allennlp.training.trainer_pieces - _classification_layer.weight\n","2020-11-09 07:59:56,341 - INFO - allennlp.training.trainer_pieces - _classification_layer.bias\n","2020-11-09 07:59:56,341 - INFO - allennlp.common.params - trainer.patience = 3\n","2020-11-09 07:59:56,342 - INFO - allennlp.common.params - trainer.validation_metric = +f1\n","2020-11-09 07:59:56,342 - INFO - allennlp.common.params - trainer.shuffle = True\n","2020-11-09 07:59:56,342 - INFO - allennlp.common.params - trainer.num_epochs = 10\n","2020-11-09 07:59:56,342 - INFO - allennlp.common.params - trainer.cuda_device = 0\n","2020-11-09 07:59:56,342 - INFO - allennlp.common.params - trainer.grad_norm = None\n","2020-11-09 07:59:56,342 - INFO - allennlp.common.params - trainer.grad_clipping = None\n","2020-11-09 07:59:56,342 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None\n","2020-11-09 07:59:56,342 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n","2020-11-09 07:59:56,342 - INFO - allennlp.common.params - trainer.gradient_accumulation_batch_size = 8\n","2020-11-09 08:00:01,118 - INFO - allennlp.common.params - trainer.optimizer.type = bert_adam\n","2020-11-09 08:00:01,119 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n","2020-11-09 08:00:01,119 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n","2020-11-09 08:00:01,119 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups.0.1.weight_decay = 0\n","2020-11-09 08:00:01,120 - INFO - allennlp.training.optimizers - Done constructing parameter groups.\n","2020-11-09 08:00:01,120 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_classification_layer.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias', '_feedforward_layer._linear_layers.0.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias'], {'weight_decay': 0}\n","2020-11-09 08:00:01,161 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight', '_classification_layer.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight', '_feedforward_layer._linear_layers.0.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight'], {}\n","2020-11-09 08:00:01,161 - WARNING - allennlp.training.optimizers - When constructing parameter groups,  layer_norm.weight not match any parameter name\n","2020-11-09 08:00:01,162 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125239300\n","2020-11-09 08:00:01,163 - INFO - allennlp.common.params - trainer.optimizer.infer_type_and_cast = True\n","2020-11-09 08:00:01,163 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n","2020-11-09 08:00:01,163 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n","2020-11-09 08:00:01,163 - INFO - allennlp.common.params - trainer.optimizer.b1 = 0.9\n","2020-11-09 08:00:01,163 - INFO - allennlp.common.params - trainer.optimizer.b2 = 0.98\n","2020-11-09 08:00:01,163 - INFO - allennlp.common.params - trainer.optimizer.e = 1e-06\n","2020-11-09 08:00:01,163 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05\n","2020-11-09 08:00:01,163 - INFO - allennlp.common.params - trainer.optimizer.max_grad_norm = 1\n","2020-11-09 08:00:01,163 - INFO - allennlp.common.params - trainer.optimizer.schedule = warmup_linear\n","2020-11-09 08:00:01,163 - INFO - allennlp.common.params - trainer.optimizer.t_total = -1\n","2020-11-09 08:00:01,163 - INFO - allennlp.common.params - trainer.optimizer.warmup = 0.06\n","2020-11-09 08:00:01,163 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1\n","2020-11-09 08:00:01,163 - WARNING - pytorch_pretrained_bert.optimization - t_total value of -1 results in schedule not being applied\n","2020-11-09 08:00:01,165 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 0\n","2020-11-09 08:00:01,165 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None\n","2020-11-09 08:00:01,165 - INFO - allennlp.common.params - trainer.model_save_interval = None\n","2020-11-09 08:00:01,165 - INFO - allennlp.common.params - trainer.summary_interval = 100\n","2020-11-09 08:00:01,165 - INFO - allennlp.common.params - trainer.histogram_interval = None\n","2020-11-09 08:00:01,165 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True\n","2020-11-09 08:00:01,165 - INFO - allennlp.common.params - trainer.should_log_learning_rate = False\n","2020-11-09 08:00:01,165 - INFO - allennlp.common.params - trainer.log_batch_size_period = None\n","2020-11-09 08:00:01,167 - INFO - allennlp.training.trainer - Beginning training.\n","2020-11-09 08:00:01,168 - INFO - allennlp.training.trainer - Epoch 0/9\n","2020-11-09 08:00:01,168 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 5694.66\n","2020-11-09 08:00:01,293 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1769\n","2020-11-09 08:00:01,296 - INFO - allennlp.training.trainer - Training\n","  0%|          | 0/14375 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","f1: 0.9008, accuracy: 0.9009, loss: 0.3210 ||: 100%|##########| 14375/14375 [36:04<00:00,  6.64it/s]\n","2020-11-09 08:36:05,351 - INFO - allennlp.training.trainer - Validating\n","f1: 0.9194, accuracy: 0.9196, loss: 0.2707 ||: 100%|##########| 79/79 [00:04<00:00, 16.18it/s]\n","2020-11-09 08:36:10,236 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 08:36:10,237 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  5694.660  |       N/A\n","2020-11-09 08:36:10,238 - INFO - allennlp.training.tensorboard_writer - f1              |     0.901  |     0.919\n","2020-11-09 08:36:10,239 - INFO - allennlp.training.tensorboard_writer - loss            |     0.321  |     0.271\n","2020-11-09 08:36:10,240 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.901  |     0.920\n","2020-11-09 08:36:10,240 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  1769.000  |       N/A\n","2020-11-09 08:36:17,216 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/ag_nas_01/best.th'.\n","2020-11-09 08:36:18,437 - INFO - allennlp.training.trainer - Epoch duration: 0:36:17.269497\n","2020-11-09 08:36:18,439 - INFO - allennlp.training.trainer - Estimated training time remaining: 5:26:35\n","2020-11-09 08:36:18,440 - INFO - allennlp.training.trainer - Epoch 1/9\n","2020-11-09 08:36:18,440 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 5865.14\n","2020-11-09 08:36:18,568 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 7033\n","2020-11-09 08:36:18,572 - INFO - allennlp.training.trainer - Training\n","f1: 0.9168, accuracy: 0.9168, loss: 0.2914 ||: 100%|##########| 14375/14375 [35:04<00:00,  6.83it/s]\n","2020-11-09 09:11:22,584 - INFO - allennlp.training.trainer - Validating\n","f1: 0.9232, accuracy: 0.9234, loss: 0.2905 ||: 100%|##########| 79/79 [00:04<00:00, 16.95it/s]\n","2020-11-09 09:11:27,247 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 09:11:27,247 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  5865.140  |       N/A\n","2020-11-09 09:11:27,247 - INFO - allennlp.training.tensorboard_writer - f1              |     0.917  |     0.923\n","2020-11-09 09:11:27,248 - INFO - allennlp.training.tensorboard_writer - loss            |     0.291  |     0.291\n","2020-11-09 09:11:27,250 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.917  |     0.923\n","2020-11-09 09:11:27,250 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  7033.000  |       N/A\n","2020-11-09 09:11:34,483 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/ag_nas_01/best.th'.\n","2020-11-09 09:11:35,893 - INFO - allennlp.training.trainer - Epoch duration: 0:35:17.453099\n","2020-11-09 09:11:35,893 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:46:18\n","2020-11-09 09:11:35,893 - INFO - allennlp.training.trainer - Epoch 2/9\n","2020-11-09 09:11:35,893 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 5868.452\n","2020-11-09 09:11:36,022 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 7033\n","2020-11-09 09:11:36,026 - INFO - allennlp.training.trainer - Training\n","f1: 0.9244, accuracy: 0.9244, loss: 0.2664 ||: 100%|##########| 14375/14375 [34:56<00:00,  6.86it/s]\n","2020-11-09 09:46:32,277 - INFO - allennlp.training.trainer - Validating\n","f1: 0.9280, accuracy: 0.9280, loss: 0.3272 ||: 100%|##########| 79/79 [00:04<00:00, 17.08it/s]\n","2020-11-09 09:46:36,905 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 09:46:36,905 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  5868.452  |       N/A\n","2020-11-09 09:46:36,906 - INFO - allennlp.training.tensorboard_writer - f1              |     0.924  |     0.928\n","2020-11-09 09:46:36,906 - INFO - allennlp.training.tensorboard_writer - loss            |     0.266  |     0.327\n","2020-11-09 09:46:36,907 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.924  |     0.928\n","2020-11-09 09:46:36,908 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  7033.000  |       N/A\n","2020-11-09 09:46:43,943 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/ag_nas_01/best.th'.\n","2020-11-09 09:46:45,545 - INFO - allennlp.training.trainer - Epoch duration: 0:35:09.652092\n","2020-11-09 09:46:45,545 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:09:03\n","2020-11-09 09:46:45,546 - INFO - allennlp.training.trainer - Epoch 3/9\n","2020-11-09 09:46:45,546 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 5868.452\n","2020-11-09 09:46:45,671 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 7033\n","2020-11-09 09:46:45,674 - INFO - allennlp.training.trainer - Training\n","f1: 0.9317, accuracy: 0.9317, loss: 0.2567 ||: 100%|##########| 14375/14375 [34:21<00:00,  6.97it/s]\n","2020-11-09 10:21:07,179 - INFO - allennlp.training.trainer - Validating\n","f1: 0.9202, accuracy: 0.9198, loss: 0.3851 ||: 100%|##########| 79/79 [00:04<00:00, 17.00it/s]\n","2020-11-09 10:21:11,827 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 10:21:11,827 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  5868.452  |       N/A\n","2020-11-09 10:21:11,828 - INFO - allennlp.training.tensorboard_writer - f1              |     0.932  |     0.920\n","2020-11-09 10:21:11,828 - INFO - allennlp.training.tensorboard_writer - loss            |     0.257  |     0.385\n","2020-11-09 10:21:11,829 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.932  |     0.920\n","2020-11-09 10:21:11,829 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  7033.000  |       N/A\n","2020-11-09 10:21:18,583 - INFO - allennlp.training.trainer - Epoch duration: 0:34:33.036934\n","2020-11-09 10:21:18,583 - INFO - allennlp.training.trainer - Estimated training time remaining: 3:31:56\n","2020-11-09 10:21:18,583 - INFO - allennlp.training.trainer - Epoch 4/9\n","2020-11-09 10:21:18,583 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 5868.452\n","2020-11-09 10:21:18,706 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 7033\n","2020-11-09 10:21:18,709 - INFO - allennlp.training.trainer - Training\n","f1: 0.9359, accuracy: 0.9359, loss: 0.2469 ||: 100%|##########| 14375/14375 [34:33<00:00,  6.93it/s]\n","2020-11-09 10:55:52,258 - INFO - allennlp.training.trainer - Validating\n","f1: 0.9279, accuracy: 0.9278, loss: 0.3290 ||: 100%|##########| 79/79 [00:04<00:00, 17.00it/s]\n","2020-11-09 10:55:56,907 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 10:55:56,907 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  5868.452  |       N/A\n","2020-11-09 10:55:56,908 - INFO - allennlp.training.tensorboard_writer - f1              |     0.936  |     0.928\n","2020-11-09 10:55:56,909 - INFO - allennlp.training.tensorboard_writer - loss            |     0.247  |     0.329\n","2020-11-09 10:55:56,909 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.936  |     0.928\n","2020-11-09 10:55:56,910 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  7033.000  |       N/A\n","2020-11-09 10:56:04,322 - INFO - allennlp.training.trainer - Epoch duration: 0:34:45.739180\n","2020-11-09 10:56:04,322 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:56:03\n","2020-11-09 10:56:04,323 - INFO - allennlp.training.trainer - Epoch 5/9\n","2020-11-09 10:56:04,323 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 5868.452\n","2020-11-09 10:56:04,444 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 7033\n","2020-11-09 10:56:04,447 - INFO - allennlp.training.trainer - Training\n","f1: 0.9403, accuracy: 0.9403, loss: 0.2328 ||: 100%|##########| 14375/14375 [35:12<00:00,  6.80it/s]\n","2020-11-09 11:31:17,121 - INFO - allennlp.training.trainer - Validating\n","f1: 0.9281, accuracy: 0.9280, loss: 0.3244 ||: 100%|##########| 79/79 [00:04<00:00, 16.84it/s]\n","2020-11-09 11:31:21,813 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 11:31:21,813 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  5868.452  |       N/A\n","2020-11-09 11:31:21,814 - INFO - allennlp.training.tensorboard_writer - f1              |     0.940  |     0.928\n","2020-11-09 11:31:21,814 - INFO - allennlp.training.tensorboard_writer - loss            |     0.233  |     0.324\n","2020-11-09 11:31:21,814 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.940  |     0.928\n","2020-11-09 11:31:21,815 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  7033.000  |       N/A\n","2020-11-09 11:31:29,073 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/ag_nas_01/best.th'.\n","2020-11-09 11:31:30,174 - INFO - allennlp.training.trainer - Epoch duration: 0:35:25.851315\n","2020-11-09 11:31:30,174 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:20:59\n","2020-11-09 11:31:30,174 - INFO - allennlp.training.trainer - Epoch 6/9\n","2020-11-09 11:31:30,174 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 5868.452\n","2020-11-09 11:31:30,303 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 7033\n","2020-11-09 11:31:30,306 - INFO - allennlp.training.trainer - Training\n","f1: 0.9430, accuracy: 0.9430, loss: 0.2267 ||: 100%|##########| 14375/14375 [35:42<00:00,  6.71it/s]\n","2020-11-09 12:07:13,273 - INFO - allennlp.training.trainer - Validating\n","f1: 0.9246, accuracy: 0.9248, loss: 0.3536 ||: 100%|##########| 79/79 [00:04<00:00, 16.93it/s]\n","2020-11-09 12:07:17,943 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 12:07:17,943 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  5868.452  |       N/A\n","2020-11-09 12:07:17,943 - INFO - allennlp.training.tensorboard_writer - f1              |     0.943  |     0.925\n","2020-11-09 12:07:17,944 - INFO - allennlp.training.tensorboard_writer - loss            |     0.227  |     0.354\n","2020-11-09 12:07:17,944 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.943  |     0.925\n","2020-11-09 12:07:17,946 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  7033.000  |       N/A\n","2020-11-09 12:07:24,889 - INFO - allennlp.training.trainer - Epoch duration: 0:35:54.714728\n","2020-11-09 12:07:24,889 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:46:01\n","2020-11-09 12:07:24,889 - INFO - allennlp.training.trainer - Epoch 7/9\n","2020-11-09 12:07:24,890 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 5868.452\n","2020-11-09 12:07:25,013 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 7033\n","2020-11-09 12:07:25,017 - INFO - allennlp.training.trainer - Training\n","f1: 0.9439, accuracy: 0.9439, loss: 0.2365 ||: 100%|##########| 14375/14375 [35:31<00:00,  6.74it/s]\n","2020-11-09 12:42:56,510 - INFO - allennlp.training.trainer - Validating\n","f1: 0.9272, accuracy: 0.9274, loss: 0.3492 ||: 100%|##########| 79/79 [00:04<00:00, 16.80it/s]\n","2020-11-09 12:43:01,216 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 12:43:01,216 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  5868.452  |       N/A\n","2020-11-09 12:43:01,216 - INFO - allennlp.training.tensorboard_writer - f1              |     0.944  |     0.927\n","2020-11-09 12:43:01,217 - INFO - allennlp.training.tensorboard_writer - loss            |     0.237  |     0.349\n","2020-11-09 12:43:01,218 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.944  |     0.927\n","2020-11-09 12:43:01,218 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  7033.000  |       N/A\n","2020-11-09 12:43:08,728 - INFO - allennlp.training.trainer - Epoch duration: 0:35:43.838429\n","2020-11-09 12:43:08,728 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:10:46\n","2020-11-09 12:43:08,728 - INFO - allennlp.training.trainer - Epoch 8/9\n","2020-11-09 12:43:08,728 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 5868.452\n","2020-11-09 12:43:08,850 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 7033\n","2020-11-09 12:43:08,854 - INFO - allennlp.training.trainer - Training\n","f1: 0.9479, accuracy: 0.9479, loss: 0.2124 ||: 100%|##########| 14375/14375 [36:13<00:00,  6.62it/s]\n","2020-11-09 13:19:21,892 - INFO - allennlp.training.trainer - Validating\n","f1: 0.9290, accuracy: 0.9292, loss: 0.3499 ||: 100%|##########| 79/79 [00:04<00:00, 16.76it/s]\n","2020-11-09 13:19:26,609 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 13:19:26,609 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  5868.452  |       N/A\n","2020-11-09 13:19:26,609 - INFO - allennlp.training.tensorboard_writer - f1              |     0.948  |     0.929\n","2020-11-09 13:19:26,611 - INFO - allennlp.training.tensorboard_writer - loss            |     0.212  |     0.350\n","2020-11-09 13:19:26,611 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.948  |     0.929\n","2020-11-09 13:19:26,611 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  7033.000  |       N/A\n","2020-11-09 13:19:33,667 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/ag_nas_01/best.th'.\n","2020-11-09 13:19:35,202 - INFO - allennlp.training.trainer - Epoch duration: 0:36:26.474109\n","2020-11-09 13:19:35,203 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:35:30\n","2020-11-09 13:19:35,203 - INFO - allennlp.training.trainer - Epoch 9/9\n","2020-11-09 13:19:35,203 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 5868.452\n","2020-11-09 13:19:35,332 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 7033\n","2020-11-09 13:19:35,335 - INFO - allennlp.training.trainer - Training\n","f1: 0.9526, accuracy: 0.9526, loss: 0.1977 ||: 100%|##########| 14375/14375 [36:31<00:00,  6.56it/s]\n","2020-11-09 13:56:06,901 - INFO - allennlp.training.trainer - Validating\n","f1: 0.9309, accuracy: 0.9312, loss: 0.3483 ||: 100%|##########| 79/79 [00:04<00:00, 16.90it/s]\n","2020-11-09 13:56:11,579 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 13:56:11,580 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  5868.452  |       N/A\n","2020-11-09 13:56:11,580 - INFO - allennlp.training.tensorboard_writer - f1              |     0.953  |     0.931\n","2020-11-09 13:56:11,581 - INFO - allennlp.training.tensorboard_writer - loss            |     0.198  |     0.348\n","2020-11-09 13:56:11,581 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.953  |     0.931\n","2020-11-09 13:56:11,582 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  7033.000  |       N/A\n","2020-11-09 13:56:18,796 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/ag_nas_01/best.th'.\n","2020-11-09 13:56:20,453 - INFO - allennlp.training.trainer - Epoch duration: 0:36:45.249954\n","2020-11-09 13:56:20,454 - INFO - allennlp.training.checkpointer - loading best weights\n","2020-11-09 13:56:21,053 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.\n","2020-11-09 13:56:21,054 - INFO - allennlp.training.util - Iterating over dataset\n","f1: 0.92, accuracy: 0.93, loss: 0.38 ||: 100%|##########| 119/119 [00:07<00:00, 15.88it/s]\n","2020-11-09 13:56:28,548 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/ag_nas_01/model.tar.gz\n","2020-11-09 13:56:56,144 - INFO - allennlp.common.util - Metrics: {\n","  \"best_epoch\": 9,\n","  \"peak_cpu_memory_MB\": 5868.452,\n","  \"peak_gpu_0_memory_MB\": 7033,\n","  \"training_duration\": \"5:56:10.414769\",\n","  \"training_start_epoch\": 0,\n","  \"training_epochs\": 9,\n","  \"epoch\": 9,\n","  \"training_f1\": 0.9526129961013794,\n","  \"training_accuracy\": 0.9526086956521739,\n","  \"training_loss\": 0.19766442463071612,\n","  \"training_cpu_memory_MB\": 5868.452,\n","  \"training_gpu_0_memory_MB\": 7033,\n","  \"validation_f1\": 0.9308993518352509,\n","  \"validation_accuracy\": 0.9312,\n","  \"validation_loss\": 0.3483208000624576,\n","  \"best_validation_f1\": 0.9308993518352509,\n","  \"best_validation_accuracy\": 0.9312,\n","  \"best_validation_loss\": 0.3483208000624576,\n","  \"test_f1\": 0.9249369353055954,\n","  \"test_accuracy\": 0.9252631578947368,\n","  \"test_loss\": 0.3763611076963173\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v1uFTZkwqkAG","executionInfo":{"status":"ok","timestamp":1604930429751,"user_tz":300,"elapsed":44262760,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"8bd17027-39b2-46e2-babe-891e0f6c22f6","colab":{"base_uri":"https://localhost:8080/"}},"source":["!python -m scripts.train \\\n","        --config training_config/classifier.jsonnet \\\n","        --serialization_dir model_logs/hyperpartisan_news_nas_01 \\\n","        --hyperparameters ROBERTA_CLASSIFIER_MINI \\\n","        --dataset hyperpartisan_news \\\n","        --model roberta-base \\\n","        --device 0 \\\n","        --perf +f1 \\\n","        --evaluate_on_test"],"execution_count":21,"outputs":[{"output_type":"stream","text":["2020-11-09 13:57:05,881 - INFO - pytorch_pretrained_bert.modeling - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-09 13:57:06,386 - INFO - pytorch_transformers.modeling_bert - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-09 13:57:06,390 - INFO - pytorch_transformers.modeling_xlnet - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n","2020-11-09 13:57:06,962 - INFO - allennlp.common.params - random_seed = 539954\n","2020-11-09 13:57:06,962 - INFO - allennlp.common.params - numpy_seed = 539954\n","2020-11-09 13:57:06,962 - INFO - allennlp.common.params - pytorch_seed = 539954\n","2020-11-09 13:57:06,970 - INFO - allennlp.common.checks - Pytorch version: 1.7.0+cu101\n","2020-11-09 13:57:06,971 - INFO - allennlp.common.params - evaluate_on_test = True\n","2020-11-09 13:57:06,972 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}, 'type': 'text_classification_json_with_sampling'} and extras set()\n","2020-11-09 13:57:06,972 - INFO - allennlp.common.params - dataset_reader.type = text_classification_json_with_sampling\n","2020-11-09 13:57:06,972 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.data.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}} and extras set()\n","2020-11-09 13:57:06,972 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 13:57:06,972 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.type = pretrained_transformer\n","2020-11-09 13:57:06,973 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base'} and extras set()\n","2020-11-09 13:57:06,973 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.model_name = roberta-base\n","2020-11-09 13:57:06,973 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.do_lowercase = False\n","2020-11-09 13:57:06,973 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.namespace = tags\n","2020-11-09 13:57:06,973 - INFO - allennlp.common.params - dataset_reader.token_indexers.roberta.token_min_padding_length = 0\n","2020-11-09 13:57:07,771 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 13:57:07,771 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 13:57:07,852 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 1\n","2020-11-09 13:57:07,852 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 13:57:07,852 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer\n","2020-11-09 13:57:07,852 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>']} and extras set()\n","2020-11-09 13:57:07,852 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-base\n","2020-11-09 13:57:07,853 - INFO - allennlp.common.params - dataset_reader.tokenizer.do_lowercase = False\n","2020-11-09 13:57:07,853 - INFO - allennlp.common.params - dataset_reader.tokenizer.start_tokens = ['<s>']\n","2020-11-09 13:57:07,853 - INFO - allennlp.common.params - dataset_reader.tokenizer.end_tokens = ['</s>']\n","2020-11-09 13:57:08,573 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 13:57:08,573 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 13:57:08,650 - INFO - allennlp.common.params - dataset_reader.max_sequence_length = 512\n","2020-11-09 13:57:08,650 - INFO - allennlp.common.params - dataset_reader.sample = None\n","2020-11-09 13:57:08,650 - INFO - allennlp.common.params - dataset_reader.skip_label_indexing = False\n","2020-11-09 13:57:08,651 - INFO - allennlp.common.params - dataset_reader.lazy = False\n","2020-11-09 13:57:08,651 - INFO - allennlp.training.util - Using a separate dataset reader to load validation and test data.\n","2020-11-09 13:57:08,651 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}, 'type': 'text_classification_json_with_sampling'} and extras set()\n","2020-11-09 13:57:08,651 - INFO - allennlp.common.params - validation_dataset_reader.type = text_classification_json_with_sampling\n","2020-11-09 13:57:08,651 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.data.dataset_readers.text_classification_json_reader_with_sampling.TextClassificationJsonReaderWithSampling'> from params {'lazy': False, 'max_sequence_length': 512, 'token_indexers': {'roberta': {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'tokenizer': {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'}} and extras set()\n","2020-11-09 13:57:08,651 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 13:57:08,651 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.type = pretrained_transformer\n","2020-11-09 13:57:08,651 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'roberta-base'} and extras set()\n","2020-11-09 13:57:08,651 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.model_name = roberta-base\n","2020-11-09 13:57:08,652 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.do_lowercase = False\n","2020-11-09 13:57:08,652 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.namespace = tags\n","2020-11-09 13:57:08,652 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.roberta.token_min_padding_length = 0\n","2020-11-09 13:57:09,386 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 13:57:09,386 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 13:57:09,462 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 1\n","2020-11-09 13:57:09,463 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>'], 'type': 'pretrained_transformer'} and extras set()\n","2020-11-09 13:57:09,463 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = pretrained_transformer\n","2020-11-09 13:57:09,463 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': ['</s>'], 'model_name': 'roberta-base', 'start_tokens': ['<s>']} and extras set()\n","2020-11-09 13:57:09,463 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.model_name = roberta-base\n","2020-11-09 13:57:09,463 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.do_lowercase = False\n","2020-11-09 13:57:09,463 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.start_tokens = ['<s>']\n","2020-11-09 13:57:09,463 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.end_tokens = ['</s>']\n","2020-11-09 13:57:10,187 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2020-11-09 13:57:10,187 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2020-11-09 13:57:10,264 - INFO - allennlp.common.params - validation_dataset_reader.max_sequence_length = 512\n","2020-11-09 13:57:10,264 - INFO - allennlp.common.params - validation_dataset_reader.sample = None\n","2020-11-09 13:57:10,264 - INFO - allennlp.common.params - validation_dataset_reader.skip_label_indexing = False\n","2020-11-09 13:57:10,264 - INFO - allennlp.common.params - validation_dataset_reader.lazy = False\n","2020-11-09 13:57:10,264 - INFO - allennlp.common.params - train_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/hyperpartisan_news/train.jsonl\n","2020-11-09 13:57:10,264 - INFO - allennlp.training.util - Reading training data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/hyperpartisan_news/train.jsonl\n","0it [00:00, ?it/s]2020-11-09 13:57:10,946 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/hyperpartisan_news/train.jsonl not found in cache, downloading to /tmp/tmp23tx_02z\n","\n","  0%|          | 0/1749366 [00:00<?, ?B/s]\u001b[A\n","  1%|          | 17408/1749366 [00:00<00:16, 107429.79B/s]\u001b[A\n","  3%|2         | 52224/1749366 [00:00<00:13, 126244.65B/s]\u001b[A\n","  6%|5         | 104448/1749366 [00:00<00:10, 154298.05B/s]\u001b[A\n"," 10%|9         | 174080/1749366 [00:00<00:08, 190893.31B/s]\u001b[A\n"," 20%|#9        | 348160/1749366 [00:00<00:05, 253252.34B/s]\u001b[A\n"," 41%|####      | 713728/1749366 [00:00<00:03, 345076.70B/s]\u001b[A\n","100%|##########| 1749366/1749366 [00:01<00:00, 1526080.64B/s]\n","2020-11-09 13:57:12,891 - INFO - allennlp.common.file_utils - copying /tmp/tmp23tx_02z to cache at /root/.allennlp/cache/0289787a1d77fcf966b4eadc353477c4a95fee51874a50d37d973d30b764cb1c.96bd2e09fa3e900b16872f6cb552d18c497c0f45eb6ea8af1283bac2e3016950\n","2020-11-09 13:57:12,894 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/0289787a1d77fcf966b4eadc353477c4a95fee51874a50d37d973d30b764cb1c.96bd2e09fa3e900b16872f6cb552d18c497c0f45eb6ea8af1283bac2e3016950\n","2020-11-09 13:57:12,894 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmp23tx_02z\n","516it [00:05, 96.64it/s] \n","2020-11-09 13:57:15,604 - INFO - allennlp.common.params - validation_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/hyperpartisan_news/dev.jsonl\n","2020-11-09 13:57:15,604 - INFO - allennlp.training.util - Reading validation data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/hyperpartisan_news/dev.jsonl\n","0it [00:00, ?it/s]2020-11-09 13:57:16,307 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/hyperpartisan_news/dev.jsonl not found in cache, downloading to /tmp/tmp5q86yc0g\n","\n","  0%|          | 0/202157 [00:00<?, ?B/s]\u001b[A\n","  9%|8         | 17408/202157 [00:00<00:01, 106871.26B/s]\u001b[A\n"," 26%|##5       | 52224/202157 [00:00<00:01, 125874.24B/s]\u001b[A\n","100%|##########| 202157/202157 [00:00<00:00, 411719.11B/s]\n","2020-11-09 13:57:17,529 - INFO - allennlp.common.file_utils - copying /tmp/tmp5q86yc0g to cache at /root/.allennlp/cache/c645401e93532c0a655ed86f537534e66cd7ca1e2bdb46bd56d1d899844201c2.040eceadee42631351e5639783ebf3702dc7d0864a53a164a1072a59b50a554b\n","2020-11-09 13:57:17,530 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/c645401e93532c0a655ed86f537534e66cd7ca1e2bdb46bd56d1d899844201c2.040eceadee42631351e5639783ebf3702dc7d0864a53a164a1072a59b50a554b\n","2020-11-09 13:57:17,530 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmp5q86yc0g\n","63it [00:02, 26.93it/s]\n","2020-11-09 13:57:17,944 - INFO - allennlp.common.params - test_data_path = https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/hyperpartisan_news/test.jsonl\n","2020-11-09 13:57:17,944 - INFO - allennlp.training.util - Reading test data from https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/hyperpartisan_news/test.jsonl\n","0it [00:00, ?it/s]2020-11-09 13:57:18,618 - INFO - allennlp.common.file_utils - https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/hyperpartisan_news/test.jsonl not found in cache, downloading to /tmp/tmpk1kcnkub\n","\n","  0%|          | 0/247602 [00:00<?, ?B/s]\u001b[A\n","  7%|7         | 17408/247602 [00:00<00:02, 106714.12B/s]\u001b[A\n"," 21%|##1       | 52224/247602 [00:00<00:01, 125668.13B/s]\u001b[A\n"," 42%|####2     | 104448/247602 [00:00<00:00, 153685.78B/s]\u001b[A\n","100%|##########| 247602/247602 [00:00<00:00, 378479.71B/s]\n","2020-11-09 13:57:19,978 - INFO - allennlp.common.file_utils - copying /tmp/tmpk1kcnkub to cache at /root/.allennlp/cache/a53ab0b4447a5cd77840935a729ce23b684023797cf4f85aeb689d875c9390b2.9110014cd86917ada88fda4dbc6e64ea913af5fd218af1335c899f9f251505f7\n","2020-11-09 13:57:19,979 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/a53ab0b4447a5cd77840935a729ce23b684023797cf4f85aeb689d875c9390b2.9110014cd86917ada88fda4dbc6e64ea913af5fd218af1335c899f9f251505f7\n","2020-11-09 13:57:19,979 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmpk1kcnkub\n","65it [00:02, 27.19it/s]\n","2020-11-09 13:57:20,351 - INFO - allennlp.training.trainer_pieces - From dataset instances, test, train, validation will be considered for vocabulary creation.\n","2020-11-09 13:57:20,351 - INFO - allennlp.common.params - vocabulary.type = None\n","2020-11-09 13:57:20,351 - INFO - allennlp.common.params - vocabulary.extend = False\n","2020-11-09 13:57:20,351 - INFO - allennlp.common.params - vocabulary.directory_path = None\n","2020-11-09 13:57:20,351 - INFO - allennlp.common.params - vocabulary.min_count = None\n","2020-11-09 13:57:20,351 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None\n","2020-11-09 13:57:20,351 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')\n","2020-11-09 13:57:20,351 - INFO - allennlp.common.params - vocabulary.pretrained_files = {}\n","2020-11-09 13:57:20,351 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None\n","2020-11-09 13:57:20,351 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False\n","2020-11-09 13:57:20,351 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None\n","2020-11-09 13:57:20,351 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n","644it [00:00, 19107.09it/s]\n","2020-11-09 13:57:20,386 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'dropout': '0.1', 'feedforward_layer': {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1}, 'seq2vec_encoder': {'embedding_dim': 768, 'type': 'cls_pooler'}, 'text_field_embedder': {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}, 'type': 'basic_classifier_with_f1'} and extras {'vocab'}\n","2020-11-09 13:57:20,386 - INFO - allennlp.common.params - model.type = basic_classifier_with_f1\n","2020-11-09 13:57:20,386 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.models.basic_classifier_with_f1.BasicClassifierWithF1'> from params {'dropout': '0.1', 'feedforward_layer': {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1}, 'seq2vec_encoder': {'embedding_dim': 768, 'type': 'cls_pooler'}, 'text_field_embedder': {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}}} and extras {'vocab'}\n","2020-11-09 13:57:20,386 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'roberta': {'model_name': 'roberta-base', 'type': 'pretrained_transformer'}} and extras {'vocab'}\n","2020-11-09 13:57:20,386 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n","2020-11-09 13:57:20,387 - INFO - allennlp.common.params - model.text_field_embedder.embedder_to_indexer_map = None\n","2020-11-09 13:57:20,387 - INFO - allennlp.common.params - model.text_field_embedder.allow_unmatched_keys = False\n","2020-11-09 13:57:20,387 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders = None\n","2020-11-09 13:57:20,387 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_name': 'roberta-base', 'type': 'pretrained_transformer'} and extras {'vocab'}\n","2020-11-09 13:57:20,387 - INFO - allennlp.common.params - model.text_field_embedder.roberta.type = pretrained_transformer\n","2020-11-09 13:57:20,387 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.pretrained_transformer_embedder.PretrainedTransformerEmbedder'> from params {'model_name': 'roberta-base'} and extras {'vocab'}\n","2020-11-09 13:57:20,387 - INFO - allennlp.common.params - model.text_field_embedder.roberta.model_name = roberta-base\n","2020-11-09 13:57:20,762 - INFO - pytorch_transformers.modeling_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/pytorch_transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n","2020-11-09 13:57:20,762 - INFO - pytorch_transformers.modeling_utils - Model config {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 1,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","2020-11-09 13:57:21,145 - INFO - pytorch_transformers.modeling_utils - loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n","2020-11-09 13:57:25,827 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'embedding_dim': 768, 'type': 'cls_pooler'} and extras {'vocab'}\n","2020-11-09 13:57:25,827 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler\n","2020-11-09 13:57:25,827 - INFO - allennlp.common.from_params - instantiating class <class 'dont_stop_pretraining.modules.seq2vec_encoders.cls_pooler.CLSPooler'> from params {'embedding_dim': 768} and extras {'vocab'}\n","2020-11-09 13:57:25,828 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 768\n","2020-11-09 13:57:25,828 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1} and extras {'vocab'}\n","2020-11-09 13:57:25,828 - INFO - allennlp.common.params - model.feedforward_layer.input_dim = 768\n","2020-11-09 13:57:25,828 - INFO - allennlp.common.params - model.feedforward_layer.num_layers = 1\n","2020-11-09 13:57:25,828 - INFO - allennlp.common.params - model.feedforward_layer.hidden_dims = 768\n","2020-11-09 13:57:25,828 - INFO - allennlp.common.params - model.feedforward_layer.activations = tanh\n","2020-11-09 13:57:25,829 - INFO - allennlp.common.params - model.feedforward_layer.dropout = 0.0\n","2020-11-09 13:57:25,834 - INFO - allennlp.common.params - model.dropout = 0.1\n","2020-11-09 13:57:25,834 - INFO - allennlp.common.params - model.num_labels = None\n","2020-11-09 13:57:25,834 - INFO - allennlp.common.params - model.label_namespace = labels\n","2020-11-09 13:57:25,834 - INFO - allennlp.nn.initializers - Initializing parameters\n","2020-11-09 13:57:25,836 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n","2020-11-09 13:57:25,836 - INFO - allennlp.nn.initializers -    _classification_layer.bias\n","2020-11-09 13:57:25,836 - INFO - allennlp.nn.initializers -    _classification_layer.weight\n","2020-11-09 13:57:25,836 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.bias\n","2020-11-09 13:57:25,836 - INFO - allennlp.nn.initializers -    _feedforward_layer._linear_layers.0.weight\n","2020-11-09 13:57:25,836 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias\n","2020-11-09 13:57:25,836 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight\n","2020-11-09 13:57:25,836 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight\n","2020-11-09 13:57:25,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight\n","2020-11-09 13:57:25,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight\n","2020-11-09 13:57:25,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias\n","2020-11-09 13:57:25,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight\n","2020-11-09 13:57:25,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias\n","2020-11-09 13:57:25,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight\n","2020-11-09 13:57:25,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias\n","2020-11-09 13:57:25,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight\n","2020-11-09 13:57:25,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias\n","2020-11-09 13:57:25,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight\n","2020-11-09 13:57:25,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias\n","2020-11-09 13:57:25,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight\n","2020-11-09 13:57:25,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias\n","2020-11-09 13:57:25,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight\n","2020-11-09 13:57:25,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias\n","2020-11-09 13:57:25,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight\n","2020-11-09 13:57:25,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias\n","2020-11-09 13:57:25,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight\n","2020-11-09 13:57:25,837 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias\n","2020-11-09 13:57:25,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight\n","2020-11-09 13:57:25,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias\n","2020-11-09 13:57:25,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight\n","2020-11-09 13:57:25,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias\n","2020-11-09 13:57:25,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight\n","2020-11-09 13:57:25,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias\n","2020-11-09 13:57:25,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight\n","2020-11-09 13:57:25,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias\n","2020-11-09 13:57:25,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight\n","2020-11-09 13:57:25,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias\n","2020-11-09 13:57:25,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight\n","2020-11-09 13:57:25,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias\n","2020-11-09 13:57:25,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight\n","2020-11-09 13:57:25,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias\n","2020-11-09 13:57:25,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight\n","2020-11-09 13:57:25,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias\n","2020-11-09 13:57:25,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight\n","2020-11-09 13:57:25,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias\n","2020-11-09 13:57:25,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight\n","2020-11-09 13:57:25,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias\n","2020-11-09 13:57:25,838 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight\n","2020-11-09 13:57:25,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias\n","2020-11-09 13:57:25,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight\n","2020-11-09 13:57:25,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias\n","2020-11-09 13:57:25,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight\n","2020-11-09 13:57:25,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias\n","2020-11-09 13:57:25,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight\n","2020-11-09 13:57:25,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias\n","2020-11-09 13:57:25,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight\n","2020-11-09 13:57:25,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias\n","2020-11-09 13:57:25,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight\n","2020-11-09 13:57:25,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias\n","2020-11-09 13:57:25,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight\n","2020-11-09 13:57:25,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias\n","2020-11-09 13:57:25,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight\n","2020-11-09 13:57:25,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias\n","2020-11-09 13:57:25,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight\n","2020-11-09 13:57:25,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias\n","2020-11-09 13:57:25,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight\n","2020-11-09 13:57:25,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,839 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias\n","2020-11-09 13:57:25,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight\n","2020-11-09 13:57:25,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias\n","2020-11-09 13:57:25,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight\n","2020-11-09 13:57:25,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias\n","2020-11-09 13:57:25,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight\n","2020-11-09 13:57:25,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias\n","2020-11-09 13:57:25,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight\n","2020-11-09 13:57:25,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias\n","2020-11-09 13:57:25,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight\n","2020-11-09 13:57:25,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias\n","2020-11-09 13:57:25,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight\n","2020-11-09 13:57:25,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias\n","2020-11-09 13:57:25,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight\n","2020-11-09 13:57:25,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias\n","2020-11-09 13:57:25,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight\n","2020-11-09 13:57:25,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias\n","2020-11-09 13:57:25,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight\n","2020-11-09 13:57:25,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias\n","2020-11-09 13:57:25,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight\n","2020-11-09 13:57:25,840 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias\n","2020-11-09 13:57:25,841 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight\n","2020-11-09 13:57:25,841 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias\n","2020-11-09 13:57:25,841 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight\n","2020-11-09 13:57:25,841 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias\n","2020-11-09 13:57:25,841 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight\n","2020-11-09 13:57:25,841 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias\n","2020-11-09 13:57:25,841 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight\n","2020-11-09 13:57:25,841 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,858 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias\n","2020-11-09 13:57:25,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight\n","2020-11-09 13:57:25,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias\n","2020-11-09 13:57:25,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight\n","2020-11-09 13:57:25,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias\n","2020-11-09 13:57:25,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight\n","2020-11-09 13:57:25,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias\n","2020-11-09 13:57:25,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight\n","2020-11-09 13:57:25,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias\n","2020-11-09 13:57:25,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight\n","2020-11-09 13:57:25,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias\n","2020-11-09 13:57:25,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight\n","2020-11-09 13:57:25,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias\n","2020-11-09 13:57:25,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight\n","2020-11-09 13:57:25,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias\n","2020-11-09 13:57:25,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight\n","2020-11-09 13:57:25,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias\n","2020-11-09 13:57:25,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight\n","2020-11-09 13:57:25,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias\n","2020-11-09 13:57:25,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight\n","2020-11-09 13:57:25,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias\n","2020-11-09 13:57:25,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight\n","2020-11-09 13:57:25,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias\n","2020-11-09 13:57:25,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight\n","2020-11-09 13:57:25,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias\n","2020-11-09 13:57:25,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight\n","2020-11-09 13:57:25,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias\n","2020-11-09 13:57:25,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight\n","2020-11-09 13:57:25,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias\n","2020-11-09 13:57:25,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight\n","2020-11-09 13:57:25,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias\n","2020-11-09 13:57:25,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight\n","2020-11-09 13:57:25,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias\n","2020-11-09 13:57:25,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight\n","2020-11-09 13:57:25,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias\n","2020-11-09 13:57:25,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight\n","2020-11-09 13:57:25,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias\n","2020-11-09 13:57:25,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight\n","2020-11-09 13:57:25,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias\n","2020-11-09 13:57:25,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight\n","2020-11-09 13:57:25,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias\n","2020-11-09 13:57:25,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight\n","2020-11-09 13:57:25,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias\n","2020-11-09 13:57:25,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight\n","2020-11-09 13:57:25,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias\n","2020-11-09 13:57:25,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight\n","2020-11-09 13:57:25,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias\n","2020-11-09 13:57:25,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight\n","2020-11-09 13:57:25,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias\n","2020-11-09 13:57:25,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight\n","2020-11-09 13:57:25,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias\n","2020-11-09 13:57:25,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight\n","2020-11-09 13:57:25,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias\n","2020-11-09 13:57:25,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight\n","2020-11-09 13:57:25,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias\n","2020-11-09 13:57:25,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight\n","2020-11-09 13:57:25,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias\n","2020-11-09 13:57:25,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight\n","2020-11-09 13:57:25,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias\n","2020-11-09 13:57:25,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight\n","2020-11-09 13:57:25,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias\n","2020-11-09 13:57:25,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight\n","2020-11-09 13:57:25,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias\n","2020-11-09 13:57:25,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight\n","2020-11-09 13:57:25,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias\n","2020-11-09 13:57:25,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight\n","2020-11-09 13:57:25,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias\n","2020-11-09 13:57:25,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight\n","2020-11-09 13:57:25,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias\n","2020-11-09 13:57:25,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight\n","2020-11-09 13:57:25,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias\n","2020-11-09 13:57:25,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight\n","2020-11-09 13:57:25,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias\n","2020-11-09 13:57:25,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight\n","2020-11-09 13:57:25,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias\n","2020-11-09 13:57:25,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight\n","2020-11-09 13:57:25,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias\n","2020-11-09 13:57:25,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight\n","2020-11-09 13:57:25,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias\n","2020-11-09 13:57:25,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight\n","2020-11-09 13:57:25,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias\n","2020-11-09 13:57:25,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight\n","2020-11-09 13:57:25,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias\n","2020-11-09 13:57:25,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight\n","2020-11-09 13:57:25,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias\n","2020-11-09 13:57:25,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight\n","2020-11-09 13:57:25,866 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 8, 'sorting_keys': [['tokens', 'num_tokens']], 'type': 'bucket'} and extras set()\n","2020-11-09 13:57:25,866 - INFO - allennlp.common.params - iterator.type = bucket\n","2020-11-09 13:57:25,867 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 8, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()\n","2020-11-09 13:57:25,867 - INFO - allennlp.common.params - iterator.sorting_keys = [['tokens', 'num_tokens']]\n","2020-11-09 13:57:25,867 - INFO - allennlp.common.params - iterator.padding_noise = 0.1\n","2020-11-09 13:57:25,867 - INFO - allennlp.common.params - iterator.biggest_batch_first = False\n","2020-11-09 13:57:25,867 - INFO - allennlp.common.params - iterator.batch_size = 8\n","2020-11-09 13:57:25,867 - INFO - allennlp.common.params - iterator.instances_per_epoch = None\n","2020-11-09 13:57:25,867 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None\n","2020-11-09 13:57:25,867 - INFO - allennlp.common.params - iterator.cache_instances = False\n","2020-11-09 13:57:25,868 - INFO - allennlp.common.params - iterator.track_epoch = False\n","2020-11-09 13:57:25,868 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None\n","2020-11-09 13:57:25,868 - INFO - allennlp.common.params - iterator.skip_smaller_batches = False\n","2020-11-09 13:57:25,868 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'sorting_keys': [['tokens', 'num_tokens']], 'type': 'bucket'} and extras set()\n","2020-11-09 13:57:25,868 - INFO - allennlp.common.params - validation_iterator.type = bucket\n","2020-11-09 13:57:25,868 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 64, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()\n","2020-11-09 13:57:25,868 - INFO - allennlp.common.params - validation_iterator.sorting_keys = [['tokens', 'num_tokens']]\n","2020-11-09 13:57:25,868 - INFO - allennlp.common.params - validation_iterator.padding_noise = 0.1\n","2020-11-09 13:57:25,868 - INFO - allennlp.common.params - validation_iterator.biggest_batch_first = False\n","2020-11-09 13:57:25,869 - INFO - allennlp.common.params - validation_iterator.batch_size = 64\n","2020-11-09 13:57:25,869 - INFO - allennlp.common.params - validation_iterator.instances_per_epoch = None\n","2020-11-09 13:57:25,869 - INFO - allennlp.common.params - validation_iterator.max_instances_in_memory = None\n","2020-11-09 13:57:25,869 - INFO - allennlp.common.params - validation_iterator.cache_instances = False\n","2020-11-09 13:57:25,869 - INFO - allennlp.common.params - validation_iterator.track_epoch = False\n","2020-11-09 13:57:25,869 - INFO - allennlp.common.params - validation_iterator.maximum_samples_per_batch = None\n","2020-11-09 13:57:25,869 - INFO - allennlp.common.params - validation_iterator.skip_smaller_batches = False\n","2020-11-09 13:57:25,869 - INFO - allennlp.common.params - trainer.no_grad = ()\n","2020-11-09 13:57:25,872 - INFO - allennlp.training.trainer_pieces - Following parameters are Frozen  (without gradient):\n","2020-11-09 13:57:25,872 - INFO - allennlp.training.trainer_pieces - Following parameters are Tunable (with gradient):\n","2020-11-09 13:57:25,872 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight\n","2020-11-09 13:57:25,872 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight\n","2020-11-09 13:57:25,872 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight\n","2020-11-09 13:57:25,873 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight\n","2020-11-09 13:57:25,873 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias\n","2020-11-09 13:57:25,873 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight\n","2020-11-09 13:57:25,873 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias\n","2020-11-09 13:57:25,873 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight\n","2020-11-09 13:57:25,873 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias\n","2020-11-09 13:57:25,873 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight\n","2020-11-09 13:57:25,873 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias\n","2020-11-09 13:57:25,873 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight\n","2020-11-09 13:57:25,873 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias\n","2020-11-09 13:57:25,873 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,873 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,873 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight\n","2020-11-09 13:57:25,873 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias\n","2020-11-09 13:57:25,873 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight\n","2020-11-09 13:57:25,874 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias\n","2020-11-09 13:57:25,874 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight\n","2020-11-09 13:57:25,874 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias\n","2020-11-09 13:57:25,874 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight\n","2020-11-09 13:57:25,874 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias\n","2020-11-09 13:57:25,874 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight\n","2020-11-09 13:57:25,874 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias\n","2020-11-09 13:57:25,874 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight\n","2020-11-09 13:57:25,874 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias\n","2020-11-09 13:57:25,874 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight\n","2020-11-09 13:57:25,874 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias\n","2020-11-09 13:57:25,874 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,874 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,874 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight\n","2020-11-09 13:57:25,874 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias\n","2020-11-09 13:57:25,874 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight\n","2020-11-09 13:57:25,874 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias\n","2020-11-09 13:57:25,875 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight\n","2020-11-09 13:57:25,875 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias\n","2020-11-09 13:57:25,875 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight\n","2020-11-09 13:57:25,875 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias\n","2020-11-09 13:57:25,875 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight\n","2020-11-09 13:57:25,875 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias\n","2020-11-09 13:57:25,875 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight\n","2020-11-09 13:57:25,875 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias\n","2020-11-09 13:57:25,875 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight\n","2020-11-09 13:57:25,875 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias\n","2020-11-09 13:57:25,875 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,875 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,875 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight\n","2020-11-09 13:57:25,875 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias\n","2020-11-09 13:57:25,875 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight\n","2020-11-09 13:57:25,875 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias\n","2020-11-09 13:57:25,876 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight\n","2020-11-09 13:57:25,876 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias\n","2020-11-09 13:57:25,876 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight\n","2020-11-09 13:57:25,876 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias\n","2020-11-09 13:57:25,876 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight\n","2020-11-09 13:57:25,876 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias\n","2020-11-09 13:57:25,876 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight\n","2020-11-09 13:57:25,876 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias\n","2020-11-09 13:57:25,876 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight\n","2020-11-09 13:57:25,876 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias\n","2020-11-09 13:57:25,876 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,876 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,876 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight\n","2020-11-09 13:57:25,876 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias\n","2020-11-09 13:57:25,876 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight\n","2020-11-09 13:57:25,877 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias\n","2020-11-09 13:57:25,877 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight\n","2020-11-09 13:57:25,877 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias\n","2020-11-09 13:57:25,877 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight\n","2020-11-09 13:57:25,877 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias\n","2020-11-09 13:57:25,877 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight\n","2020-11-09 13:57:25,877 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias\n","2020-11-09 13:57:25,877 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight\n","2020-11-09 13:57:25,877 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias\n","2020-11-09 13:57:25,966 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight\n","2020-11-09 13:57:25,966 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias\n","2020-11-09 13:57:25,966 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,966 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,966 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight\n","2020-11-09 13:57:25,966 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias\n","2020-11-09 13:57:25,966 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight\n","2020-11-09 13:57:25,967 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias\n","2020-11-09 13:57:25,967 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight\n","2020-11-09 13:57:25,967 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias\n","2020-11-09 13:57:25,967 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight\n","2020-11-09 13:57:25,967 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias\n","2020-11-09 13:57:25,967 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight\n","2020-11-09 13:57:25,967 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias\n","2020-11-09 13:57:25,967 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight\n","2020-11-09 13:57:25,967 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias\n","2020-11-09 13:57:25,967 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight\n","2020-11-09 13:57:25,967 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias\n","2020-11-09 13:57:25,967 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,967 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,967 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight\n","2020-11-09 13:57:25,967 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias\n","2020-11-09 13:57:25,968 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight\n","2020-11-09 13:57:25,968 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias\n","2020-11-09 13:57:25,968 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight\n","2020-11-09 13:57:25,968 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias\n","2020-11-09 13:57:25,968 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight\n","2020-11-09 13:57:25,968 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias\n","2020-11-09 13:57:25,968 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight\n","2020-11-09 13:57:25,968 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias\n","2020-11-09 13:57:25,968 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight\n","2020-11-09 13:57:25,968 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias\n","2020-11-09 13:57:25,968 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight\n","2020-11-09 13:57:25,968 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias\n","2020-11-09 13:57:25,968 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,968 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,968 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight\n","2020-11-09 13:57:25,968 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias\n","2020-11-09 13:57:25,968 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight\n","2020-11-09 13:57:25,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias\n","2020-11-09 13:57:25,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight\n","2020-11-09 13:57:25,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias\n","2020-11-09 13:57:25,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight\n","2020-11-09 13:57:25,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias\n","2020-11-09 13:57:25,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight\n","2020-11-09 13:57:25,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias\n","2020-11-09 13:57:25,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight\n","2020-11-09 13:57:25,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias\n","2020-11-09 13:57:25,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight\n","2020-11-09 13:57:25,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias\n","2020-11-09 13:57:25,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight\n","2020-11-09 13:57:25,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias\n","2020-11-09 13:57:25,969 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight\n","2020-11-09 13:57:25,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias\n","2020-11-09 13:57:25,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight\n","2020-11-09 13:57:25,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias\n","2020-11-09 13:57:25,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight\n","2020-11-09 13:57:25,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias\n","2020-11-09 13:57:25,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight\n","2020-11-09 13:57:25,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias\n","2020-11-09 13:57:25,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight\n","2020-11-09 13:57:25,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias\n","2020-11-09 13:57:25,970 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight\n","2020-11-09 13:57:25,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias\n","2020-11-09 13:57:25,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight\n","2020-11-09 13:57:25,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias\n","2020-11-09 13:57:25,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight\n","2020-11-09 13:57:25,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias\n","2020-11-09 13:57:25,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight\n","2020-11-09 13:57:25,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias\n","2020-11-09 13:57:25,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight\n","2020-11-09 13:57:25,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias\n","2020-11-09 13:57:25,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight\n","2020-11-09 13:57:25,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias\n","2020-11-09 13:57:25,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight\n","2020-11-09 13:57:25,971 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias\n","2020-11-09 13:57:25,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight\n","2020-11-09 13:57:25,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias\n","2020-11-09 13:57:25,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight\n","2020-11-09 13:57:25,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias\n","2020-11-09 13:57:25,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight\n","2020-11-09 13:57:25,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias\n","2020-11-09 13:57:25,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight\n","2020-11-09 13:57:25,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias\n","2020-11-09 13:57:25,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight\n","2020-11-09 13:57:25,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias\n","2020-11-09 13:57:25,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight\n","2020-11-09 13:57:25,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias\n","2020-11-09 13:57:25,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight\n","2020-11-09 13:57:25,972 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias\n","2020-11-09 13:57:25,973 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight\n","2020-11-09 13:57:25,973 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias\n","2020-11-09 13:57:25,973 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,973 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,973 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight\n","2020-11-09 13:57:25,973 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias\n","2020-11-09 13:57:25,973 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight\n","2020-11-09 13:57:25,973 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias\n","2020-11-09 13:57:25,973 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight\n","2020-11-09 13:57:25,973 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias\n","2020-11-09 13:57:25,973 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight\n","2020-11-09 13:57:25,973 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias\n","2020-11-09 13:57:25,973 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight\n","2020-11-09 13:57:25,973 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias\n","2020-11-09 13:57:25,973 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight\n","2020-11-09 13:57:25,973 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias\n","2020-11-09 13:57:25,974 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight\n","2020-11-09 13:57:25,974 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias\n","2020-11-09 13:57:25,974 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n","2020-11-09 13:57:25,974 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n","2020-11-09 13:57:25,974 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight\n","2020-11-09 13:57:25,974 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias\n","2020-11-09 13:57:25,974 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight\n","2020-11-09 13:57:25,974 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias\n","2020-11-09 13:57:25,974 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight\n","2020-11-09 13:57:25,974 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias\n","2020-11-09 13:57:25,974 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight\n","2020-11-09 13:57:25,974 - INFO - allennlp.training.trainer_pieces - _text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias\n","2020-11-09 13:57:25,974 - INFO - allennlp.training.trainer_pieces - _feedforward_layer._linear_layers.0.weight\n","2020-11-09 13:57:25,974 - INFO - allennlp.training.trainer_pieces - _feedforward_layer._linear_layers.0.bias\n","2020-11-09 13:57:25,974 - INFO - allennlp.training.trainer_pieces - _classification_layer.weight\n","2020-11-09 13:57:25,974 - INFO - allennlp.training.trainer_pieces - _classification_layer.bias\n","2020-11-09 13:57:25,975 - INFO - allennlp.common.params - trainer.patience = 3\n","2020-11-09 13:57:25,975 - INFO - allennlp.common.params - trainer.validation_metric = +f1\n","2020-11-09 13:57:25,975 - INFO - allennlp.common.params - trainer.shuffle = True\n","2020-11-09 13:57:25,975 - INFO - allennlp.common.params - trainer.num_epochs = 10\n","2020-11-09 13:57:25,975 - INFO - allennlp.common.params - trainer.cuda_device = 0\n","2020-11-09 13:57:25,975 - INFO - allennlp.common.params - trainer.grad_norm = None\n","2020-11-09 13:57:25,975 - INFO - allennlp.common.params - trainer.grad_clipping = None\n","2020-11-09 13:57:25,975 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None\n","2020-11-09 13:57:25,975 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n","2020-11-09 13:57:25,975 - INFO - allennlp.common.params - trainer.gradient_accumulation_batch_size = 8\n","2020-11-09 13:57:31,010 - INFO - allennlp.common.params - trainer.optimizer.type = bert_adam\n","2020-11-09 13:57:31,010 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n","2020-11-09 13:57:31,011 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n","2020-11-09 13:57:31,011 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups.0.1.weight_decay = 0\n","2020-11-09 13:57:31,012 - INFO - allennlp.training.optimizers - Done constructing parameter groups.\n","2020-11-09 13:57:31,012 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.bias', '_feedforward_layer._linear_layers.0.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_classification_layer.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.bias'], {'weight_decay': 0}\n","2020-11-09 13:57:31,096 - INFO - allennlp.training.optimizers - Group 1: ['_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.value.weight', '_feedforward_layer._linear_layers.0.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.output.dense.weight', '_classification_layer.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_roberta.transformer_model.encoder.layer.0.output.dense.weight'], {}\n","2020-11-09 13:57:31,096 - WARNING - allennlp.training.optimizers - When constructing parameter groups,  layer_norm.weight not match any parameter name\n","2020-11-09 13:57:31,096 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125237762\n","2020-11-09 13:57:31,097 - INFO - allennlp.common.params - trainer.optimizer.infer_type_and_cast = True\n","2020-11-09 13:57:31,097 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n","2020-11-09 13:57:31,097 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n","2020-11-09 13:57:31,097 - INFO - allennlp.common.params - trainer.optimizer.b1 = 0.9\n","2020-11-09 13:57:31,098 - INFO - allennlp.common.params - trainer.optimizer.b2 = 0.98\n","2020-11-09 13:57:31,098 - INFO - allennlp.common.params - trainer.optimizer.e = 1e-06\n","2020-11-09 13:57:31,098 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05\n","2020-11-09 13:57:31,098 - INFO - allennlp.common.params - trainer.optimizer.max_grad_norm = 1\n","2020-11-09 13:57:31,098 - INFO - allennlp.common.params - trainer.optimizer.schedule = warmup_linear\n","2020-11-09 13:57:31,098 - INFO - allennlp.common.params - trainer.optimizer.t_total = -1\n","2020-11-09 13:57:31,098 - INFO - allennlp.common.params - trainer.optimizer.warmup = 0.06\n","2020-11-09 13:57:31,098 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.1\n","2020-11-09 13:57:31,098 - WARNING - pytorch_pretrained_bert.optimization - t_total value of -1 results in schedule not being applied\n","2020-11-09 13:57:31,100 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 0\n","2020-11-09 13:57:31,100 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None\n","2020-11-09 13:57:31,100 - INFO - allennlp.common.params - trainer.model_save_interval = None\n","2020-11-09 13:57:31,100 - INFO - allennlp.common.params - trainer.summary_interval = 100\n","2020-11-09 13:57:31,100 - INFO - allennlp.common.params - trainer.histogram_interval = None\n","2020-11-09 13:57:31,100 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True\n","2020-11-09 13:57:31,100 - INFO - allennlp.common.params - trainer.should_log_learning_rate = False\n","2020-11-09 13:57:31,100 - INFO - allennlp.common.params - trainer.log_batch_size_period = None\n","2020-11-09 13:57:31,103 - INFO - allennlp.training.trainer - Beginning training.\n","2020-11-09 13:57:31,103 - INFO - allennlp.training.trainer - Epoch 0/9\n","2020-11-09 13:57:31,103 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4877.188\n","2020-11-09 13:57:31,218 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1769\n","2020-11-09 13:57:31,221 - INFO - allennlp.training.trainer - Training\n","  0%|          | 0/65 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","f1: 0.5613, accuracy: 0.6570, loss: 0.6032 ||: 100%|##########| 65/65 [00:21<00:00,  3.06it/s]\n","2020-11-09 13:57:52,451 - INFO - allennlp.training.trainer - Validating\n","f1: 0.7753, accuracy: 0.7937, loss: 0.6285 ||: 100%|##########| 1/1 [00:00<00:00,  1.44it/s]\n","2020-11-09 13:57:53,148 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 13:57:53,149 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  1769.000  |       N/A\n","2020-11-09 13:57:53,150 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4877.188  |       N/A\n","2020-11-09 13:57:53,151 - INFO - allennlp.training.tensorboard_writer - f1              |     0.561  |     0.775\n","2020-11-09 13:57:53,152 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.657  |     0.794\n","2020-11-09 13:57:53,153 - INFO - allennlp.training.tensorboard_writer - loss            |     0.603  |     0.629\n","2020-11-09 13:57:58,935 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/hyperpartisan_news_nas_01/best.th'.\n","2020-11-09 13:58:00,281 - INFO - allennlp.training.trainer - Epoch duration: 0:00:29.178685\n","2020-11-09 13:58:00,284 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:04:22\n","2020-11-09 13:58:00,284 - INFO - allennlp.training.trainer - Epoch 1/9\n","2020-11-09 13:58:00,284 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4889.496\n","2020-11-09 13:58:00,396 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 12795\n","2020-11-09 13:58:00,400 - INFO - allennlp.training.trainer - Training\n","f1: 0.7798, accuracy: 0.7984, loss: 0.4583 ||: 100%|##########| 65/65 [00:21<00:00,  3.03it/s]\n","2020-11-09 13:58:21,848 - INFO - allennlp.training.trainer - Validating\n","f1: 0.8134, accuracy: 0.8254, loss: 0.4151 ||: 100%|##########| 1/1 [00:00<00:00,  1.48it/s]\n","2020-11-09 13:58:22,527 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 13:58:22,528 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  12795.000  |       N/A\n","2020-11-09 13:58:22,528 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4889.496  |       N/A\n","2020-11-09 13:58:22,529 - INFO - allennlp.training.tensorboard_writer - f1              |     0.780  |     0.813\n","2020-11-09 13:58:22,529 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.798  |     0.825\n","2020-11-09 13:58:22,530 - INFO - allennlp.training.tensorboard_writer - loss            |     0.458  |     0.415\n","2020-11-09 13:58:30,551 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'model_logs/hyperpartisan_news_nas_01/best.th'.\n","2020-11-09 13:58:31,974 - INFO - allennlp.training.trainer - Epoch duration: 0:00:31.690051\n","2020-11-09 13:58:31,974 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:04:03\n","2020-11-09 13:58:31,974 - INFO - allennlp.training.trainer - Epoch 2/9\n","2020-11-09 13:58:31,974 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4889.688\n","2020-11-09 13:58:32,101 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 12795\n","2020-11-09 13:58:32,105 - INFO - allennlp.training.trainer - Training\n","f1: 0.8457, accuracy: 0.8585, loss: 0.3559 ||: 100%|##########| 65/65 [00:20<00:00,  3.10it/s]\n","2020-11-09 13:58:53,069 - INFO - allennlp.training.trainer - Validating\n","f1: 0.8058, accuracy: 0.8254, loss: 0.5026 ||: 100%|##########| 1/1 [00:00<00:00,  1.48it/s]\n","2020-11-09 13:58:53,745 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 13:58:53,746 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  12795.000  |       N/A\n","2020-11-09 13:58:53,746 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4889.688  |       N/A\n","2020-11-09 13:58:53,747 - INFO - allennlp.training.tensorboard_writer - f1              |     0.846  |     0.806\n","2020-11-09 13:58:53,748 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.859  |     0.825\n","2020-11-09 13:58:53,749 - INFO - allennlp.training.tensorboard_writer - loss            |     0.356  |     0.503\n","2020-11-09 13:59:01,771 - INFO - allennlp.training.trainer - Epoch duration: 0:00:29.796637\n","2020-11-09 13:59:01,771 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:03:31\n","2020-11-09 13:59:01,771 - INFO - allennlp.training.trainer - Epoch 3/9\n","2020-11-09 13:59:01,771 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4889.688\n","2020-11-09 13:59:01,881 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 12803\n","2020-11-09 13:59:01,884 - INFO - allennlp.training.trainer - Training\n","f1: 0.8784, accuracy: 0.8887, loss: 0.2899 ||: 100%|##########| 65/65 [00:21<00:00,  3.06it/s]\n","2020-11-09 13:59:23,098 - INFO - allennlp.training.trainer - Validating\n","f1: 0.8099, accuracy: 0.8254, loss: 0.6734 ||: 100%|##########| 1/1 [00:00<00:00,  1.49it/s]\n","2020-11-09 13:59:23,773 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation\n","2020-11-09 13:59:23,774 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  12803.000  |       N/A\n","2020-11-09 13:59:23,774 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4889.688  |       N/A\n","2020-11-09 13:59:23,774 - INFO - allennlp.training.tensorboard_writer - f1              |     0.878  |     0.810\n","2020-11-09 13:59:23,776 - INFO - allennlp.training.tensorboard_writer - accuracy        |     0.889  |     0.825\n","2020-11-09 13:59:23,776 - INFO - allennlp.training.tensorboard_writer - loss            |     0.290  |     0.673\n","2020-11-09 13:59:32,087 - INFO - allennlp.training.trainer - Epoch duration: 0:00:30.315888\n","2020-11-09 13:59:32,088 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:03:01\n","2020-11-09 13:59:32,088 - INFO - allennlp.training.trainer - Epoch 4/9\n","2020-11-09 13:59:32,088 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4889.688\n","2020-11-09 13:59:32,199 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 12803\n","2020-11-09 13:59:32,202 - INFO - allennlp.training.trainer - Training\n","f1: 0.9316, accuracy: 0.9380, loss: 0.2012 ||: 100%|##########| 65/65 [00:21<00:00,  3.03it/s]\n","2020-11-09 13:59:53,646 - INFO - allennlp.training.trainer - Validating\n","f1: 0.7500, accuracy: 0.7778, loss: 0.6949 ||: 100%|##########| 1/1 [00:00<00:00,  1.48it/s]\n","2020-11-09 13:59:54,323 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.\n","2020-11-09 13:59:54,324 - INFO - allennlp.training.checkpointer - loading best weights\n","2020-11-09 13:59:54,850 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.\n","2020-11-09 13:59:54,851 - INFO - allennlp.training.util - Iterating over dataset\n","f1: 0.87, accuracy: 0.88, loss: 0.26 ||: 100%|##########| 2/2 [00:00<00:00,  2.74it/s]\n","2020-11-09 13:59:55,583 - INFO - allennlp.models.archival - archiving weights and vocabulary to model_logs/hyperpartisan_news_nas_01/model.tar.gz\n","2020-11-09 14:00:28,224 - INFO - allennlp.common.util - Metrics: {\n","  \"best_epoch\": 1,\n","  \"peak_cpu_memory_MB\": 4889.688,\n","  \"peak_gpu_0_memory_MB\": 12803,\n","  \"training_duration\": \"0:01:52.673809\",\n","  \"training_start_epoch\": 0,\n","  \"training_epochs\": 3,\n","  \"epoch\": 3,\n","  \"training_f1\": 0.8783711194992065,\n","  \"training_accuracy\": 0.888671875,\n","  \"training_loss\": 0.28990345179045107,\n","  \"training_cpu_memory_MB\": 4889.688,\n","  \"training_gpu_0_memory_MB\": 12803,\n","  \"validation_f1\": 0.8098765313625336,\n","  \"validation_accuracy\": 0.8253968253968254,\n","  \"validation_loss\": 0.6734015345573425,\n","  \"best_validation_f1\": 0.8133584856987,\n","  \"best_validation_accuracy\": 0.8253968253968254,\n","  \"best_validation_loss\": 0.4150813817977905,\n","  \"test_f1\": 0.8699999749660492,\n","  \"test_accuracy\": 0.8769230769230769,\n","  \"test_loss\": 0.26101113855838776\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PckLU_XZc3mt","executionInfo":{"status":"ok","timestamp":1604937052764,"user_tz":300,"elapsed":437,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"26101fee-6ff0-4101-8919-3e5e2467d18b","colab":{"base_uri":"https://localhost:8080/"}},"source":["!python -m scripts.train \\\n","        --config training_config/classifier.jsonnet \\\n","        --serialization_dir model_logs/amazon_nas_03 \\\n","        --hyperparameters ROBERTA_CLASSIFIER_MINI \\\n","        --dataset amazon \\\n","        --model roberta-base \\\n","        --device 0 \\\n","        --perf +f1 \\\n","        --evaluate_on_test"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/usr/bin/python3: Error while finding module specification for 'scripts.train' (ModuleNotFoundError: No module named 'scripts')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L0Fy8sxYsxHD","executionInfo":{"status":"ok","timestamp":1604937003619,"user_tz":300,"elapsed":4132,"user":{"displayName":"Nathan Susanj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoQndWkN5SDIjqyvu822oEPdtGmM_W1loHOWJD=s64","userId":"15663150816458790265"}},"outputId":"20d69589-f714-4b58-e05b-1417b5153f5a","colab":{"base_uri":"https://localhost:8080/"}},"source":["import torch\n","if torch.cuda.is_available():\n","  device = torch.device(\"cuda\")\n","else:\n","  device = torch.device(\"cpu\")\n","print(device)\n","\n","!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["cuda\n","Mon Nov  9 15:50:03 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    25W / 250W |     10MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oniC7LugsyIR"},"source":[""],"execution_count":null,"outputs":[]}]}